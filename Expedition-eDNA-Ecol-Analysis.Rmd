---
title: "Expedition-eDNA-Ecol-analysis"
author: "Liz Suter"
date: "started 2025-03-27"
output: html_document
---

# I. Prepare packages and data

## Load packages

```{r}
# rm(list = ls())
library(tidyverse)
library(phyloseq)
library(vegan)
library(RColorBrewer)
library(microbiome)
library(metagMisc)
library(fantaxtic)
library(ggrepel)
library(paletteer)
library(pals)
library(compositions)
library(hms)
library(ggvegan)
library(sf)
library(ggimage)
library(cowplot)
library(patchwork)
library(spOccupancy)
library(corrplot)
library(geosphere)
library(plotly)
library(glue)
library(magick)
library(rredlist)
library(patchwork)
library(coda)

sessionInfo()
```

## Load data from QC and Filtering Workbook
```{r}
load("figures-expedition/environment_upto_export.RData")
```


# II. Abundance plots

## Bar plots of top species from whole dataset
### Prepare data
#### Expedition/ Mifish
```{r}
# Remove control samples
ps2024_exp_mifish_nocontrols <- subset_samples(ps2024_exp_mifish, is.na(controls))

# Convert to dataframe
exp_mifish_species_abundance <- data.frame(otu_table(ps2024_exp_mifish_nocontrols)) %>%
  mutate(ASV = rownames(.))

# Add back in tax information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_exp_mifish_nocontrols)) %>%
  mutate(ASV = rownames(.))

exp_mifish_species_abundance <- exp_mifish_species_abundance %>%
  left_join(tax_info, by = c("ASV" = "ASV"))

# Group and sum
exp_mifish_species_abundance <- exp_mifish_species_abundance %>%
  group_by(Species.CommonName) %>%
  summarise(TotalAbundance = sum(across(where(is.numeric)))) %>%
  ungroup()

# Calculate relative abundances across the whole dataset
exp_mifish_species_abundance <- exp_mifish_species_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Retain only most abundant sp
exp_mifish_species_abundance <- exp_mifish_species_abundance %>%
  arrange(desc(RelativeAbundance)) %>%
  slice_head(n = 12) # Show top 12 species


# Add columns indicating which library and sample type
exp_mifish_species_abundance$library <- "MiFish"
exp_mifish_species_abundance$sample_type <- "USV"


exp_mifish_species_abundance
```


#### Expedition/ Elas
```{r}
# Remove control samples
ps2024_exp_elas_nocontrols <- subset_samples(ps2024_exp_elas, is.na(controls))

# Convert to dataframe
exp_elas_species_abundance <- data.frame(otu_table(ps2024_exp_elas_nocontrols)) %>%
  mutate(ASV = rownames(.))

# Add back in tax information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_exp_elas_nocontrols)) %>%
  mutate(ASV = rownames(.))

exp_elas_species_abundance <- exp_elas_species_abundance %>%
  left_join(tax_info, by = c("ASV" = "ASV"))

# Group and sum
exp_elas_species_abundance <- exp_elas_species_abundance %>%
  group_by(Species.CommonName) %>%
  summarise(TotalAbundance = sum(across(where(is.numeric)))) %>%
  ungroup()

# Calculate relative abundances across the whole dataset
exp_elas_species_abundance <- exp_elas_species_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Plot only most abundant
exp_elas_species_abundance <- exp_elas_species_abundance %>%
  arrange(desc(RelativeAbundance)) %>%
  slice_head(n = 2) # Show top 2 species


# Add columns indicating which library and sample type
exp_elas_species_abundance$library <- "Elas02"
exp_elas_species_abundance$sample_type <- "USV"

exp_elas_species_abundance
```

#### Expedition/ CO1

There is too much going on here to make a similar figure of top species, so group by different taxonomic levels of interest...

##### Phyla
First, make a figure for top 10 phyla
```{r}
# Remove control samples
ps2024_exp_co1_phyla <- subset_samples(ps2024_exp_co1, is.na(controls))


# Aggregate
ps2024_exp_co1_phyla <- tax_glom(ps2024_exp_co1_phyla, taxrank = "Phylum") 

# Summarize total abundances for each species across the whole dataset
exp_co1_phyla_abundance <- data.frame(otu_table(ps2024_exp_co1_phyla)) %>%
  rowSums() %>%
  as.data.frame() %>%
  rownames_to_column(var = "ASV") %>%
  rename(TotalAbundance = ".")

# Calculate relative abundances across the whole dataset
exp_co1_phyla_abundance <- exp_co1_phyla_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Add back taxonomic information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_exp_co1_phyla))
tax_info <- tax_info %>%
  mutate(ASV = rownames(tax_info))

exp_co1_phyla_abundance <- exp_co1_phyla_abundance %>%
  left_join(tax_info, by = c("ASV" = "ASV"))

# Remove columns no longer relevant
exp_co1_phyla_abundance <- exp_co1_phyla_abundance[, colSums(!is.na(exp_co1_phyla_abundance)) > 0]

# Add columns indicating which library and sample type
exp_co1_phyla_abundance$library <- "CO1"
exp_co1_phyla_abundance$sample_type <- "USV"

# Add back in colors and common names of phyla
commonnames <- read_csv(file = "../eDNA-databases/commonnames.csv") 

# Add back in colors and common name
exp_co1_phyla_abundance <- exp_co1_phyla_abundance %>% 
  left_join(commonnames, by = c("Phylum" = "Taxon"))

exp_co1_phyla_abundance

```

##### Phyla of Animals only
All animals
```{r}
ps2024_exp_co1_animals <- subset_taxa(ps2024_exp_co1_nocontrols, Phylum %in% c("Annelida","Arthropoda","Cnidaria","Echinodermata","Mollusca","Ctenophora","Chordata","Porifera","Onychophora","Nemertea","Bryozoa","Platyhelminthes","Hemichordata","Nematoda","Gastrotricha","Placozoa","Xenacoelomorpha","Entoprocta","Tardigrada"))


# Aggregate
ps2024_exp_co1_animals_phyla <- tax_glom(ps2024_exp_co1_animals, taxrank = "Phylum") 

# Summarize total abundances for each species across the whole dataset
exp_co1_animals_phyla <- data.frame(otu_table(ps2024_exp_co1_animals_phyla)) %>%
  rowSums() %>%
  as.data.frame() %>%
  rownames_to_column(var = "ASV") %>%
  rename(TotalAbundance = ".")

# Calculate relative abundances across the whole dataset
exp_co1_animals_phyla <- exp_co1_animals_phyla %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Add back taxonomic information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_exp_co1_animals_phyla))
tax_info <- tax_info %>%
  mutate(ASV = rownames(tax_info))

exp_co1_animals_phyla <- exp_co1_animals_phyla %>%
  left_join(tax_info, by = c("ASV" = "ASV"))

# Remove columns no longer relevant
exp_co1_animals_phyla <- exp_co1_animals_phyla[, colSums(!is.na(exp_co1_animals_phyla)) > 0]

# Add columns indicating which library and sample type
exp_co1_animals_phyla$library <- "CO1"
exp_co1_animals_phyla$sample_type <- "USV"

# note- this table doesn't have colors yet

exp_co1_animals_phyla

```

##### Animals of interest
```{r}
ps2024_exp_co1_animals_ofinterest <- subset_taxa(ps2024_exp_co1_nocontrols, Phylum %in% c("Arthropoda","Mollusca","Chordata","Echinodermata"))


# Aggregate
ps2024_exp_co1_animals_ofinterest_class <- tax_glom(ps2024_exp_co1_animals_ofinterest, taxrank = "Class") 

# Summarize total abundances for each species across the whole dataset
exp_co1_animals_ofinterest_class <- data.frame(otu_table(ps2024_exp_co1_animals_ofinterest_class)) %>%
  rowSums() %>%
  as.data.frame() %>%
  rownames_to_column(var = "ASV") %>%
  rename(TotalAbundance = ".")

# Calculate relative abundances across the whole dataset
exp_co1_animals_ofinterest_class <- exp_co1_animals_ofinterest_class %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Add back taxonomic information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_exp_co1_animals_ofinterest_class))
tax_info <- tax_info %>%
  mutate(ASV = rownames(tax_info))

exp_co1_animals_ofinterest_class <- exp_co1_animals_ofinterest_class %>%
  left_join(tax_info, by = c("ASV" = "ASV"))

# Remove columns no longer relevant
exp_co1_animals_ofinterest_class <- exp_co1_animals_ofinterest_class[, colSums(!is.na(exp_co1_animals_ofinterest_class)) > 0]

# Add columns indicating which library and sample type
exp_co1_animals_ofinterest_class$library <- "CO1"
exp_co1_animals_ofinterest_class$sample_type <- "USV"

# Add back in colors and common names of phyla
commonnames <- read_csv(file = "../eDNA-databases/commonnames.csv") 

# Add back in colors and common name
exp_co1_animals_ofinterest_class <- exp_co1_animals_ofinterest_class %>% 
  left_join(commonnames, by = c("Class" = "Taxon"))

exp_co1_animals_ofinterest_class

```




##### Teleosts and Elasmobranchs
Then separate out all Actinopteri and elasmos and aggregate at species level
```{r}
# Remove control samples
ps2024_exp_co1_nocontrols <- subset_samples(ps2024_exp_co1, is.na(controls))

# Filter to just Actinopteri
ps2024_exp_co1_actinopteri_elasmos <- subset_taxa(ps2024_exp_co1_nocontrols, Class %in% c("Actinopteri","Chondrichthyes"))

# Convert to dataframe
exp_co1_actinopteri_elasmos_sp_abundance <- data.frame(otu_table(ps2024_exp_co1_actinopteri_elasmos)) %>%
  mutate(ASV = rownames(.))

# Add back in tax information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_exp_co1_actinopteri_elasmos)) %>%
  mutate(ASV = rownames(.))

exp_co1_actinopteri_elasmos_sp_abundance <- exp_co1_actinopteri_elasmos_sp_abundance %>%
  left_join(tax_info, by = c("ASV" = "ASV"))

# Group and sum
exp_co1_actinopteri_elasmos_sp_abundance <- exp_co1_actinopteri_elasmos_sp_abundance %>%
  group_by(Species.CommonName) %>%
  summarise(TotalAbundance = sum(across(where(is.numeric)))) %>%
  ungroup()

# Remove unclassified Actinopteri
exp_co1_actinopteri_elasmos_sp_abundance <- exp_co1_actinopteri_elasmos_sp_abundance %>%
  filter(!Species.CommonName == "Actinopteri")

# Calculate relative abundances across the whole dataset
exp_co1_actinopteri_elasmos_sp_abundance <- exp_co1_actinopteri_elasmos_sp_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Plot only most abundant
exp_co1_actinopteri_elasmos_sp_abundance <- exp_co1_actinopteri_elasmos_sp_abundance %>%
  arrange(desc(RelativeAbundance)) %>%
  slice_head(n = 14) # Show top 14 species


# Add columns indicating which library and sample type
exp_co1_actinopteri_elasmos_sp_abundance$library <- "CO1"
exp_co1_actinopteri_elasmos_sp_abundance$sample_type <- "USV"



exp_co1_actinopteri_elasmos_sp_abundance
```




##### Other Chordates
```{r}
# Filter 
ps2024_exp_co1_chordates <- subset_taxa(ps2024_exp_co1_nocontrols,
  Phylum == "Chordata" & Class != "Actinopteri" & Class != "Chondrichthyes")

# Convert to dataframe
exp_co1_chordates_sp_abundance <- data.frame(otu_table(ps2024_exp_co1_chordates)) %>%
  mutate(ASV = rownames(.))

# Add back in tax information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_exp_co1_chordates)) %>%
  mutate(ASV = rownames(.))

exp_co1_chordates_sp_abundance <- exp_co1_chordates_sp_abundance %>%
  left_join(tax_info, by = c("ASV" = "ASV"))


# Group and Sum
exp_co1_chordates_sp_abundance <- exp_co1_chordates_sp_abundance %>%
  group_by(Species) %>%
  summarise(TotalAbundance = sum(across(where(is.numeric)))) %>%
  ungroup()


# Calculate relative abundances across the whole dataset
exp_co1_chordates_sp_abundance <- exp_co1_chordates_sp_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Add columns indicating which library and sample type
exp_co1_chordates_sp_abundance$library <- "CO1"
exp_co1_chordates_sp_abundance$sample_type <- "USV"

exp_co1_chordates_sp_abundance

```
Mostly tunicates


##### Mollusks
Check Molluscs
```{r}
# Filter 
ps2024_exp_co1_molluscs <- subset_taxa(ps2024_exp_co1_nocontrols,
  Phylum == "Mollusca")

# Convert to dataframe
exp_co1_molluscs_sp_abundance <- data.frame(otu_table(ps2024_exp_co1_molluscs)) %>%
  mutate(ASV = rownames(.))

# Add back in tax information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_exp_co1_molluscs)) %>%
  mutate(ASV = rownames(.))

exp_co1_molluscs_sp_abundance <- exp_co1_molluscs_sp_abundance %>%
  left_join(tax_info, by = c("ASV" = "ASV"))


# Group and Sum
exp_co1_molluscs_sp_abundance <- exp_co1_molluscs_sp_abundance %>%
  group_by(Species) %>%
  summarise(TotalAbundance = sum(across(where(is.numeric)))) %>%
  ungroup()


# Calculate relative abundances across the whole dataset
exp_co1_molluscs_sp_abundance <- exp_co1_molluscs_sp_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Add columns indicating which library and sample type
exp_co1_molluscs_sp_abundance$library <- "CO1"
exp_co1_molluscs_sp_abundance$sample_type <- "USV"

exp_co1_molluscs_sp_abundance

```

##### Arthropods

```{r}
# Filter 
ps2024_exp_co1_arthropods <- subset_taxa(ps2024_exp_co1_nocontrols,
  Phylum == "Arthropoda")

# Convert to dataframe
exp_co1_arthropods_sp_abundance <- data.frame(otu_table(ps2024_exp_co1_arthropods)) %>%
  mutate(ASV = rownames(.))

# Add back in tax information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_exp_co1_arthropods)) %>%
  mutate(ASV = rownames(.))

exp_co1_arthropods_sp_abundance <- exp_co1_arthropods_sp_abundance %>%
  left_join(tax_info, by = c("ASV" = "ASV"))


# Group and Sum
exp_co1_arthropods_sp_abundance <- exp_co1_arthropods_sp_abundance %>%
  group_by(Species) %>%
  summarise(TotalAbundance = sum(across(where(is.numeric)))) %>%
  ungroup()


# Calculate relative abundances across the whole dataset
exp_co1_arthropods_sp_abundance <- exp_co1_arthropods_sp_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Add columns indicating which library and sample type
exp_co1_arthropods_sp_abundance$library <- "CO1"
exp_co1_arthropods_sp_abundance$sample_type <- "USV"

exp_co1_arthropods_sp_abundance

```



#### Trawl/ Mifish
```{r}
# Remove controls
ps2024_trawl_mifish_species <- subset_taxa(subset_samples(ps2024_trawl_mifish, is.na(controls)))

# Aggregate by Common Name
ps2024_trawl_mifish_species <- tax_glom(ps2024_trawl_mifish_species, taxrank = "Species.CommonName") 

# Summarize total abundances for each species across the whole dataset
trawl_mifish_species_abundance <- data.frame(otu_table(ps2024_trawl_mifish_species)) %>%
  rowSums() %>%
  as.data.frame() %>%
  rownames_to_column(var = "ASV") %>%
  rename(TotalAbundance = ".")

# Calculate relative abundances across the whole dataset
trawl_mifish_species_abundance <- trawl_mifish_species_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Add back taxonomic information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_trawl_mifish_species))
tax_info <- tax_info %>%
  mutate(ASV = rownames(tax_info))


trawl_mifish_species_abundance <- trawl_mifish_species_abundance %>%
  left_join(tax_info, by = c("ASV" = "ASV"))

# Plot only most abundant
trawl_mifish_species_abundance <- trawl_mifish_species_abundance %>%
  arrange(desc(RelativeAbundance)) %>%
  slice_head(n = 12) # Show top 12 species

# Remove ASV column
trawl_mifish_species_abundance <- trawl_mifish_species_abundance %>% select(-ASV)

# Add columns indicating which library and sample type
trawl_mifish_species_abundance$library <- "MiFish"
trawl_mifish_species_abundance$sample_type <- "Manual Sample"

trawl_mifish_species_abundance
```

#### Trawl/ Elas
```{r}
# Remove control samples
ps2024_trawl_elas_nocontrols <- subset_samples(ps2024_trawl_elas, is.na(controls))

# Convert to dataframe
trawl_elas_species_abundance <- data.frame(otu_table(ps2024_trawl_elas_nocontrols)) %>%
  mutate(ASV = rownames(.))

# Add back in tax information
rm(tax_info)
tax_info <- as.data.frame(tax_table(ps2024_trawl_elas_nocontrols)) %>%
  mutate(ASV = rownames(.))

trawl_elas_species_abundance <- trawl_elas_species_abundance %>%
  left_join(tax_info, by = c("ASV" = "ASV"))

# Group and sum
trawl_elas_species_abundance <- trawl_elas_species_abundance %>%
  group_by(Species.CommonName) %>%
  summarise(TotalAbundance = sum(across(where(is.numeric)))) %>%
  ungroup()

# Calculate relative abundances across the whole dataset
trawl_elas_species_abundance <- trawl_elas_species_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))

# Plot only most abundant
trawl_elas_species_abundance <- trawl_elas_species_abundance %>%
  arrange(desc(RelativeAbundance)) %>%
  slice_head(n = 2) # Show top 2 species


# Add columns indicating which library and sample type
trawl_elas_species_abundance$library <- "Elas02"
trawl_elas_species_abundance$sample_type <- "Manual Sample"

trawl_elas_species_abundance
```




#### Summary of top Species
Sum what % of total the top species comprise
```{r}
sum(exp_mifish_species_abundance$RelativeAbundance)
sum(trawl_mifish_species_abundance$RelativeAbundance)

sum(exp_elas_species_abundance$RelativeAbundance)
sum(trawl_elas_species_abundance$RelativeAbundance)

sum(exp_co1_phyla_abundance$RelativeAbundance)
sum(exp_co1_actinopteri_elasmos_sp_abundance$RelativeAbundance)
sum(exp_co1_chordates_sp_abundance$RelativeAbundance)
sum(exp_co1_molluscs_sp_abundance$RelativeAbundance)
sum(exp_co1_arthropods_sp_abundance$RelativeAbundance)
```

### Visualize
Append the 5 datasets of actinopteri and elasmos for comparison
```{r}
commonnames <- read_csv(file = "../eDNA-databases/commonnames.csv")

most_abund_all_datasets <- exp_mifish_species_abundance %>%
  bind_rows(trawl_mifish_species_abundance) %>%
  bind_rows(exp_elas_species_abundance) %>%
  bind_rows(trawl_elas_species_abundance) %>% 
  bind_rows(exp_co1_actinopteri_elasmos_sp_abundance) %>% 
  select (-Color, -CommonName) # this formatting got messed up in some of the rows

commonnames_mod <- commonnames %>% select(-Taxon) %>% distinct()

# Add back in colors and common name
most_abund_all_datasets <- most_abund_all_datasets %>% 
  left_join(commonnames_mod, by = c("Species.CommonName" = "Taxon.CommonName"))


most_abund_all_datasets
```



Fix colors so they remain constant in following plots
Some [predefined color names](https://sape.inf.usi.ch/quick-reference/ggplot2/colour) for reference
I started a colors column in commonnames database to keep assignment consistent across notebooks, but they got lost from the df when aggregating. Join back in and format for plotting
```{r}

myColors_sciname <- setNames(commonnames$Color, commonnames$Taxon)
myColors_comname <- setNames(commonnames$Color, commonnames$CommonName)
myColors_taxcomname <- setNames(commonnames$Color, commonnames$Taxon.CommonName)

head(myColors_sciname)
head(myColors_comname)
head(myColors_taxcomname)
```

#### Top Species- Teleosts and Elasmos
For report: MiFish and Elas02 only
```{r}
# Plot a stacked barplot- 
top_species_abundance_plot <- ggplot(most_abund_all_datasets %>% filter(!library == "CO1"), aes(x = sample_type, y = RelativeAbundance, fill = CommonName)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::percent_format()) + 
  scale_fill_manual(values = myColors_comname) +
  facet_grid(~library) +
  labs(x = NULL, y = "Relative Abundance (%)", title = "Relative Abundance of Top Species: Expedition vs. Manual Samples") +
  theme_minimal() +
  guides(fill = guide_legend(ncol = 2)) +  # Adjust # of legend columns
  theme(legend.title = element_blank())
  
  

top_species_abundance_plot

ggsave(plot = top_species_abundance_plot, filename = "figures-expedition/top_species_abundance_plot.jpg")

```



For presentation: MiFish and Elas02 alongside CO1
```{r}
# Plot a stacked barplot- 
top_species_abundance_plot_CO1 <- ggplot(most_abund_all_datasets, aes(x = sample_type, y = RelativeAbundance, fill = CommonName)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::percent_format()) + 
  scale_fill_manual(values = myColors_comname) +
  facet_grid(~library, scales = "free_x", space = "free") +
  labs(x = NULL, y = "Relative Abundance (%)", title = "Relative Abundance of Top Species: Expedition vs. Manual Samples") +
  theme_minimal() +
  guides(fill = guide_legend(ncol = 2)) +  # Adjust # of legend columns
  theme(legend.title = element_blank())
  
  

top_species_abundance_plot_CO1

ggsave(plot = top_species_abundance_plot_CO1, filename = "figures-expedition/top_species_abundance_plot_with_CO1.jpg")

```

#### Top Phyla- CO1
```{r}
# Retain only most abundant sp
exp_co1_phyla_abundance_top <- exp_co1_phyla_abundance %>%
  arrange(desc(RelativeAbundance)) %>%
  slice_head(n = 15) # Show top 15 phyla


# Plot a stacked barplot- 
top_phyla_abundance_plot_CO1 <- ggplot(exp_co1_phyla_abundance_top, aes(x = sample_type, y = RelativeAbundance, fill = Taxon.CommonName)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::percent_format()) + 
  scale_fill_manual(values = myColors_taxcomname) +
  facet_grid(~library, scales = "free_x", space = "free") +
  labs(x = NULL, y = "Relative Abundance (%)", title = "Relative Abundance of Top Phyla: CO1") +
  theme_minimal() +
  guides(fill = guide_legend(ncol = 2)) +  # Adjust # of legend columns
  theme(legend.title = element_blank())
  
  

top_phyla_abundance_plot_CO1

ggsave(plot = top_phyla_abundance_plot_CO1, filename = "figures-expedition/top_phyla_abundance_plot_CO1.jpg")

```

#### Classes of Animals of Interest
```{r}
# Plot a stacked barplot- 
animals_plot_CO1 <- ggplot(exp_co1_animals_ofinterest_class, aes(x = sample_type, y = RelativeAbundance, fill = Taxon.CommonName)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::percent_format()) + 
  scale_fill_manual(values = myColors_taxcomname) +
  facet_grid(~library, scales = "free_x", space = "free") +
  labs(x = NULL, y = "Relative Abundance (%)", title = "CO1: Arthropods, Molluscs, Chordates, and Echinoderms") +
  theme_minimal() +
  guides(fill = guide_legend(ncol = 2)) +  # Adjust # of legend columns
  theme(legend.title = element_blank())

animals_plot_CO1

ggsave(plot = animals_plot_CO1, filename = "figures-expedition/animals_plot_CO1.jpg")

```



## Examine controls 

### Prepare data for positive controls
Extract positive controls and convert to dataframe
NOTE- there are not Elasmo pos controls in this dataset
```{r}
ps2024_exp_mifish_controls <- subset_samples(ps2024_exp_mifish, controls == "positive")
ps2024_exp_co1_controls <- subset_samples(ps2024_exp_co1, controls == "positive")
ps2024_trawl_mifish_controls <- subset_samples(ps2024_trawl_mifish, controls == "positive")

ps2024_exp_mifish_controls_long_df <- ps2024_exp_mifish_controls %>%
  psmelt() %>%
  as_tibble()

ps2024_exp_co1_controls_long_df <- ps2024_exp_co1_controls %>%
  psmelt() %>%
  as_tibble()

ps2024_trawl_mifish_controls_long_df <- ps2024_trawl_mifish_controls %>%
  psmelt() %>%
  as_tibble()

ps2024_exp_mifish_controls_long_df
ps2024_exp_co1_controls_long_df
ps2024_trawl_mifish_controls_long_df
```


#### Exp/MiFish-

Plot a stacked barplot- 
```{r}
# Sum by common name, calculate total abundance and relative abundance
ps2024_exp_mifish_controls_long_df_sum <- ps2024_exp_mifish_controls_long_df %>%
  group_by(CommonName, Name.Deploy_Cartr_Library) %>%
  summarise(TotalAbundance = sum(Abundance, na.rm = TRUE), .groups = "drop_last") %>%
  group_by(Name.Deploy_Cartr_Library) %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(TotalAbundance > 0) %>%
  arrange(desc(TotalAbundance))

# Pos Controls by read abundance
ps2024_exp_mifish_posctl_barplot <- ggplot(ps2024_exp_mifish_controls_long_df_sum, 
       aes(x = Name.Deploy_Cartr_Library, y = TotalAbundance, fill = CommonName)) +
  geom_bar(stat = "identity") +
  labs(title = "2024 Expedition, Pos. Controls: Read Abund.",
       x = NULL, fill = NULL) +
  scale_y_continuous(name="Read Abundance") +
  theme(axis.title.x=element_blank(), legend.title = element_blank(), axis.text.x = element_blank()) +
  scale_fill_manual(values = myColors_comname) +
  theme_minimal()
ps2024_exp_mifish_posctl_barplot

# Pos Controls by relative abundance
ps2024_exp_mifish_posctl_ra_barplot <- ggplot(ps2024_exp_mifish_controls_long_df_sum, 
       aes(x = Name.Deploy_Cartr_Library, y = RelativeAbundance, fill = CommonName)) +
  geom_bar(stat = "identity") +
  labs(title = "2024 Expedition, Pos. Controls: Relative Read Abund.",
       x = NULL, fill = NULL) +
  scale_y_continuous(name="Read Abundance") +
  theme(axis.title.x=element_blank(), legend.title = element_blank(), axis.text.x = element_blank()) +
  scale_fill_manual(values = myColors_comname) +
  theme_minimal()
ps2024_exp_mifish_posctl_ra_barplot


ggsave(plot = ps2024_exp_mifish_posctl_barplot, filename = "figures-expedition/2024_exp_mifish_posctl_barplot.jpg", width = 4, height = 4, units = "in")
ggsave(plot = ps2024_exp_mifish_posctl_ra_barplot, filename = "figures-expedition/2024_exp_mifish_posctl_ra_barplot.jpg", width = 4, height = 4, units = "in")

ggsave(plot = ps2024_exp_mifish_posctl_barplot, filename = "figures-expedition/2024_exp_mifish_posctl_barplot.eps", width = 4, height = 4, units = "in")
ggsave(plot = ps2024_exp_mifish_posctl_ra_barplot, filename = "figures-expedition/2024_exp_mifish_posctl_ra_barplot.eps", width = 4, height = 4, units = "in")

```

#### Exp/CO1-
(Note- there are no pos ctls for elasmobranchs in 2024)
Plot a stacked barplot- 
```{r}
# Sum by common name, calculate total abundance and relative abundance
ps2024_exp_co1_controls_long_df_sum <- ps2024_exp_co1_controls_long_df %>%
  group_by(CommonName, Name_Deploy_Cartr) %>%
  summarise(TotalAbundance = sum(Abundance, na.rm = TRUE), .groups = "drop_last") %>%
  filter(!is.na(CommonName)) %>%  # Remove NAs BEFORE calculating relative abundance
  group_by(Name_Deploy_Cartr) %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(TotalAbundance > 0) %>%
  arrange(desc(TotalAbundance))


# Pos Controls by read abundance
ps2024_exp_co1_posctl_barplot <- ggplot(ps2024_exp_co1_controls_long_df_sum, 
       aes(x = Name_Deploy_Cartr, y = TotalAbundance, fill = CommonName)) +
  geom_bar(stat = "identity") +
  labs(title = "2024 Expedition, Pos. Controls: Read Abund.",
       x = NULL, fill = NULL) +
  scale_y_continuous(name="Read Abundance") +
  theme(axis.title.x=element_blank(), legend.title = element_blank(), axis.text.x = element_blank()) +
  scale_fill_manual(values = myColors_comname) +
  theme_minimal()
ps2024_exp_co1_posctl_barplot

# Pos Controls by relative abundance
ps2024_exp_co1_posctl_ra_barplot <- ggplot(ps2024_exp_co1_controls_long_df_sum, 
       aes(x = Name_Deploy_Cartr, y = RelativeAbundance, fill = CommonName)) +
  geom_bar(stat = "identity") +
  labs(title = "2024 Expedition, Pos. Controls: Relative Read Abund.",
       x = NULL, fill = NULL) +
  scale_y_continuous(name="Read Abundance") +
  theme(axis.title.x=element_blank(), legend.title = element_blank(), axis.text.x = element_blank()) +
  scale_fill_manual(values = myColors_comname) +
  theme_minimal()
ps2024_exp_co1_posctl_ra_barplot


ggsave(plot = ps2024_exp_co1_posctl_barplot, filename = "figures-expedition/2024_exp_co1_posctl_barplot.jpg", width = 4, height = 4, units = "in")
ggsave(plot = ps2024_exp_co1_posctl_ra_barplot, filename = "figures-expedition/2024_exp_co1_posctl_ra_barplot.jpg", width = 4, height = 4, units = "in")

ggsave(plot = ps2024_exp_co1_posctl_barplot, filename = "figures-expedition/2024_exp_co1_posctl_barplot.eps", width = 4, height = 4, units = "in")
ggsave(plot = ps2024_exp_co1_posctl_ra_barplot, filename = "figures-expedition/2024_exp_co1_posctl_ra_barplot.eps", width = 4, height = 4, units = "in")

```


#### Trawl/MiFish-
(again, no Elasmo pos controls from hand samples)

Plot a stacked barplot- 
```{r}
# Sum by common name, calculate total abundance and relative abundance
ps2024_trawl_mifish_controls_long_df_sum <- ps2024_trawl_mifish_controls_long_df %>%
  group_by(CommonName, replicates) %>%
  summarise(TotalAbundance = sum(Abundance, na.rm = TRUE), .groups = "drop_last") %>%
  group_by(replicates) %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(TotalAbundance > 0) %>%
  arrange(desc(TotalAbundance))

# Pos Controls by read abundance
ps2024_trawl_mifish_posctl_barplot <- ggplot(ps2024_trawl_mifish_controls_long_df_sum, 
       aes(x = replicates, y = TotalAbundance, fill = CommonName)) +
  geom_bar(stat = "identity") +
  labs(title = "2024 trawl, Pos. Controls: Read Abund.",
       x = NULL, fill = NULL) +
  scale_y_continuous(name="Read Abundance") +
  theme(axis.title.x=element_blank(), legend.title = element_blank(), axis.text.x = element_blank()) +
  scale_fill_manual(values = myColors_comname) +
  theme_minimal()
ps2024_trawl_mifish_posctl_barplot

# Pos Controls by relative abundance
ps2024_trawl_mifish_posctl_ra_barplot <- ggplot(ps2024_trawl_mifish_controls_long_df_sum, 
       aes(x = replicates, y = RelativeAbundance, fill = CommonName)) +
  geom_bar(stat = "identity") +
  labs(title = "2024 trawl, Pos. Controls: Relative Read Abund.",
       x = NULL, fill = NULL) +
  scale_y_continuous(name="Read Abundance") +
  theme(axis.title.x=element_blank(), legend.title = element_blank(), axis.text.x = element_blank()) +
  scale_fill_manual(values = myColors_comname) +
  theme_minimal()
ps2024_trawl_mifish_posctl_ra_barplot


ggsave(plot = ps2024_trawl_mifish_posctl_barplot, filename = "figures-expedition/2024_trawl_mifish_posctl_barplot.jpg", width = 4, height = 4, units = "in")
ggsave(plot = ps2024_trawl_mifish_posctl_ra_barplot, filename = "figures-expedition/2024_trawl_mifish_posctl_ra_barplot.jpg", width = 4, height = 4, units = "in")

ggsave(plot = ps2024_trawl_mifish_posctl_barplot, filename = "figures-expedition/2024_trawl_mifish_posctl_barplot.eps", width = 4, height = 4, units = "in")
ggsave(plot = ps2024_trawl_mifish_posctl_ra_barplot, filename = "figures-expedition/2024_trawl_mifish_posctl_ra_barplot.eps", width = 4, height = 4, units = "in")

```


### Remove Pos and Neg  Controls from all phyloseq objects:
(Note, they were already removed from Elas objects just based on quality filtering above)

ASV-based, reads:
ps2024_exp_mifish

ASV-based, relative abundance:
ps2024_exp_mifish_ra

Taxonomy (species)- based, reads:
ps2024_exp_mifish_glommed


Taxonomy (species)- based, relative abundance:
ps2024_exp_mifish_glommed_ra


```{r}
ps2024_exp_mifish <- subset_samples(ps2024_exp_mifish, is.na(controls))
ps2024_exp_mifish_ra <- subset_samples(ps2024_exp_mifish_ra, is.na(controls))
ps2024_exp_mifish_glommed <- subset_samples(ps2024_exp_mifish_glommed, is.na(controls))
ps2024_exp_mifish_glommed_ra <- subset_samples(ps2024_exp_mifish_glommed_ra, is.na(controls))

ps2024_exp_elas <- subset_samples(ps2024_exp_elas, is.na(controls))
ps2024_exp_elas_ra <- subset_samples(ps2024_exp_elas_ra, is.na(controls))
ps2024_exp_elas_glommed <- subset_samples(ps2024_exp_elas_glommed, is.na(controls))
ps2024_exp_elas_glommed_ra <- subset_samples(ps2024_exp_elas_glommed_ra, is.na(controls))

ps2024_exp_co1 <- subset_samples(ps2024_exp_co1, is.na(controls))
ps2024_exp_co1_ra <- subset_samples(ps2024_exp_co1_ra, is.na(controls))
ps2024_exp_co1_glommed <- subset_samples(ps2024_exp_co1_glommed, is.na(controls))
ps2024_exp_co1_glommed_ra <- subset_samples(ps2024_exp_co1_glommed_ra, is.na(controls))

ps2024_exp_co1_actinopteri_elasmos <- subset_samples(ps2024_exp_co1_actinopteri_elasmos, is.na(controls))
ps2024_exp_co1_arthropods <- subset_samples(ps2024_exp_co1_arthropods, is.na(controls))
ps2024_exp_co1_chordates <- subset_samples(ps2024_exp_co1_chordates, is.na(controls))
ps2024_exp_co1_molluscs <- subset_samples(ps2024_exp_co1_molluscs, is.na(controls))

ps2024_trawl_mifish <- subset_samples(ps2024_trawl_mifish, is.na(controls))
ps2024_trawl_mifish_ra <- subset_samples(ps2024_trawl_mifish_ra, is.na(controls))
ps2024_trawl_mifish_glommed <- subset_samples(ps2024_trawl_mifish_glommed, is.na(controls))
ps2024_trawl_mifish_glommed_ra <- subset_samples(ps2024_trawl_mifish_glommed_ra, is.na(controls))

ps2024_trawl_elas <- subset_samples(ps2024_trawl_elas, is.na(controls))
ps2024_trawl_elas_ra <- subset_samples(ps2024_trawl_elas_ra, is.na(controls))
ps2024_trawl_elas_glommed <- subset_samples(ps2024_trawl_elas_glommed, is.na(controls))
ps2024_trawl_elas_glommed_ra <- subset_samples(ps2024_trawl_elas_glommed_ra, is.na(controls))

```

#### Save

```{r}
save.image(file = "figures-expedition/exp_ecol_analysis_environment_upto_posctlanalysis.RData")
```

or load back in
```{r}
load(file = "figures-expedition/exp_ecol_analysis_environment_upto_posctlanalysis.RData")
```



## Bubble plots

Based on my previous [scripts](https://github.com/lizsuter/Cariaco_Euk)

Work with tax-based dataframes (rather than ASV-based):

Taxonomy (species)- based, reads:
ps2024_exp_mifish_glommed

Taxonomy (species)- based, relative abundance:
ps2024_exp_mifish_glommed_ra

### Prepare data
#### Expedition/ MiFish
```{r}
# convert ps object to dataframe using phyloseq's psmelt
ps2024_exp_mifish_glommed_df <- psmelt(ps2024_exp_mifish_glommed)
ps2024_exp_mifish_glommed_ra_df <- psmelt(ps2024_exp_mifish_glommed_ra)

# replace zeroes in the table with NA
ps2024_exp_mifish_glommed_df[ps2024_exp_mifish_glommed_df == 0] <- NA
ps2024_exp_mifish_glommed_ra_df[ps2024_exp_mifish_glommed_ra_df == 0] <- NA

# and remove rows with NAs (so they don't appear as small dots in plot)
ps2024_exp_mifish_glommed_df <-  filter(ps2024_exp_mifish_glommed_df, !is.na(Abundance))
ps2024_exp_mifish_glommed_ra_df <-  filter(ps2024_exp_mifish_glommed_ra_df, !is.na(Abundance))


# and view
ps2024_exp_mifish_glommed_df
ps2024_exp_mifish_glommed_ra_df
```

#### Expedition/ Elas02-
```{r}
# convert ps object to dataframe using phyloseq's psmelt
ps2024_exp_elas_glommed_df <- psmelt(ps2024_exp_elas_glommed)
ps2024_exp_elas_glommed_ra_df <- psmelt(ps2024_exp_elas_glommed_ra)

# replace zeroes in the table with NA
ps2024_exp_elas_glommed_df[ps2024_exp_elas_glommed_df == 0] <- NA
ps2024_exp_elas_glommed_ra_df[ps2024_exp_elas_glommed_ra_df == 0] <- NA

# and remove rows with NAs (so they don't appear as small dots in plot)
ps2024_exp_elas_glommed_df <-  filter(ps2024_exp_elas_glommed_df, !is.na(Abundance))
ps2024_exp_elas_glommed_ra_df <-  filter(ps2024_exp_elas_glommed_ra_df, !is.na(Abundance))

# and view
ps2024_exp_elas_glommed_df
ps2024_exp_elas_glommed_ra_df
```

#### Expedition/ CO1- 
```{r}
# convert ps object to dataframe using phyloseq's psmelt
ps2024_exp_co1_glommed_df <- psmelt(ps2024_exp_co1_glommed)

# replace zeroes in the table with NA
ps2024_exp_co1_glommed_df[ps2024_exp_co1_glommed_df == 0] <- NA

# and remove rows with NAs (so they don't appear as small dots in plot)
ps2024_exp_co1_glommed_df <-  filter(ps2024_exp_co1_glommed_df, !is.na(Abundance))


# and view
ps2024_exp_co1_glommed_df
```

CO1 Species
```{r}
# convert ps object to dataframe using phyloseq's psmelt
ps2024_exp_co1_glommed_df_species <- psmelt(ps2024_exp_co1_glommed)

# replace zeroes in the table with NA
ps2024_exp_co1_glommed_df_species[ps2024_exp_co1_glommed_df_species == 0] <- NA

# and remove rows with NAs (so they don't appear as small dots in plot)
ps2024_exp_co1_glommed_df_species <-  filter(ps2024_exp_co1_glommed_df_species, !is.na(Abundance))


# and view
ps2024_exp_co1_glommed_df_species
```


CO1 Actinopteri and Elasmobranchs only 
```{r}
# convert ps object to dataframe using phyloseq's psmelt
ps2024_exp_co1_glommed_df_actinopteri_elasmos <- psmelt(ps2024_exp_co1_actinopteri_elasmos)

# replace zeroes in the table with NA
ps2024_exp_co1_glommed_df_actinopteri_elasmos[ps2024_exp_co1_glommed_df_actinopteri_elasmos == 0] <- NA

# and remove rows with NAs (so they don't appear as small dots in plot)
ps2024_exp_co1_glommed_df_actinopteri_elasmos <-  filter(ps2024_exp_co1_glommed_df_actinopteri_elasmos, !is.na(Abundance))


# and view
ps2024_exp_co1_glommed_df_actinopteri_elasmos
```

CO1 Chordates only 
```{r}
# convert ps object to dataframe using phyloseq's psmelt
ps2024_exp_co1_glommed_df_chordates <- psmelt(ps2024_exp_co1_chordates)

# replace zeroes in the table with NA
ps2024_exp_co1_glommed_df_chordates[ps2024_exp_co1_glommed_df_chordates == 0] <- NA

# and remove rows with NAs (so they don't appear as small dots in plot)
ps2024_exp_co1_glommed_df_chordates <-  filter(ps2024_exp_co1_glommed_df_chordates, !is.na(Abundance))


# and view
ps2024_exp_co1_glommed_df_chordates
```

CO1 Molluscs only 
```{r}
# convert ps object to dataframe using phyloseq's psmelt
ps2024_exp_co1_glommed_df_molluscs <- psmelt(ps2024_exp_co1_chordates)

# replace zeroes in the table with NA
ps2024_exp_co1_glommed_df_chordates[ps2024_exp_co1_glommed_df_chordates == 0] <- NA

# and remove rows with NAs (so they don't appear as small dots in plot)
ps2024_exp_co1_glommed_df_chordates <-  filter(ps2024_exp_co1_glommed_df_chordates, !is.na(Abundance))


# and view
ps2024_exp_co1_glommed_df_chordates

```


### Plot by sites

#### MiFish-

```{r}

# First sort the site names in a sensible way
levels(unique(c(ps2024_exp_mifish_glommed_df$sites)))
sitelevels <- as.character(sort(as.numeric(levels(unique(c(ps2024_exp_mifish_glommed_df$sites))))))
sitelevels

# Order E-W in sensible way by making it a factor
ps2024_exp_mifish_glommed_df$Bayside_f= factor(ps2024_exp_mifish_glommed_df$Bayside, levels=c('W','E'))

```



##### By bayside
```{r}
# First average replicates at same sites
ps2024_exp_mifish_glommed_df_bayside <- ps2024_exp_mifish_glommed_df %>%
    group_by(sites, Bayside_f, CommonName, `Species.CommonName`) %>%
    dplyr::summarize(Abundance = mean(Abundance))
ps2024_exp_mifish_glommed_df_bayside


bubbleplot_comname_2024_expedition_mifish_Bayside <- ggplot(ps2024_exp_mifish_glommed_df_bayside, aes(x = factor(sites, levels = sitelevels), y = fct_rev(`Species.CommonName`))) + # the fancy stuff around y (`Species-CommonName`) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size=ifelse(Abundance==0, NA, Abundance), fill = `CommonName`), color = "black", pch = 21) +
  scale_size_area(breaks = c(1000,10000,100000,1000000,10000000))+
  xlab("")+
  ylab("")+
  labs(size="Read Abundance", fill = "")+
  theme_bw() +
  scale_fill_manual(values = myColors_comname)+
  theme(axis.title.x=element_blank(), axis.text.x = element_text(size = 11), axis.text.y = element_text(size = 11), legend.position = "bottom") +
  guides(fill="none") +
  facet_grid(~Bayside_f, scales = "free", space = "free", drop= TRUE)
bubbleplot_comname_2024_expedition_mifish_Bayside


  
  
# save
ggsave(plot = bubbleplot_comname_2024_expedition_mifish_Bayside, filename = "figures-expedition/bubbleplot_comname_2024_expedition_mifish_Bayside.eps", width = 9.5, height = 10, units = "in")

ggsave(plot = bubbleplot_comname_2024_expedition_mifish_Bayside, filename = "figures-expedition/bubbleplot_comname_2024_expedition_mifish_Bayside.jpg", width = 9.5, height = 10, units = "in")
```

##### By Day/Night
```{r}
# First average replicates at same sites
ps2024_exp_mifish_glommed_df_daynight <- ps2024_exp_mifish_glommed_df %>%
    group_by(sites, Night__Day, CommonName, `Species.CommonName`) %>%
    dplyr::summarize(Abundance = mean(Abundance))
ps2024_exp_mifish_glommed_df_daynight


bubbleplot_comname_2024_expedition_mifish_DayNight <- ggplot(ps2024_exp_mifish_glommed_df_daynight, aes(x = factor(sites, levels = sitelevels), y = fct_rev(`Species.CommonName`))) + # the fancy stuff around y (`Species-CommonName`) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size=ifelse(Abundance==0, NA, Abundance), fill = `CommonName`), color = "black", pch = 21) +
  scale_size_area(breaks = c(1000,10000,100000,1000000,10000000))+
  xlab("")+
  ylab("")+
  labs(size="Read Abundance", fill = "")+
  theme_bw() +
  scale_fill_manual(values = myColors_comname)+
   theme(axis.title.x=element_blank(), axis.text.x = element_text(size = 11), axis.text.y = element_text(size = 11), legend.position = "bottom") +
  guides(fill="none") +
  facet_grid(~Night__Day, scales = "free", space = "free", drop= TRUE)
bubbleplot_comname_2024_expedition_mifish_DayNight


ggsave(plot = bubbleplot_comname_2024_expedition_mifish_DayNight, filename = "figures-expedition/bubbleplot_comname_2024_expedition_mifish_DayNight.eps", width = 12, height = 7, units = "in")
```

##### By Habitat
```{r}
# First average replicates at same sites
ps2024_exp_mifish_glommed_df_habitat <- ps2024_exp_mifish_glommed_df %>%
    group_by(sites, Habitat, CommonName, `Species.CommonName`) %>%
    dplyr::summarize(Abundance = mean(Abundance))
ps2024_exp_mifish_glommed_df_habitat


bubbleplot_comname_2024_expedition_mifish_Habitat <- ggplot(ps2024_exp_mifish_glommed_df_habitat, aes(x = factor(sites, levels = sitelevels), y = fct_rev(`Species.CommonName`))) + # the fancy stuff around y (`Species-CommonName`) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size=ifelse(Abundance==0, NA, Abundance), fill = `CommonName`), color = "black", pch = 21) +
  scale_size_area(breaks = c(1000,10000,100000,1000000,10000000))+
  xlab("")+
  ylab("")+
  labs(size="Read Abundance", fill = "")+
  theme_bw() +
  scale_fill_manual(values = myColors_comname)+
   theme(axis.title.x=element_blank(), axis.text.x = element_text(size = 11), axis.text.y = element_text(size = 11), legend.position = "bottom") +
  guides(fill="none") +
  facet_grid(~Habitat, scales = "free", space = "free", drop= TRUE)
bubbleplot_comname_2024_expedition_mifish_Habitat

ggsave(plot = bubbleplot_comname_2024_expedition_mifish_Habitat, filename = "figures-expedition/bubbleplot_comname_2024_expedition_mifish_Habitat.eps", width = 12, height = 7, units = "in")
```
##### By Bayside and Day-Night
```{r}
# First average replicates at same sites
ps2024_exp_mifish_glommed_df_bayside_daynight <- ps2024_exp_mifish_glommed_df %>%
    group_by(sites, Bayside_f, Night__Day, CommonName, `Species.CommonName`) %>%
    dplyr::summarize(Abundance = mean(Abundance))
ps2024_exp_mifish_glommed_df_bayside_daynight


bubbleplot_comname_2024_expedition_mifish_Bayside_DayNight <- ggplot(ps2024_exp_mifish_glommed_df_bayside_daynight, aes(x = factor(sites, levels = sitelevels), y = fct_rev(`Species.CommonName`))) + # the fancy stuff around y (`Species-CommonName`) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size=ifelse(Abundance==0, NA, Abundance), fill = `CommonName`), color = "black", pch = 21) +
  scale_size_area(breaks = c(1000,10000,100000,1000000,10000000))+
  xlab("")+
  ylab("")+
  labs(size="Read Abundance", fill = "")+
  theme_bw() +
  scale_fill_manual(values = myColors_comname)+
   theme(axis.title.x=element_blank(), axis.text.x = element_text(size = 11), axis.text.y = element_text(size = 11), legend.position = "bottom") +
  guides(fill="none") +
  facet_grid(Night__Day~Bayside_f, scales = "free", space = "free", drop= TRUE)
bubbleplot_comname_2024_expedition_mifish_Bayside_DayNight




ggsave(plot = bubbleplot_comname_2024_expedition_mifish_Bayside_DayNight, filename = "figures-expedition/bubbleplot_comname_2024_expedition_mifish_Bayside_DayNight.eps", width = 10, height = 9, units = "in")

```





#### Elas02-

```{r}

# First sort the site names in a sensible way
levels(unique(c(ps2024_exp_elas_glommed_df$sites)))
sitelevels <- as.character(sort(as.numeric(levels(unique(c(ps2024_exp_elas_glommed_df$sites))))))
sitelevels

# Order E-W in sensible way by making it a factor
ps2024_exp_elas_glommed_df$Bayside_f= factor(ps2024_exp_elas_glommed_df$Bayside, levels=c('W','E'))

```



##### By bayside
```{r}
# First average replicates at same sites
ps2024_exp_elas_glommed_df_bayside <- ps2024_exp_elas_glommed_df %>%
    group_by(sites, Bayside_f, CommonName, `Species.CommonName`) %>%
    dplyr::summarize(Abundance = mean(Abundance))
ps2024_exp_elas_glommed_df_bayside



bubbleplot_comname_2024_expedition_elas_Bayside <- ggplot(ps2024_exp_elas_glommed_df_bayside, aes(x = factor(sites, levels = sitelevels), y = fct_rev(`Species.CommonName`))) + # the fancy stuff around y (`Species-CommonName`) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size=ifelse(Abundance==0, NA, Abundance), fill = `CommonName`), color = "black", pch = 21) +
  scale_size_area(breaks = c(1000,10000,100000,1000000,10000000))+
  xlab("")+
  ylab("")+
  labs(size="Read Abundance", fill = "")+
  theme_bw() +
  scale_fill_manual(values = myColors_comname)+
   theme(axis.title.x=element_blank(), axis.text.x = element_text(size = 11), axis.text.y = element_text(size = 11), legend.position = "bottom") +
  guides(fill="none") +
  facet_grid(~Bayside_f, scales = "free", space = "free", drop= TRUE)
bubbleplot_comname_2024_expedition_elas_Bayside

# save
ggsave(plot = bubbleplot_comname_2024_expedition_elas_Bayside, filename = "figures-expedition/bubbleplot_comname_2024_expedition_elas_Bayside.eps", width = 8, height = 2.5, units = "in")

ggsave(plot = bubbleplot_comname_2024_expedition_elas_Bayside, filename = "figures-expedition/bubbleplot_comname_2024_expedition_elas_Bayside.jpg", width = 8, height = 2.5, units = "in")
```

##### By DayNight
```{r}
# First average replicates at same sites
ps2024_exp_elas_glommed_df_daynight <- ps2024_exp_elas_glommed_df %>%
    group_by(sites, Night__Day, CommonName, `Species.CommonName`) %>%
    dplyr::summarize(Abundance = mean(Abundance))
ps2024_exp_elas_glommed_df_daynight


bubbleplot_comname_2024_expedition_elas_DayNight <- ggplot(ps2024_exp_elas_glommed_df_daynight, aes(x = factor(sites, levels = sitelevels), y = fct_rev(`Species.CommonName`))) + # the fancy stuff around y (`Species-CommonName`) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size=ifelse(Abundance==0, NA, Abundance), fill = `CommonName`), color = "black", pch = 21) +
  scale_size_area(breaks = c(1000,10000,100000,1000000,10000000))+
  xlab("")+
  ylab("")+
  labs(size="Read Abundance", fill = "")+
  theme_bw() +
  scale_fill_manual(values = myColors_comname)+
   theme(axis.title.x=element_blank(), axis.text.x = element_text(size = 11), axis.text.y = element_text(size = 11), legend.position = "bottom") +
  guides(fill="none") +
  facet_grid(~Night__Day, scales = "free", space = "free", drop= TRUE)
bubbleplot_comname_2024_expedition_elas_DayNight


ggsave(plot = bubbleplot_comname_2024_expedition_elas_DayNight, filename = "figures-expedition/bubbleplot_comname_2024_expedition_elas_DayNight.eps", width = 10, height = 2.5, units = "in")
```

##### By Habitat
```{r}
# First average replicates at same sites
ps2024_exp_elas_glommed_df_habitat <- ps2024_exp_elas_glommed_df %>%
    group_by(sites, Habitat, CommonName, `Species.CommonName`) %>%
    dplyr::summarize(Abundance = mean(Abundance))
ps2024_exp_elas_glommed_df_habitat


bubbleplot_comname_2024_expedition_elas_Habitat <- ggplot(ps2024_exp_elas_glommed_df_habitat, aes(x = factor(sites, levels = sitelevels), y = fct_rev(`Species.CommonName`))) + # the fancy stuff around y (`Species-CommonName`) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size=ifelse(Abundance==0, NA, Abundance), fill = `CommonName`), color = "black", pch = 21) +
  scale_size_area(breaks = c(1000,10000,100000,1000000,10000000))+
  xlab("")+
  ylab("")+
  labs(size="Read Abundance", fill = "")+
  theme_bw() +
  scale_fill_manual(values = myColors_comname)+
   theme(axis.title.x=element_blank(), axis.text.x = element_text(size = 11), axis.text.y = element_text(size = 11), legend.position = "bottom") +
  guides(fill="none") +
  facet_grid(~Habitat, scales = "free", space = "free", drop= TRUE)
bubbleplot_comname_2024_expedition_elas_Habitat

ggsave(plot = bubbleplot_comname_2024_expedition_elas_Habitat, filename = "figures-expedition/bubbleplot_comname_2024_expedition_elas_Habitat.eps", width = 10, height = 2.5, units = "in")
```
##### By Bayside and Day-Night
```{r}
# First average replicates at same sites
ps2024_exp_elas_glommed_df_bayside_daynight <- ps2024_exp_elas_glommed_df %>%
    group_by(sites, Bayside_f, Night__Day, CommonName, `Species.CommonName`) %>%
    dplyr::summarize(Abundance = mean(Abundance))
ps2024_exp_elas_glommed_df_bayside_daynight


bubbleplot_comname_2024_expedition_elas_Bayside_DayNight <- ggplot(ps2024_exp_elas_glommed_df_bayside_daynight, aes(x = factor(sites, levels = sitelevels), y = fct_rev(`Species.CommonName`))) + # the fancy stuff around y (`Species-CommonName`) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size=ifelse(Abundance==0, NA, Abundance), fill = `CommonName`), color = "black", pch = 21) +
  scale_size_area(breaks = c(1000,10000,100000,1000000,10000000))+
  xlab("")+
  ylab("")+
  labs(size="Read Abundance", fill = "")+
  theme_bw() +
  scale_fill_manual(values = myColors_comname)+
   theme(axis.title.x=element_blank(), axis.text.x = element_text(size = 11), axis.text.y = element_text(size = 11), legend.position = "bottom") +
  guides(fill="none") +
  facet_grid(Night__Day~Bayside_f, scales = "free", space = "free", drop= TRUE)
bubbleplot_comname_2024_expedition_elas_Bayside_DayNight




ggsave(plot = bubbleplot_comname_2024_expedition_elas_Bayside_DayNight, filename = "figures-expedition/bubbleplot_comname_2024_expedition_elas_Bayside_DayNight.eps", width = 10, height = 4, units = "in")

```

#### CO1

```{r}
# First sort the site names in a sensible way
levels(unique(c(ps2024_exp_co1_glommed_df$sites)))
sitelevels <- as.character(sort(as.numeric(levels(unique(c(ps2024_exp_co1_glommed_df$sites))))))
sitelevels

# Order E-W in sensible way by making it a factor
ps2024_exp_co1_glommed_df$Bayside_f= factor(ps2024_exp_co1_glommed_df$Bayside, levels=c('W','E'))

```


##### By bayside
```{r}
# First average replicates at same sites
ps2024_exp_co1_glommed_df_phyla_bayside <- ps2024_exp_co1_glommed_df %>%
    group_by(sites, Bayside_f, Phylum) %>%
    dplyr::summarize(Abundance = mean(Abundance)) %>% 
  left_join(commonnames, by = c("Phylum" = "Taxon"))


bubbleplot_comname_2024_expedition_co1_Bayside <- ggplot(ps2024_exp_co1_glommed_df_phyla_bayside, aes(x = factor(sites, levels = sitelevels), y = fct_rev(Taxon.CommonName))) + 
  geom_point(aes(size=ifelse(Abundance==0, NA, Abundance), fill = Taxon.CommonName), color = "black", pch = 21) +
  scale_size_area(breaks = c(1000,10000,100000,1000000,10000000))+
  xlab("")+
  ylab("")+
  labs(size="Read Abundance", fill = "")+
  theme_bw() +
  scale_fill_manual(values = myColors_taxcomname)+
   theme(axis.title.x=element_blank(), axis.text.x = element_text(size = 11), axis.text.y = element_text(size = 11), legend.position = "bottom") +
  guides(fill="none") +
  facet_grid(~Bayside_f, scales = "free", space = "free", drop= TRUE)
bubbleplot_comname_2024_expedition_co1_Bayside

# save
ggsave(plot = bubbleplot_comname_2024_expedition_co1_Bayside, filename = "figures-expedition/bubbleplot_comname_2024_expedition_co1_Bayside.eps", width = 9, height = 9.5, units = "in")

ggsave(plot = bubbleplot_comname_2024_expedition_co1_Bayside, filename = "figures-expedition/bubbleplot_comname_2024_expedition_co1_Bayside.jpg", width = 9, height = 9.5, units = "in")
```



## Krona plots
Re-create Krona plots using cleaned up datasets--

Following [this](https://github.com/markschl/embed_krona/blob/main/example.Rmd)
Compatible with phyloseq objects
Must run in the console:
```{r}
source('https://raw.githubusercontent.com/markschl/embed_krona/master/embed_krona.R')
plot_krona(ps2024_exp_mifish_glommed)
plot_krona(ps2024_exp_elas_glommed)
plot_krona(ps2024_exp_co1_glommed)
 
```

Manually changed the names in folder to 
Generates the [MiFish krona plot](krona_files/krona_1.html) and [Elas02 krona plot](krona_files/krona_2.html) as an html file in current working directory. 


#### Save

```{r}
save.image(file = "figures-expedition/exp_ecol_analysis_environment_upto_kronaplots.RData")
```

or load back in
```{r}
load(file = "figures-expedition/exp_ecol_analysis_environment_upto_kronaplots.RData")
```

## Summary stats
### CO1
#### Total species, genera, etc.
```{r}
paste("Unique Species (includes unknown sp with assigned genus, family, etc)")
length(unique(ps2024_exp_co1_glommed_df$Species))

paste("Unique Species (no, unknowns)")
ps2024_exp_co1_glommed_df %>%
  filter(!str_detect(Species, "Unknown")) %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique Genera (includes unknown sp with assigned family, order, etc)")
length(unique(ps2024_exp_co1_glommed_df$Genus))

paste("Unique Genera (no, unknowns)")
ps2024_exp_co1_glommed_df %>%
  filter(!str_detect(Genus, "Unknown")) %>%
  select(Genus) %>%
  unique() %>%
  dim()

paste("Unique Families (includes unknown sp with assigned order, class, etc)")
length(unique(ps2024_exp_co1_glommed_df$Family))

paste("Unique Families (no, unknowns)")
ps2024_exp_co1_glommed_df %>%
  filter(!str_detect(Family, "Unknown")) %>%
  select(Family) %>%
  unique() %>%
  dim()

paste("Unique Orders (includes unknowns)")
length(unique(ps2024_exp_co1_glommed_df$Order))

paste("Unique Orders (no, unknowns)")
ps2024_exp_co1_glommed_df %>%
  filter(!str_detect(Order, "Unknown")) %>%
  select(Order) %>%
  unique() %>%
  dim()

paste("Unique Classes (includes unknowns)")
length(unique(ps2024_exp_co1_glommed_df$Family))

paste("Unique Classes (no, unknowns)")
ps2024_exp_co1_glommed_df %>%
  filter(!str_detect(Class, "Unknown")) %>%
  select(Class) %>%
  unique() %>%
  dim()


paste("Unique Phyla (includes unknowns)")
length(unique(ps2024_exp_co1_glommed_df$Phylum))

paste("Unique Phyla (no, unknowns)")
ps2024_exp_co1_glommed_df %>%
  filter(!str_detect(Phylum, "Unknown")) %>%
  select(Phylum) %>%
  unique() %>%
  dim()

```

#### Inverts
Invertebrate Animal Phyla:

Arthropoda: Includes insects, spiders, crustaceans, and others. They are characterized by exoskeletons and segmented bodies.
Cnidaria: Known for jellyfish, corals, sea anemones, etc., distinguished by their cnidocytes.
Annelida: Segment worms like earthworms and leeches fall under this phylum.
Ctenophora: Also known as comb jellies, they are marine and gelatinous, similar to cnidarians but distinct.
Echinodermata: Sea stars, sea urchins, and their relatives. They are known for their radially symmetrical body plans (in the adult form) and a unique water vascular system.
Rotifera: Rotifers are microscopic, mostly aquatic organisms.
Nemertea: Ribbon worms, which are notable for their proboscis.
Mollusca: This diverse phylum includes snails, slugs, clams, octopuses, and squids, characterized by a muscular foot and mantle.
Porifera: Sponges, simple animals with porous bodies through which water flows.
Platyhelminthes: Flatworms, including both free-living and parasitic varieties.
Bryozoa: Moss animals, small colonial animals mostly found in marine environments.
Onychophora: Velvet worms, small worm-like creatures with numerous stubby legs.
Nematoda: Roundworms, which are ubiquitous in both aquatic and terrestrial environments.
Gastrotricha: Microscopic, worm-like animals mainly found in freshwater and marine environments.
Tardigrada: Water bears or moss piglets, known for their incredible resilience.
Xenacoelomorpha: A recently recognized phylum of simple marine invertebrates.

```{r}
invertebrate_list <- c(
  "Arthropoda",
  "Cnidaria", 
  "Annelida", 
  "Ctenophora", 
  "Echinodermata", 
  "Rotifera", 
  "Nemertea", 
  "Mollusca", 
  "Porifera", 
  "Platyhelminthes", 
  "Bryozoa", 
  "Onychophora", 
  "Nematoda", 
  "Gastrotricha", 
  "Tardigrada", 
  "Xenacoelomorpha", 
  "Entoprocta",
  "Placozoa")
```


```{r}
paste("Unique invertebrates, including unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Phylum %in% invertebrate_list) %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique invertebrates, no unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Phylum %in% invertebrate_list) %>%
  filter(!str_detect(Species, "Unknown")) %>%
  select(Species) %>%
  unique() %>%
  dim()
```
#### Chordates
```{r}
paste("Unique vertebrates, including unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Phylum == "Chordata") %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique vertebrates, no unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Phylum == "Chordata") %>%
  filter(!str_detect(Species, "Unknown")) %>%
  select(Species) %>%
  unique() %>%
  dim()
```
Who are the chordates
```{r}
ps2024_exp_co1_glommed_df %>%
  filter(Phylum == "Chordata") %>%
  select(Class) %>%
  unique()
```


Sea squirts, tunicates, fish, birds, larvaceans, elasmobranchs, amphibians, reptiles. 
Count the fish, birds, elasmos, amphibians, reptiles....
```{r}
paste("Unique teleost fish, including unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Actinopteri") %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique teleost fish, no unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Actinopteri") %>%
  filter(!str_detect(Species, "Unknown")) %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique elasmobranchs, including unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Chondrichthyes") %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique elasmobranchs, no unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Chondrichthyes") %>%
  filter(!str_detect(Species, "Unknown")) %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique birds, including unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Aves") %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique birds, no unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Aves") %>%
  filter(!str_detect(Species, "Unknown")) %>%
  select(Species) %>%
  unique() %>%
  dim()


paste("Unique amphibians, including unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Amphibia") %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique amphibians, no unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Amphibia") %>%
  filter(!str_detect(Species, "Unknown")) %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique reptiles, including unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Lepidosauria") %>%
  select(Species) %>%
  unique() %>%
  dim()

paste("Unique reptiles, no unknowns")
ps2024_exp_co1_glommed_df %>%
  filter(Class == "Lepidosauria") %>%
  filter(!str_detect(Species, "Unknown")) %>%
  select(Species) %>%
  unique() %>%
  dim()


```



# III. Priority Species Maps
Import data and draw map (see CTD notebook for more details)
```{r}
# lets get a box to make a smaller sized objects and facilitate the examples:
geo.box <- c(xmin=-72.61, xmax=-72.4, ymin=40.79, ymax=40.9)

sf_use_s2(FALSE)

# Shoreline data for us detail
gshhg.l1 <- sf::read_sf("raw_data/gshhg-shp-2.3.7/GSHHS_shp/f/GSHHS_f_L1.shp") %>% st_crop(geo.box)
plot(gshhg.l1["id"])

# make ggplot object
shinnbay_map <- ggplot(data = gshhg.l1) +
  geom_sf(aes(geometry = geometry)) +
    scale_x_continuous(breaks = seq(-72.6, -72.4, 0.1)) +
    scale_y_continuous(breaks = seq(40.80, 40.9, 0.05))

shinnbay_map

```

Define a single helper function for plotting + saving so all plots have same scale

```{r}
plot_rel_abund <- function(
  df, colour, title, outname,
  limits     = c(0.1, 10),               # fixed scale across all plots
  breaks     = c(0.1, 0.5, 1, 5, 10),    # ~5 legend bubbles
  size_range = c(2, 12),              # same visual min/max bubble size
  map_object = shinnbay_map
) {
  df2 <- df %>%
    dplyr::filter(!is.na(long), !is.na(lat), !is.na(AverageRelativeAbundancePercent)) %>%
    dplyr::mutate(
      size_var = pmin(pmax(AverageRelativeAbundancePercent, limits[1]), limits[2]) 
    )

  # custom labels: endpoints show  and 
  lims <- limits
  lab_fun <- function(x) {
    out <- scales::label_number(accuracy = 0.1)(x)
    out[x <= lims[1] + 1e-12] <- paste0("\u2264 ", lims[1])  #  0.1
    out[x >= lims[2] - 1e-12] <- paste0("\u2265 ", lims[2])  #  10
    out
  }

  p <- map_object +
    ggplot2::geom_point(
      data = df2,
      ggplot2::aes(x = long, y = lat, size = size_var),
      alpha = 0.6, color = colour
    ) +
    ggplot2::scale_size_continuous(
      name   = "Avg. Relative\nAbundance (%)",
      limits = limits,
      breaks = breaks,
      labels = lab_fun,
      range  = size_range
    ) +
    ggplot2::guides(size = ggplot2::guide_legend(override.aes = list(alpha = 1))) +
    ggplot2::theme_minimal() +
    ggplot2::labs(title = title, x = "Longitude", y = "Latitude")

  ggplot2::ggsave(glue::glue("figures-expedition/{outname}.eps"), p, width = 8, height = 6, units = "in")
  ggplot2::ggsave(glue::glue("figures-expedition/{outname}.jpg"), p, width = 8, height = 6, units = "in")

  invisible(p)
}

```

### a. MiFish: Top Species
#### Prepare data
Group MiFish species abundance by station
```{r}
# Average replicates at same sites
ps2024_exp_mifish_glommed_df_bystation <- ps2024_exp_mifish_glommed_df %>%
    group_by(sites, Species.CommonName) %>%
    dplyr::summarize(Abundance = mean(Abundance)) %>% 
  left_join(commonnames_mod, by = c("Species.CommonName" = "Taxon.CommonName"))

# Calculate relative abundances across the whole dataset
ps2024_exp_mifish_glommed_df_bystation <- ps2024_exp_mifish_glommed_df_bystation %>%
  group_by(sites) %>%
  mutate(RelativeAbundance = Abundance / sum(Abundance))


# Calculate relative abundances across the whole dataset
exp_mifish_species_abundance <- exp_mifish_species_abundance %>%
  mutate(RelativeAbundance = TotalAbundance / sum(TotalAbundance))


# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
ps2024_exp_mifish_glommed_df_bystation <- ps2024_exp_mifish_glommed_df_bystation %>%
  left_join(stationdata, by = c("sites" = "sites"))


ps2024_exp_mifish_glommed_df_bystation

```


#### Plot
Plot only top species, same as those from `trawl_mifish_species_abundance`
```{r}
# First create a dummy plot to extract the legend
legend_plot <- ggplot(ps2024_exp_mifish_glommed_df_bystation %>% filter(Species.CommonName %in% exp_mifish_species_abundance$Species.CommonName),
                      aes(x = sites, y = RelativeAbundance, fill = Species.CommonName)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = myColors_taxcomname) +
  theme_minimal() +
  theme(legend.position = "right",  #right is the only one that works later with get_legend
        legend.title = element_blank()) + 
  guides(fill = guide_legend(ncol = 2))


# Create a list of mini barplots for each site
mini_barplots_mifish <- ps2024_exp_mifish_glommed_df_bystation %>%
  group_by(sites) %>%
  filter(Species.CommonName %in% exp_mifish_species_abundance$Species.CommonName) %>%
  group_split() %>%
  setNames(unique(ps2024_exp_mifish_glommed_df_bystation$sites)) %>%
  lapply(function(df_site) {
    ggplot(df_site, aes(x = sites, y = Abundance, fill = Species.CommonName)) +
      geom_bar(stat = "identity") +
      theme_void() +
      theme(legend.position = "none") +
      scale_fill_manual(values = myColors_taxcomname)})

# Prepare a summary table of one row per site with lat/long and the mini-plot
site_coords <- ps2024_exp_mifish_glommed_df_bystation %>%
  group_by(sites, lat, long) %>%
  summarise(.groups = "drop") %>%
  mutate(plot = mini_barplots_mifish[as.character(sites)])

# Grab legend from top species plot
fish_legend <- cowplot::get_legend(legend_plot)
cowplot::ggdraw(fish_legend)

# Add to base map
map_with_subplots <- shinnbay_map +
  ggimage::geom_subview(
    data = site_coords,
    aes(x = long, y = lat, subview = plot),
    width = 0.0085, height = 0.0085  # adjust size as needed
  )

# 4. Combine map and legend
mifish_map <- cowplot::plot_grid(
  map_with_subplots,
  fish_legend,
  ncol = 1,
  rel_heights = c(.9, 0.3)  # adjust the space for legend
)

mifish_map

  
ggsave("figures-expedition/mifish_expedition_topspecies_map.eps", plot = mifish_map, width = 8, height = 6, units = "in")
ggsave("figures-expedition/mifish_expedition_topspecies_map.jpg", plot = mifish_map, width = 8, height = 6, units = "in")

```



### b. Aureococcus
#### Prepare data
```{r}
# Calculate relative abundance of Aureococcus anophagefferens per Site
aureo_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            AureococcusCounts = sum(Species == "Aureococcus anophagefferens")) %>%
  mutate(RelativeAbundance = AureococcusCounts / TotalCounts) %>%
  select(-TotalCounts, -AureococcusCounts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot


# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
aureo_relative_abundance_df <- aureo_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


aureo_relative_abundance_df

```

#### Plot Aureococcus map
```{r}
# Assuming shinn_bay is a ggplot object, add points for relative abundance
shinn_bay_aureococcus <- shinnbay_map +
  geom_point(data = aureo_relative_abundance_df, aes(x = long, y = lat, size = AverageRelativeAbundancePercent), alpha = 0.6, color = "brown") +
  scale_size_continuous(name = "Average Relative\nAbundance (%)", range = c(0.25, 12)) +
  theme_minimal() +
labs(title = expression("Relative Abundance, " * italic("Aureococcus anophagefferens") * " CO1 Reads"),
       x = "Longitude", y = "Latitude")

shinn_bay_aureococcus



ggsave("figures-expedition/aureococcus_map.eps", plot = shinn_bay_aureococcus, width = 8, height = 6, units = "in")
ggsave("figures-expedition/aureococcus_map.jpg", plot = shinn_bay_aureococcus, width = 8, height = 6, units = "in")

```


### b. Bivalves
#### Prepare data
```{r}
# Calculate relative abundance per Site
bivalves_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Class == "Bivalvia")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot


# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
bivalves_relative_abundance_df <- bivalves_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


bivalves_relative_abundance_df

```


#### Plot map
```{r}
# Assuming shinn_bay is a ggplot object, add points for relative abundance
shinn_bay_bivalves <- shinnbay_map +
  geom_point(data = bivalves_relative_abundance_df, aes(x = long, y = lat, size = AverageRelativeAbundancePercent), alpha = 0.6, color = "grey2") +
  scale_size_continuous(name = "Average Relative\nAbundance (%)", range = c(0.25, 12)) +
  theme_minimal() +
labs(title = expression("Relative Abundance, " * italic("Bivalve") * " CO1 Reads"),
       x = "Longitude", y = "Latitude")

shinn_bay_bivalves



ggsave("figures-expedition/bivalves_map.eps", plot = shinn_bay_bivalves, width = 8, height = 6, units = "in")
ggsave("figures-expedition/bivalves_map.jpg", plot = shinn_bay_bivalves, width = 8, height = 6, units = "in")

```




### b3. Other bivalves
(minus eastern oyster and hard clam, plotted below)
#### Prepare data
```{r}
# Calculate relative abundance per Site
otherbivalves_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  filter(Class == "Bivalvia", 
         !Species %in% c("Mercenaria mercenaria", "Crassostrea virginica")) %>%
  group_by(sites) %>%
  summarise(TotalCounts = n()) %>%
  left_join(ps2024_exp_co1_glommed_df %>%
              group_by(sites) %>%
              summarise(TotalSpeciesCount = n()), by = "sites") %>%
  mutate(RelativeAbundance = TotalCounts / TotalSpeciesCount) %>%
  select(sites, RelativeAbundance) %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance) * 100) %>%
  filter(AverageRelativeAbundancePercent > 0)


# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
otherbivalves_relative_abundance_df <- otherbivalves_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


otherbivalves_relative_abundance_df

```


#### Plot map
```{r}
# Assuming shinn_bay is a ggplot object, add points for relative abundance
shinn_bay_otherbivalves <- shinnbay_map +
  geom_point(data = otherbivalves_relative_abundance_df, aes(x = long, y = lat, size = AverageRelativeAbundancePercent), alpha = 0.6, color = "grey3") +
  scale_size_continuous(name = "Average Relative\nAbundance (%)", range = c(0.25, 12)) +
  theme_minimal() +
labs(title = expression("Relative Abundance, other " * italic("Bivalvia") * ", CO1 Reads"),
       x = "Longitude", y = "Latitude")

shinn_bay_otherbivalves



# what are they? 
otherbivalveslist <- ps2024_exp_co1_glommed_df %>%
  filter(Class == "Bivalvia", 
         !Species %in% c("Mercenaria mercenaria", "Crassostrea virginica")) %>%
  distinct(Species) %>%
  filter(!str_starts(Species, "Unknown")) %>%
  arrange(Species) %>%
  bind_rows(tibble(Species = "Unknown bivalves")) 
otherbivalveslist



ggsave("figures-expedition/otherbivalves_map.eps", plot = shinn_bay_otherbivalves, width = 8, height = 6, units = "in")
ggsave("figures-expedition/otherbivalves_map.jpg", plot = shinn_bay_otherbivalves, width = 8, height = 6, units = "in")

# also save list of other bivalve names
write.csv(otherbivalveslist, "figures-expedition/otherbivalves_names.csv", row.names = FALSE)



```


### c. Eelgrass wasting diseases (EWD)

See [review](https://pmc.ncbi.nlm.nih.gov/articles/PMC6445351/#:~:text=Human%2Dinduced%20global%20change%20is,under%20future%20global%20change%20scenarios.) and specifically table 1.

- No hits to Labyrinthula zosterae, the known agent of eelgrass wasting disease, nor to anything in the class Labyrinthulae.
- No hits to Phytomyxea, the class containing pathogenic Plasmodiophora species.
- There are many hits to Pythiales, an order of water molds in the Oomycetes that contains potential pathogens (including Halophytophthora. Note there are no hits to Phytophthora species or Halophytophthora zostera specifically so these are POTENTIALLY pathogens).

#### Prepare data
```{r}
# Calculate relative abundance  per Site
EWD_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Order == "Pythiales")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
EWD_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
EWD_relative_abundance_df <- EWD_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


EWD_relative_abundance_df

```


#### Plot map
```{r}
# Assuming shinn_bay is a ggplot object, add points for relative abundance
shinn_bay_EWD <- shinnbay_map +
  geom_point(data = EWD_relative_abundance_df, aes(x = long, y = lat, size = AverageRelativeAbundancePercent), alpha = 0.6, color = "green3") +
  scale_size_continuous(name = "Average Relative\nAbundance (%)", range = c(0.25, 12)) +
  theme_minimal() +
labs(title = expression("Relative Abundance, " * italic("Pythiales") * ", Potential Eelgrass Wasting Disease, CO1 Reads"),
       x = "Longitude", y = "Latitude")

shinn_bay_EWD



ggsave("figures-expedition/eelgrassdisease_map.eps", plot = shinn_bay_EWD, width = 8, height = 6, units = "in")
ggsave("figures-expedition/eelgrassdisease_map.jpg", plot = shinn_bay_EWD, width = 8, height = 6, units = "in")

```

### d. Invasives

Downloaded list of NY state aquatic invasives from [here](https://www.nynhp.org/invasives/species-tiers-table/). Get list and clean up:

```{r}
NYinvasiveslist <- read_csv(file = "../eDNA-databases/NewYorkInvasives.csv")

NYinvasiveslist <- NYinvasiveslist %>%
  select("Common Name","Scientific Name") %>%
  rename(
    CommonName = "Common Name",
    SciName    = "Scientific Name"
  ) %>%
  mutate(
    # strip any parenthetical remark
    SciClean = str_remove(SciName, "\\s*\\(.*$"),
    ## 1) pull off the genus
    Genus    = str_extract(SciClean, "^[A-Z][a-z]+"),
    ## 2) try to extract a bonafide "Genus species" pair
    sp_pair  = str_extract(SciClean,
                          "^[A-Z][a-z]+(?: x)? [a-z]+"
    ) %>%
      str_replace("^([A-Z][a-z]+) x ([a-z]+)$", "\\1 \\2"),
    ## 3) now collapse into a single clean key
    Species  = case_when(
      str_detect(SciClean, regex("\\bsp(p)?\\.", ignore_case=TRUE)) ~ 
        paste("Unknown", Genus, "(Genus)"),
      !is.na(sp_pair)                                               ~ sp_pair,
      TRUE                                                          ~ paste("Unknown", Genus, "(Genus)")
    )
  ) %>%
  select(-SciClean, -sp_pair)

NYinvasiveslist
```

Cross check with 3 libraries:

```{r}
invasives_detected <- bind_rows(
  ps2024_exp_elas_glommed_df  %>% mutate(Library = "Elas02"),
  ps2024_exp_mifish_glommed_df %>% mutate(Library = "MiFish"),
  ps2024_exp_co1_glommed_df    %>% mutate(Library = "CO1")
) %>%
  distinct(Library, Species) %>%
  mutate(
    Detected = str_extract(Species, "^[A-Z][a-z]+ [a-z]+")
  ) %>%
  inner_join(
    NYinvasiveslist,
    by = c("Detected" = "Species")
  ) %>%
  select(Library, Genus, Species, Detected)


invasives_detected


```

--> 8 invasive detected, all from the CO1 library. 


Also check for invasive genera, that may be in my database as Unkown species, for example:

```{r}
detected_lookup <- bind_rows(
  ps2024_exp_elas_glommed_df  %>% mutate(Library="Elas02"),
  ps2024_exp_mifish_glommed_df %>% mutate(Library="MiFish"),
  ps2024_exp_co1_glommed_df    %>% mutate(Library="CO1")
) %>%
  distinct(Library, Genus, Species) %>%
  group_by(Library, Genus) %>%
  summarise(
    DetectedSpecies = str_c(sort(unique(Species)), collapse = "; "),
    .groups="drop"
  )

invasive_lookup <- NYinvasiveslist %>%
  distinct(Genus, Species) %>%
  group_by(Genus) %>%
  summarise(
    InvasiveSpecies = str_c(sort(unique(Species)), collapse = "; "),
    .groups="drop"
  )

invasive_genera_detected_full <- invasive_genera_detected %>%
  left_join(detected_lookup, by = c("Library","Genus")) %>%
  left_join(invasive_lookup, by = "Genus") %>%
  select(Library, Genus, DetectedSpecies, InvasiveSpecies)

invasive_genera_detected_full

```

Additional plots to make in addition to the specific Species:

- Unknown Grateloupia (Genus) is very likely Grateloupia turuturu. I can't find much on any native species from this genus
- The invasive, Botrylloides violaceus, was not detected however, Unknown Botrylloides (Genus) was detected and it seems that there [may not be native Botrylloides species](https://invasions.si.edu/nemesis/species_summary/-100).
- The Unknown Cryptosula genus may likely be Cryptosula pallasiana, however, its "cryptic" and its status as an invasive on east coast is unclear so skip this one.
- Genus Bugula was detected, but there are native species such as Bugulina stolonifera, so it may not be the invasive Bugula neritina. Skip this one
- Genus Pseudogymnoascus was detected and it contains the invasive fungus Pseudogymnoascus destructans, causing white nose syndrome in bats, but [it is a diverse genus](https://www.frontiersin.org/journals/microbiology/articles/10.3389/fmicb.2021.713189/full) and likely we can't point to that Species specifically




### d1. Invasives: Halichondria bowerbanki (Yellow sun sponge)

[Smithosonian site](https://invasions.si.edu/nemesis/species_summary/48398) says it is native to east coast but NY database considers it invasive. List it as potential


#### Prepare data
```{r}
# Calculate relative abundance  per Site
Hbowerbanki_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Halichondria bowerbanki")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Hbowerbanki_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Hbowerbanki_relative_abundance_df <- Hbowerbanki_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Hbowerbanki_relative_abundance_df

```


#### Plot map
```{r}
shinn_bay_Hbowerbanki <- plot_rel_abund(
  df     = Hbowerbanki_relative_abundance_df,
  colour = "yellow3",
  title  = expression("Invasive: Yellow sun sponge (" * italic("Halichondria bowerbanki") * "), CO1 reads"),
  outname= "shinn_bay_Hbowerbanki"
)
shinn_bay_Hbowerbanki

```




### d2. Invasives: Gracilaria vermiculophylla (Worm Wart Weed)
From [source](https://www.deq.nc.gov/energy-mineral-and-land-resources/land-resources/publications/technical-paper-series/tech-6-invasive-species-gracilaria-vermiculophylla/download):

Gracilaria vermiculophylla is a highly branched rhodophyte, or red algae, indigenous to the coast of the Pacific Northwest. It easily recruits to hard substrates such as oyster and other shell material and fragmented specimens recover well and travel easily. This exotic is thought to have arrived to the U.S. East Coast near the Chesapeake Bay via Asian oysters imported into Virginia, or through ballast water transport. G. vermiculophylla is now considered an established invasive species along both coasts of North America and parts of central Europe.

#### Prepare data
```{r}
# Calculate relative abundance  per Site
Gvermiculophylla_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Gracilaria vermiculophylla")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Gvermiculophylla_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Gvermiculophylla_relative_abundance_df <- Gvermiculophylla_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Gvermiculophylla_relative_abundance_df

```


#### Plot map
```{r}
shinn_bay_Gvermiculophylla <- plot_rel_abund(
  df     = Gvermiculophylla_relative_abundance_df,
  colour = "red4",
  title  = expression("Invasive: Worm Wart Weed (" * italic("Gracilaria vermiculophylla") * "), CO1 reads"),
  outname= "shinn_bay_Gvermiculophylla"
)
shinn_bay_Gvermiculophylla
```





### d3. Invasives: Styela canopus (Rough Sea squirt)


#### Prepare data
```{r}
# Calculate relative abundance  per Site
Scanopus_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Styela canopus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Scanopus_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Scanopus_relative_abundance_df <- Scanopus_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Scanopus_relative_abundance_df

```


#### Plot map
```{r}
shinn_bay_Scanopus <- plot_rel_abund(
  df     = Scanopus_relative_abundance_df,
  colour = "burlywood",
  title  = expression("Invasive: Rough Sea squirt (" * italic("Styela canopus") * "), CO1 reads"),
  outname= "shinn_bay_Scanopus"
)
shinn_bay_Scanopus


```




### d4. Invasives: Carcinus maenas (Green crab)

From [source](https://dec.ny.gov/nature/animals-fish-plants/green-crab): Predation and Competition: In New York, green crabs consume native bivalves (e.g., blue mussels) and other invertebrates and compete with native crabs for food and habitat. However, the relative ecological impact of green crabs in New York has declined due to the arrival of another non-native species, the shore crab (Hemigraspus sanguineus). Since the arrival of the shore crab in the 1990s, shore crabs have partially displaced green crabs in rocky intertidal habitats.

#### Prepare data
```{r}
# Calculate relative abundance  per Site
Cmaenas_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Carcinus maenas")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Cmaenas_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Cmaenas_relative_abundance_df <- Cmaenas_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Cmaenas_relative_abundance_df

```




#### Plot map
```{r}
shinn_bay_Cmaenas <- plot_rel_abund(
  df     = Cmaenas_relative_abundance_df,
  colour = "green4",
  title  = expression("Invasive: Green crab (" * italic("Carcinus maenas") * "), CO1 reads"),
  outname= "shinn_bay_Cmaenas"
)
shinn_bay_Cmaenas

```

### d5. Invasives: Didemnum vexillum (carpet tunicate)

From [source](https://invasions.si.edu/nemesis/species_summary/-334):
Didemnum vexillum is a rapidly spreading colonial tunicate that overgrows rocks, shellfish, and other organisms (e.g. sponges, hydroids, tunicates, algae). It probably originated from the Northwest Pacific, possibly Japan, but has been reported in several parts of the world including New Zealand, North America, and Europe. Its identification in these introduced areas had been debated, but recent genetic and morphological studies confirmed that many of these global populations are D. vexillum. Its first known occurrence on the East Coast of the US was in Damariscotta River estuary, Maine in 1982. It is now common from Shinnecock Inlet, New York to Eastport, Maine. 

From [NYS DEC](https://dec.ny.gov/nature/invasive-species/aquatic/marine):
The carpet tunicate is an aggressive and fast spreading invasive species whose first known occurrence was in Maine in 1982. It is now common between Eastport, Maine to the South shore of Long Island. It was most likely introduced by means of ship hull fouling.
Colonies of the carpet tunicate are blob-like and yellowish-cream in color and have a firm, leathery texture and a veined or marbled appearance. Their large, sponge-like masses often have long, flexible leaf or flag-like projections that are cylindrical and branched. Because they are filter feeders, numerous small pores can be identified on the surface of the colony and appear as tiny, white colored spots when closed.
This invasive species grows rapidly and forms dense colonies that can cause both ecological and economic damage. Overgrowth of this species can smother and reduce the abundance of previously established, native benthic organisms. The carpet tunicate can attach and encrust nearly any substrate it encounters, altering benthic environments and completely changing the habitat structure. The carpet tunicate has the potential to cause economic damage to various fisheries and aquacultures that include bottom fish, scallops, lobsters and mussels.


#### Prepare data
```{r}
# Calculate relative abundance  per Site
Dvexillum_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Didemnum vexillum")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Dvexillum_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Dvexillum_relative_abundance_df <- Dvexillum_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Dvexillum_relative_abundance_df

```


#### Plot map
```{r}
shinn_bay_Dvexillum <- plot_rel_abund(
  df     = Dvexillum_relative_abundance_df,
  colour = "gold4",
  title  = expression("Invasive: Carpet tunicate (" * italic("Didemnum vexillum") * "), CO1 reads"),
  outname= "shinn_bay_Dvexillum"
)
shinn_bay_Dvexillum

```


### d6. Invasives: Botryllus schlosseri (Golden star tunicate)

From [source](https://www.jstor.org/stable/pdf/24866162.pdf):
According to Van Name (1945), Botryllus schlosseri was probably introduced to the east coast of North America prior to the 1830s, presumably through European shipping traffic.

From [source](https://invasions.si.edu/nemesis/species_summary/159373#:~:text=In%20the%20lower%20Chesapeake%20Bay,where%20it%20can%20grow%20rapidly.): The origin of the Golden Star Tunicate, Botryllus schlosseri, is uncertain. It is globally widespread and found on the temperate coasts of Europe, Asia, both sides of North America, Chile, Argentina, South Africa, Australia and oceanic islands such as Bermuda, the Azores and New Zealand. It is common in fouling communities and has likely spread globally through shipping, oyster culture and other aquaculture transfers. In the lower Chesapeake Bay, B. schlosseri is a fouling pest impacting oyster aquaculture, but not natural oyster beds. In some areas of its introduced range, there is concern that B. schlosseri competes with native species for space, especially on artificial substrates where it can grow rapidly.


#### Prepare data
```{r}
# Calculate relative abundance  per Site
Bschlosseri_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Botryllus schlosseri")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Bschlosseri_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Bschlosseri_relative_abundance_df <- Bschlosseri_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Bschlosseri_relative_abundance_df

```

#### Plot map
```{r}
shinn_bay_Bschlosseri <- plot_rel_abund(
  df     = Bschlosseri_relative_abundance_df,
  colour = "gold2",
  title  = expression("Invasive: Golden star tunicate (" * italic("Botryllus schlosseri") * "), CO1 reads"),
  outname= "shinn_bay_Bschlosseri"
)
shinn_bay_Bschlosseri

```

### d7: Diadumene lineata (Orange-Striped Anemone)

#### Prepare data
```{r}
# Calculate relative abundance  per Site
Dlineata_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Diadumene lineata")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Dlineata_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Dlineata_relative_abundance_df <- Dlineata_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Dlineata_relative_abundance_df

```


#### Plot map
```{r}
# Assuming shinn_bay is a ggplot object, add points for relative abundance
shinn_bay_Dlineata <- plot_rel_abund(
  df     = Dlineata_relative_abundance_df,
  colour = "darkorange",
  title  = expression("Invasive: Orange-striped anemone (" * italic("Diadumene lineata") * "), CO1 reads"),
  outname= "shinn_bay_Dlineata"
)
shinn_bay_Dlineata

```


### d8: Cygnus olor (Mute swan)

#### Prepare data
```{r}
# Calculate relative abundance  per Site
Color_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Cygnus olor")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Color_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Color_relative_abundance_df <- Color_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Color_relative_abundance_df

```


#### Plot map
```{r}
shinn_bay_Color <- plot_rel_abund(
  df     = Color_relative_abundance_df,
  colour = "black",
  title  = expression("Invasive: Mute swan (" * italic("Cygnus olor") * "), CO1 reads"),
  outname= "shinn_bay_Color"
)
shinn_bay_Color

```


### d9. Potential Invasive: Grateloupia genus (Grateloupia turuturu - Devil's Tongue Weed)

From [NYS DEC site on invasives](https://dec.ny.gov/nature/invasive-species/aquatic/marine): 
The devil's tongue weed is one of the largest known red algae. Native to the Northwest Pacific, it was first reported in Rhode Island in 1996 and is typically found in a wide range of coastal habitats. This species survives in both cold and warm temperate regions, native and artificial habitats, and grows on a variety of substrates including bedrock, cobbles, boulders, shells and even ship hulls. It is believed to have been introduced by ballast water or hull fouling.

The devil's tongue weed is a large seaweed that has a deep red, burgundy or maroon color, but can appear yellowish when dying. Blades of this plant vary in size and shape and can be irregularly divided, ranging from one to eight blades that can reach up to 15 cm in width and over 1 meter in length. The blades transition into a short, narrow, cylindrical stem that attaches to a substrate with a small, disk-shaped holdfast. The plant is thick and firm and the blades can be slippery and have a gelatinous texture.

This invasive species outcompetes native algae species and can alter benthic biodiversity. Additionally, observations of devil's tongue weed on the East Coast, in regions including Long Island Sound, suggest that this species supports fewer biological organisms, such as epiphytes and invertebrates, compared to the local red alga, Chondrus crispus.

Note- Grateloupia was IDed to the genus level only but I can't find any reference to native Grateloupia species

#### Prepare data
```{r}
# Calculate relative abundance  per Site
Grateloupia_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Genus == "Grateloupia")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Grateloupia_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Grateloupia_relative_abundance_df <- Grateloupia_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Grateloupia_relative_abundance_df

```


#### Plot map
```{r}
shinn_bay_Grateloupia <- plot_rel_abund(
  df     = Grateloupia_relative_abundance_df,
  colour = "red2",
  title  = expression("Potential Invasive: " * italic("Grateloupia") * ", Genus containing Devil's Tongue Weed ("  * italic("G. turuturu") * "), CO1 reads"),
  outname= "shinn_bay_Grateloupia"
)
shinn_bay_Grateloupia
```


### d10. Potential Invasive: Botrylloides genus (Botrylloides violaceus- Orange Sheath Tunicate)
Botrylloides was IDed to the genus level only but I can't find any reference to native Botrylloides species

#### Prepare data
```{r}
# Calculate relative abundance  per Site
Botrylloides_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Genus == "Botrylloides")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Botrylloides_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Botrylloides_relative_abundance_df <- Botrylloides_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Botrylloides_relative_abundance_df

```


#### Plot map
```{r}
shinn_bay_Botrylloides <- plot_rel_abund(
  df     = Botrylloides_relative_abundance_df,
  colour = "darkorange3",
  title  = expression("Potential Invasive: " * italic("Botrylloides") * ", Genus containing Orange Sheath Tunicate ("  * italic("B. violaceus") * "), CO1 reads"),
  outname= "shinn_bay_Botrylloides"
)
shinn_bay_Botrylloides


```




### d11. Other detected invasives (not plotted):

- Mytilus trossulus: Pacific blue mussel, was detected. Native range is northern Pacific, California to Alaska. It is not native however found in many places and forms hybrids with native species, M. edulis, so this could also be a misidentification(?). Conservatively don't label as invasive.

- Checked for other invasives but were not found:
  -  From [DEC site](https://dec.ny.gov/nature/invasive-species/aquatic/marine) and some mentioned [here](https://lispartnership.org/2021/02/aquatic-invaders-of-the-sound/))
  - Asian Shore Crab- Hemigrapsus sanguineus, Asian Sea Squirt- Styela clava, Chinese Mitten Crab- Eriocheir sinensis, Veined Rapa Whelk- Rapana venosa, Dungeness Crab- Metacarcinus magister, European Rock Shrimp, Palaemon elegans, Siphoned Feather Weed, Oyster Thief- Codium Fragile, Dasysiphonia japonica, Wakame- Undaria pinnatifida, and Asian Horseshoe Crabs- genus Tachypleus and Carcinoscorpius


### d12. Figure for manuscript
Stack 3 invasive species maps for main text (rest will go in Supp)
```{r}
# function for adding inset
add_inset_title <- function(p, label,
                            hjust = -0.25, vjust = 2.7,
                            size = 4.2, offset = 1.0) {
  parts <- strsplit(label, "\n", fixed = TRUE)[[1]]
  line1 <- parts[1]
  line2 <- if (length(parts) >= 2) parts[2] else ""

  p <- p + labs(title = NULL)

  p <- p + annotate(
    "text", x = -Inf, y = Inf,
    hjust = hjust, vjust = vjust,
    label = line1, parse = FALSE,
    size = size, fontface = "italic", lineheight = 1.1
  )

  if (nzchar(line2)) {
    p <- p + annotate(
      "text", x = -Inf, y = Inf,
      hjust = hjust, vjust = vjust + offset,  # increase this if they overlap
      label = line2, parse = FALSE,
      size = size, fontface = "plain", lineheight = 1.1
    )
  }

  p
}

tight_theme <- theme(
  plot.margin       = margin(0, 0, 0, 0),
  legend.margin     = margin(0, 0, 0, 0),
  legend.box.margin = margin(0, 0, 0, 0),
  panel.spacing     = unit(0, "pt")
)

# Build from DATA (not from the prebuilt shinn_bay_* objects)
# These assume your base map object `shinnbay_map` already has coord_sf().
g1_base <- shinnbay_map +
  geom_point(
    data = Gvermiculophylla_relative_abundance_df,
    aes(x = long, y = lat, size = AverageRelativeAbundancePercent),
    alpha = 0.6, colour = "red4"
  ) +
  labs(x = NULL, y = NULL) + 
  tight_theme

g2_base <- shinnbay_map +
  geom_point(
    data = Hbowerbanki_relative_abundance_df,
    aes(x = long, y = lat, size = AverageRelativeAbundancePercent),
    alpha = 0.6, colour = "yellow3"
  ) +
  labs(x = NULL, y = "Latitude") + 
  tight_theme

g3_base <- shinnbay_map +
  geom_point(
    data = Scanopus_relative_abundance_df,
    aes(x = long, y = lat, size = AverageRelativeAbundancePercent),
    alpha = 0.6, colour = "burlywood"
  ) +
  labs(x = "Longitude", y = NULL) + 
  tight_theme

# Add inset titles
g1 <- add_inset_title(g1_base, "Gracilaria vermiculophylla\nWorm Wart Weed",
                      vjust = 2.5, offset = 1.4)
g2 <- add_inset_title(g2_base, "Halichondria bowerbanki\nYellow sun sponge",
                      vjust = 2.5, offset = 1.4)
g3 <- add_inset_title(g3_base, "Styela canopus\nRough sea squirt",
                      vjust = 2.5, offset = 1.4)

# Stack with ONE shared legend; apply the shared size scale to all via '&'
combined_maps <- (g1 / g2 / g3) +
  plot_layout(ncol = 1, guides = "collect") &
  size_scale_fixed &
  guides(size = guide_legend(override.aes = list(colour = "black"))) &
  theme(legend.position = "right")

combined_maps

# save
ggsave("figures-expedition/combined_invasives_threepanel.eps",combined_maps, width = 8, height = 20, units = "in")
ggsave("figures-expedition/combined_invasives_threepanel.jpg",combined_maps, width = 8, height = 20, units = "in")
 
 # cut the white space
image_read("figures-expedition/combined_invasives_threepanel.jpg") |>
  image_trim() |>
  image_write("figures-expedition/combined_invasives_threepanel.jpg")
 

image_read("figures-expedition/combined_invasives_threepanel.eps") |>
  image_trim() |>
  image_write("figures-expedition/combined_invasives_threepanel.eps")

```



### e. Endangered/ Vulnerables/ Special Concern/ Etc

#### NY State List
Downloaded list of NY state Endangered species from [here](https://dec.ny.gov/nature/animals-fish-plants/biodiversity-species-conservation/endangered-species/list). Get list and clean up:


```{r}
NYendangeredslist <- read_csv(file = "../eDNA-databases/NewYorkEndangeredsEtc.csv")

NYendangeredslist <- NYendangeredslist %>%
  rename(Species = ScientificName) %>%
  mutate(Genus = str_extract(Species, "^[A-Z][a-z]+")) %>%
  relocate(Genus, .after = Species)

NYendangeredslist
```

Cross check with 3 libraries:

```{r}
endangereds_detected <- bind_rows(
  ps2024_exp_elas_glommed_df  %>% mutate(Library = "Elas02"),
  ps2024_exp_mifish_glommed_df %>% mutate(Library = "MiFish"),
  ps2024_exp_co1_glommed_df    %>% mutate(Library = "CO1")
) %>%
  distinct(Library, Species) %>%
  mutate(
    Detected = str_extract(Species, "^[A-Z][a-z]+ [a-z]+")
  ) %>%
  inner_join(
    NYendangeredslist,
    by = c("Detected" = "Species")
  ) %>%
  select(Library, Genus, Species, Detected)


endangereds_detected


```

--> 10 detections.  Anguilla rostrata and Tautoga onitis and Syngnathus fuscus detected by both MiFish and CO1. Megaptera novaeangliae and Pseudopleuronectes americanus by MiFish. Mercenaria mercenaria and 	Crassostrea virginica by CO1

--> Note roughtail sting ray didn't come out bc NY DEC has old name, Dasyatis centroura

#### IUCN List

Also check against IUCN Red List.
Set up and get API key, [instructions](https://github.com/ropensci/rredlist)
Use `rredlist::rl_use_iucn()` for instructions on modifying Renviron file

DO NOT RERUN UNLESS NECESSARY
this pings the API

```{r}

# build & clean species list (binomials only)
all_species <- bind_rows(
  ps2024_exp_elas_glommed_df  %>% mutate(Library = "Elas02"),
  ps2024_exp_mifish_glommed_df %>% mutate(Library = "MiFish"),
  ps2024_exp_co1_glommed_df    %>% mutate(Library = "CO1")
) %>%
  distinct(Species) %>%
  # strip anything weird, keep letters / spaces / hyphens
  mutate(Species = Species %>%
           str_replace_all("[^A-Za-z\\-\\s]", " ") %>%
           str_squish()) %>%
  # keep only Genus species (no subspp., no "Unknown ...")
  filter(str_detect(Species, "^[A-Z][a-z]+\\s+[a-z\\-]+$")) %>%
  pull(Species) %>%
  unique()

length(all_species)  # sanity check

# function for single-species lookup
lookup_iucn_v4 <- function(sciname, sleep_sec = 1.5) {
  nm <- str_squish(sciname)
  m  <- str_match(nm, "^([A-Z][a-z]+)\\s+([a-z\\-]+)$")
  if (is.na(m[1,1])) {
    return(tibble(scientificName = nm,
                  iucn_category = NA_character_,
                  iucn_id = NA_integer_))
  }
  genus   <- m[1,2]
  species <- m[1,3]

  out_latest <- tryCatch(rl_species_latest(genus, species), error = function(e) NULL)
  df <- NULL
  if (!is.null(out_latest) &&
      !is.null(out_latest$assessments) &&
      nrow(out_latest$assessments) > 0) {
    df <- out_latest$assessments
  } else {
    out_all <- tryCatch(rl_species(genus, species), error = function(e) NULL)
    if (!is.null(out_all) &&
        !is.null(out_all$assessments) &&
        nrow(out_all$assessments) > 0) {
      df <- out_all$assessments
    }
  }

  if (is.null(df) || nrow(df) == 0) {
    Sys.sleep(sleep_sec)
    return(tibble(scientificName = nm,
                  iucn_category = NA_character_,
                  iucn_id = NA_integer_))
  }

  # pick the "latest" if flagged; else most recent year if present
  if ("latest" %in% names(df) && any(isTRUE(df$latest))) {
    df <- df[isTRUE(df$latest), , drop = FALSE]
  } else if ("year_published" %in% names(df)) {
    df <- df[order(df$year_published, decreasing = TRUE), , drop = FALSE]
  }

  cat_code <- if ("red_list_category_code" %in% names(df) && length(df$red_list_category_code) >= 1)
                as.character(df$red_list_category_code[1]) else NA_character_
  sis_id   <- if ("sis_taxon_id" %in% names(df) && length(df$sis_taxon_id) >= 1)
                suppressWarnings(as.integer(df$sis_taxon_id[1])) else NA_integer_

  Sys.sleep(sleep_sec)  # IUCN recommends breaks between pings

  tibble(scientificName = nm,
         iucn_category  = cat_code,
         iucn_id        = sis_id)
}

safe_lookup <- function(x) {
  tryCatch(lookup_iucn_v4(x),
           error = function(e) tibble(scientificName = x,
                                      iucn_category = NA_character_,
                                      iucn_id = NA_integer_))
}

iucn_hits <- map_dfr(all_species, safe_lookup)

# make categories pretty labels
cat_map <- c(
  CR = "Critically Endangered",
  EN = "Endangered",
  VU = "Vulnerable",
  NT = "Near Threatened",
  LC = "Least Concern",
  DD = "Data Deficient",
  NE = "Not Evaluated"
)
iucn_hits <- iucn_hits %>%
  mutate(iucn_category_long = cat_map[iucn_category] %||% NA_character_)

iucn_hits
```

check over some that came back NA
```{r}
detected_full <- bind_rows(
  ps2024_exp_elas_glommed_df  %>% mutate(Library = "Elas02"),
  ps2024_exp_mifish_glommed_df %>% mutate(Library = "MiFish"),
  ps2024_exp_co1_glommed_df    %>% mutate(Library = "CO1")
)

# helper: extract binomial "Genus species" 
extract_binomial <- function(x) {
  x %>%
    str_remove("\\s*\\(.*$") %>%                                # drop trailing (...) if present
    str_match("^([A-Z][a-z]+)\\s+([a-z\\-]+)$") %>%             # Genus + species (allow hyphen)
    (\(m) ifelse(is.na(m[,1]), NA_character_, paste(m[,2], m[,3])))()
}

#build a lookup: scientificName -> taxonomy + libraries observed
species_tax_lookup <- detected_full %>%
  mutate(scientificName = extract_binomial(Species)) %>%
  filter(!is.na(scientificName)) %>%
  group_by(scientificName) %>%
  summarise(
    Kingdom   = first(na.omit(Kingdom)),
    Phylum    = first(na.omit(Phylum)),
    Class     = first(na.omit(Class)),
    Order     = first(na.omit(Order)),
    Family    = first(na.omit(Family)),
    Genus     = first(na.omit(Genus)),
    Libraries = paste(sort(unique(Library)), collapse = "; "),
    .groups   = "drop"
  )

# join to IUCN hits and keep only animals with NA category
animal_phyla <- c("Chordata","Arthropoda","Mollusca","Echinodermata","Annelida",
                  "Cnidaria","Porifera","Nematoda","Platyhelminthes","Bryozoa",
                  "Nemertea","Urochordata","Hemichordata","Chaetognatha")

na_iucn_animals <- iucn_hits %>%
  filter(is.na(iucn_category)) %>%
  left_join(species_tax_lookup, by = "scientificName") %>%
  filter(
    (!is.na(Kingdom) & Kingdom == "Animalia") |
    (!is.na(Phylum)  & Phylum %in% animal_phyla)
  ) %>%
  arrange(Phylum, Class, scientificName)

# inspect
na_iucn_animals %>%
  select(scientificName, Kingdom, Phylum, Class, Order, Family, Genus, Libraries, iucn_id, iucn_category)

```

--> a lof of annelids, arthropods, bryozoans, cnidaria, echinoderms, molluscs, sponges, that are simply not listed in IUCN so I have to skip. This includes some important crabs, shrimp, bivalves (hard clam!) as well as less well known things
--> Of the Actinopteri, Peprilus triacanthus (american butterfish) not in IUCN
--> Raja eglanteria (Clearnose skate) listed under new name in IUCN: Rostroraja eglanteria-- Least Concern and ID# 161658 -- Fix this one in table and remove rest of NAs
--> "Unknown Bathytoshia (Genus)" in the Species list is all "Bathytoshia centroura (Roughtail stingray)" but this didn't ping against API because of syntax. Add to list

```{r}
iucn_hits <- iucn_hits %>%
  mutate(
    scientificName = if_else(
      scientificName == "Raja eglanteria",
      "Rostroraja eglanteria",
      scientificName
    ),
    iucn_category = if_else(
      scientificName == "Rostroraja eglanteria" & is.na(iucn_category),
      "LC",
      iucn_category
    ),
    iucn_id = if_else(
      scientificName == "Rostroraja eglanteria" & (is.na(iucn_id) | iucn_id == 0L),
      161658L,
      iucn_id
    )
  )

# manually insert Bathytoshia centroura (VU; IUCN ID 104065040)
iucn_hits <- iucn_hits %>%
  filter(scientificName != "Bathytoshia centroura") %>%   # drop any existing row for it
  bind_rows(tibble(
    scientificName = "Bathytoshia centroura",
    iucn_category  = "VU",
    iucn_id        = 104065040L
  ))


# Sort worst  best 
iucn_order <- c("EX","EW","RE","CR","CR(PE)","EN","VU","NT","LC","DD","NE")

iucn_hits_sorted <- iucn_hits %>%
  mutate(
    iucn_cat_sort = case_when(
      str_detect(iucn_category, "^CR") ~ "CR",
      TRUE ~ iucn_category
    ),
    iucn_cat_sort = factor(iucn_cat_sort, levels = iucn_order, ordered = TRUE)
  ) %>%
  arrange(iucn_cat_sort, scientificName) %>%
  select(-iucn_cat_sort)

iucn_hits_sorted


```

There are a few here we suspect of being from restaurants based on where they were found (near marina restaurants) and the fact they are open ocean species: Lopholatilus chamaeleonticeps (Golden tilefish), Thunnus obesus (Bigeye tuna), Xiphias gladius (Swordfish). Remove from sorted table and retain only those that are not of least concern

```{r}


iucn_hits_sorted <- iucn_hits_sorted %>%
  filter(!(scientificName %in% c(
  "Lopholatilus chamaeleonticeps",
  "Thunnus obesus",
  "Xiphias gladius"
  ))) %>%     
  filter(!(iucn_category %in% c("LC", "Least Concern")))    # drop Least Concern

iucn_hits_sorted
```









#### Priority species list
Complete list of all conservation/ special focus species is

```{r}

nyspecies <- endangereds_detected$Species
iucnspecies <- iucn_hits_sorted$scientificName

unique_species <- tibble(ScientificName = sort(unique(c(nyspecies, iucnspecies)))) 

unique_species

```


### e1. Anguilla rostrata (American Eel)



#### Prepare data
```{r}

# Calculate relative abundance  per Site
Arostrata_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Anguilla rostrata")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Arostrata_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Arostrata_relative_abundance_df <- Arostrata_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Arostrata_relative_abundance_df

```

also detected by MiFish, pull that out as well

```{r}
# Calculate relative abundance  per Site
Arostrata_relative_abundance_df_mifish <- ps2024_exp_mifish_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Anguilla rostrata")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Arostrata_relative_abundance_df_mifish

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Arostrata_relative_abundance_df_mifish <- Arostrata_relative_abundance_df_mifish %>%
  left_join(stationdata, by = c("sites" = "sites"))


Arostrata_relative_abundance_df_mifish

```


#### Plot map
Both CO1 and MiFish for comparison
```{r}
shinn_bay_Arostrata <- plot_rel_abund(
  df     = Arostrata_relative_abundance_df,
  colour = "darkgoldenrod4",
  title  = expression("Endangered: American eel (" * italic("Anguilla rostrata") * "), CO1 reads"),
  outname= "shinn_bay_Arostrata"
)
shinn_bay_Arostrata



shinn_bay_Arostrata_mifish <- plot_rel_abund(
  df     = Arostrata_relative_abundance_df_mifish,
  colour = "darkgoldenrod4",
  title  = expression("Endangered: American eel (" * italic("Anguilla rostrata") * "), MiFish reads"),
  outname= "shinn_bay_Arostrata_mifish"
)
shinn_bay_Arostrata_mifish


```



### e2. Cynoscion regalis (Weakfish)



#### Prepare data
```{r}

# Calculate relative abundance  per Site
Cregalis_abundance_df <- ps2024_exp_mifish_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Cynoscion regalis")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Cregalis_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Cregalis_abundance_df <- Cregalis_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Cregalis_abundance_df

```




#### Plot map
Both CO1 and MiFish for comparison
```{r}
shinn_bay_Cregalis <- plot_rel_abund(
  df     = Cregalis_abundance_df,
  colour = "khaki3",
  title  = expression("Endangered: Weakfish (" * italic("Cynoscion regalis") * "), MiFish reads"),
  outname= "shinn_bay_Cregalis"
)
shinn_bay_Cregalis

```



### e3. Gymnura altavela (Spiny butterfly ray)

#### Prepare data
```{r}
# Calculate relative abundance  per Site
Galtavela_relative_abundance_df <- ps2024_exp_elas_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(CommonName == "Spiny Butterfly Ray")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Galtavela_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Galtavela_relative_abundance_df <- Galtavela_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Galtavela_relative_abundance_df

```


#### Plot map

```{r}
shinn_bay_Galtavela <- plot_rel_abund(
  df     = Galtavela_relative_abundance_df,
  colour = "hotpink4",
  title  = expression("Endangered: Spiny Butterfly Ray (" * italic("Gymnura altavela") * "), Elas02 reads"),
  outname= "shinn_bay_Galtavela"
)
shinn_bay_Galtavela

```






### e4. Isurus oxyrinchus (Shortfin mako shark)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Ioxyrinchus_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Isurus oxyrinchus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Ioxyrinchus_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Ioxyrinchus_relative_abundance_df <- Ioxyrinchus_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Ioxyrinchus_relative_abundance_df

```

also detected by Elas02, pull that out as well

```{r}
# Calculate relative abundance  per Site
Ioxyrinchus_relative_abundance_df_elas <- ps2024_exp_elas_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Isurus oxyrinchus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Ioxyrinchus_relative_abundance_df_elas

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Ioxyrinchus_relative_abundance_df_elas <- Ioxyrinchus_relative_abundance_df_elas %>%
  left_join(stationdata, by = c("sites" = "sites"))


Ioxyrinchus_relative_abundance_df_elas

```


#### Plot map
Both CO1 and MiFish for comparison
```{r}
shinn_bay_Ioxyrinchus <- plot_rel_abund(
  df     = Ioxyrinchus_relative_abundance_df,
  colour = "blue4",
  title  = expression("Endangered: Shortfin mako shark (" * italic("Isurus oxyrinchus") * "), CO1 reads"),
  outname= "shinn_bay_Ioxyrinchus"
)
shinn_bay_Ioxyrinchus



shinn_bay_Ioxyrinchus_elas <- plot_rel_abund(
  df     = Ioxyrinchus_relative_abundance_df_elas,
  colour = "blue4",
  title  = expression("Endangered: Shortfin mako shark (" * italic("Isurus oxyrinchus") * "), Elas02 reads"),
  outname= "shinn_bay_Ioxyrinchus_elas"
)
shinn_bay_Ioxyrinchus_elas


```



### e5. Megaptera novaeangliae (Humpback whale)



#### Prepare data
Only detected in MiFish
```{r}
# Calculate relative abundance  per Site
Mnovaeangliae_relative_abundance_df <- ps2024_exp_mifish_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Megaptera novaeangliae")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Mnovaeangliae_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Mnovaeangliae_relative_abundance_df <- Mnovaeangliae_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Mnovaeangliae_relative_abundance_df

```




#### Plot map

```{r}
shinn_bay_Mnovaeangliae <- plot_rel_abund(
  df     = Mnovaeangliae_relative_abundance_df,
  colour = "darkslategrey",
  title  = expression("Endangered: Humpback whale (" * italic("Megaptera novaeangliae") * "), MiFish reads"),
  outname= "shinn_bay_Mnovaeangliae"
)
shinn_bay_Mnovaeangliae

```




### e6. Bathytoshia centroura (Roughtail stingray)



#### Prepare data
```{r}

# Calculate relative abundance  per Site
Bcentroura_relative_abundance_df <- ps2024_exp_elas_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Unknown Bathytoshia (Genus)")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Bcentroura_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Bcentroura_relative_abundance_df <- Bcentroura_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Bcentroura_relative_abundance_df

```



#### Plot map
```{r}
shinn_bay_Bcentroura <- plot_rel_abund(
  df     = Bcentroura_relative_abundance_df,
  colour = "purple4",
  title  = expression("Vulnerable: Roughtail stingray (" * italic("Bathytoshia centroura") * "), Elas02 reads"),
  outname= "shinn_bay_Bcentroura"
)
shinn_bay_Bcentroura


```






### e7. Vulnerable: Limulus polyphemus (American Horseshoe Crab)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Lpolyphemus_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Limulus polyphemus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Lpolyphemus_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Lpolyphemus_relative_abundance_df <- Lpolyphemus_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Lpolyphemus_relative_abundance_df

```



#### Plot map

```{r}
shinn_bay_Lpolyphemus <- plot_rel_abund(
  df     = Lpolyphemus_relative_abundance_df,
  colour = "brown4",
  title  = expression("Vulnerable: American horseshoe crab (" * italic("Limulus polyphemus") * "), CO1 reads"),
  outname= "shinn_bay_Lpolyphemus"
)
shinn_bay_Lpolyphemus

```











### e8. Vulnerable: Pseudopleuronectes americanus (Winter flounder)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Pamericanus_relative_abundance_df <- ps2024_exp_mifish_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Pseudopleuronectes americanus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Pamericanus_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Pamericanus_relative_abundance_df <- Pamericanus_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Pamericanus_relative_abundance_df

```



#### Plot map

```{r}
shinn_bay_Pamericanus <- plot_rel_abund(
  df     = Pamericanus_relative_abundance_df,
  colour = "olivedrab",
  title  = expression("Vulnerable: Winter flounder (" * italic("Pseudopleuronectes americanus") * "), MiFish reads"),
  outname= "shinn_bay_Pamericanus"
)
shinn_bay_Pamericanus

```






### e9. Vulnerable: Rhinoptera bonasus (Cownose ray)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Rbonasus_relative_abundance_df <- ps2024_exp_elas_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Rhinoptera bonasus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Rbonasus_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Rbonasus_relative_abundance_df <- Rbonasus_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Rbonasus_relative_abundance_df

```


also detected in CO1
```{r}
# Calculate relative abundance  per Site
Rbonasus_relative_abundance_df_co1 <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Rhinoptera bonasus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Rbonasus_relative_abundance_df_co1

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Rbonasus_relative_abundance_df_co1 <- Rbonasus_relative_abundance_df_co1 %>%
  left_join(stationdata, by = c("sites" = "sites"))


Rbonasus_relative_abundance_df_co1

```

#### Plot map

```{r}
shinn_bay_Rbonasus <- plot_rel_abund(
  df     = Rbonasus_relative_abundance_df,
  colour = "tomato4",
  title  = expression("Vulnerable: Cownose ray (" * italic("Rhinoptera bonasus") * "), Elas02 reads"),
  outname= "shinn_bay_Rbonasus"
)
shinn_bay_Rbonasus



shinn_bay_Rbonasus_co1 <- plot_rel_abund(
  df     = Rbonasus_relative_abundance_df_co1,
  colour = "tomato4",
  title  = expression("Vulnerable: Cownose ray (" * italic("Rhinoptera bonasus") * "), CO1 reads"),
  outname= "shinn_bay_Rbonasus_co1"
)
shinn_bay_Rbonasus_co1

```










### e10. Vulnerable: Tautoga onitis (Tautog)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Tonitis_relative_abundance_df <- ps2024_exp_mifish_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Tautoga onitis")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Tonitis_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Tonitis_relative_abundance_df <- Tonitis_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Tonitis_relative_abundance_df

```


also detected in CO1
```{r}
# Calculate relative abundance  per Site
Tonitis_relative_abundance_df_co1 <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Rhinoptera bonasus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Tonitis_relative_abundance_df_co1

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Tonitis_relative_abundance_df_co1 <- Tonitis_relative_abundance_df_co1 %>%
  left_join(stationdata, by = c("sites" = "sites"))


Tonitis_relative_abundance_df_co1

```

#### Plot map

```{r}
shinn_bay_Tonitis <- plot_rel_abund(
  df     = Tonitis_relative_abundance_df,
  colour = "lightgoldenrod3",
  title  = expression("Vulnerable: Tautog (" * italic("Tautoga onitis") * "), MiFish reads"),
  outname= "shinn_bay_Tonitis"
)
shinn_bay_Tonitis



shinn_bay_Tonitis_co1 <- plot_rel_abund(
  df     = Tonitis_relative_abundance_df_co1,
  colour = "lightgoldenrod3",
  title  = expression("Vulnerable: Tautog (" * italic("Tautoga onitis") * "), CO1 reads"),
  outname= "shinn_bay_Tonitis_co1"
)
shinn_bay_Tonitis_co1

```










### e11. Near Threatened: Mustelus canis (Smooth dogfish)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Mcanis_relative_abundance_df <- ps2024_exp_elas_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Mustelus canis")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Mcanis_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Mcanis_relative_abundance_df <- Mcanis_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Mcanis_relative_abundance_df

```

also detected in MiFish
```{r}

# Calculate relative abundance  per Site
Mcanis_relative_abundance_df_mifish <- ps2024_exp_mifish_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Mustelus canis")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Mcanis_relative_abundance_df_mifish

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Mcanis_relative_abundance_df_mifish <- Mcanis_relative_abundance_df_mifish %>%
  left_join(stationdata, by = c("sites" = "sites"))


Mcanis_relative_abundance_df_mifish

```





#### Plot map

```{r}
shinn_bay_Mcanis <- plot_rel_abund(
  df     = Tonitis_relative_abundance_df,
  colour = "dodgerblue3",
  title  = expression("Near Threatened: Smooth dogfish (" * italic("Mustelus canis") * "), Elas02 reads"),
  outname= "shinn_bay_Mcanis"
)
shinn_bay_Mcanis



shinn_bay_Mcanis_mifish <- plot_rel_abund(
  df     = Tonitis_relative_abundance_df_co1,
  colour = "dodgerblue3",
  title  = expression("Near Threatened: Smooth dogfish (" * italic("Mustelus canis") * "), MiFish reads"),
  outname= "shinn_bay_Mcanis_mifish"
)
shinn_bay_Mcanis_mifish

```





### e12. Near Threatened: Scup (Stenotomus chrysops)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Schrysops_relative_abundance_df <- ps2024_exp_mifish_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Stenotomus chrysops")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Schrysops_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Schrysops_relative_abundance_df <- Schrysops_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Schrysops_relative_abundance_df

```





#### Plot map

```{r}
shinn_bay_Schrysops <- plot_rel_abund(
  df     = Schrysops_relative_abundance_df,
  colour = "cadetblue2",
  title  = expression("Near Threatened: Scup (" * italic("Stenotomus chrysops") * "), MiFish reads"),
  outname= "shinn_bay_Schrysops"
)
shinn_bay_Schrysops


```




### e13. High Priority SGCN: Eastern oyster (Crassostrea virginica)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Cvirginica_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Crassostrea virginica")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Cvirginica_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Cvirginica_relative_abundance_df <- Cvirginica_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Cvirginica_relative_abundance_df

```





#### Plot map

```{r}
shinn_bay_Cvirginica <- plot_rel_abund(
  df     = Cvirginica_relative_abundance_df,
  colour = "slategrey",
  title  = expression("High Priority SGCN: Eastern oyster (" * italic("Crassostrea virginica") * "), CO1 reads"),
  outname= "shinn_bay_Cvirginica"
)
shinn_bay_Cvirginica


```






### e13. High Priority SGCN: Hard clam (Mercenaria mercenaria)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Mmercenaria_relative_abundance_df <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Mercenaria mercenaria")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Mmercenaria_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Mmercenaria_relative_abundance_df <- Mmercenaria_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Mmercenaria_relative_abundance_df

```





#### Plot map

```{r}
shinn_bay_Mmercenaria <- plot_rel_abund(
  df     = Mmercenaria_relative_abundance_df,
  colour = "grey64",
  title  = expression("High Priority SGCN: Hard clam (" * italic("Mercenaria mercenaria") * "), CO1 reads"),
  outname= "shinn_bay_Mmercenaria"
)
shinn_bay_Mmercenaria


```






### e14. High Priority SGCN: Northern pipefish (Syngnathus fuscus)



#### Prepare data
```{r}
# Calculate relative abundance  per Site
Sfuscus_relative_abundance_df <- ps2024_exp_mifish_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Syngnathus fuscus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Sfuscus_relative_abundance_df

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Sfuscus_relative_abundance_df <- Sfuscus_relative_abundance_df %>%
  left_join(stationdata, by = c("sites" = "sites"))


Sfuscus_relative_abundance_df

```


also found in CO1
```{r}
# Calculate relative abundance  per Site
Sfuscus_relative_abundance_df_co1 <- ps2024_exp_co1_glommed_df %>%
  group_by(sites) %>%
  summarise(TotalCounts = n(), 
            Counts = sum(Species == "Syngnathus fuscus")) %>%
  mutate(RelativeAbundance = Counts / TotalCounts) %>%
  select(-TotalCounts, -Counts)  %>%
  group_by(sites) %>%
  summarise(AverageRelativeAbundancePercent = mean(RelativeAbundance)*100) %>%
  filter(AverageRelativeAbundancePercent > 0) # remove zeroes so they do no appear as bubbles in plot
Sfuscus_relative_abundance_df_co1

# add in station metadata
stationdata <- read_csv("../eDNA-databases/stationsmetadata.csv")
stationdata$sites <- as.factor(stationdata$sites) 

# combine
Sfuscus_relative_abundance_df_co1 <- Sfuscus_relative_abundance_df_co1 %>%
  left_join(stationdata, by = c("sites" = "sites"))


Sfuscus_relative_abundance_df_co1

```



#### Plot map

```{r}
shinn_bay_Sfuscus <- plot_rel_abund(
  df     = Sfuscus_relative_abundance_df,
  colour = "burlywood",
  title  = expression("High Priority SGCN: Northern pipefish (" * italic("Syngnathus fuscus") * "), MiFish reads"),
  outname= "shinn_bay_Sfuscus"
)
shinn_bay_Sfuscus


shinn_bay_Sfuscus_co1 <- plot_rel_abund(
  df     = Sfuscus_relative_abundance_df_co1,
  colour = "burlywood",
  title  = expression("High Priority SGCN: Northern pipefish (" * italic("Syngnathus fuscus") * "), CO1 reads"),
  outname= "shinn_bay_Sfuscus_co1"
)
shinn_bay_Sfuscus_co1

```






### e15. Figure for manuscript
Stack a select few for main text (rest will go in Supp)
```{r}

# legend labels 
lab_fun <- function(x) ifelse(x == 0.1, "\u2264 0.1",
                       ifelse(x == 10,  "\u2265 10", as.character(x)))

# same size scale across all panels
size_scale_fixed <- scale_size_continuous(
  name   = "Avg. Relative\nAbundance (%)",
  limits = c(0.1, 10),
  breaks = c(0.1, 0.5, 1, 5, 10),
  labels = lab_fun,
  range  = c(3.5, 12)
)

# inset title (two lines) at the top-left; line 1 italic
add_inset_title <- function(p, label,
                            hjust = -0.2, vjust = 2.4,
                            size = 4.2, offset = 1.2) {
  parts <- strsplit(label, "\n", fixed = TRUE)[[1]]
  line1 <- parts[1]
  line2 <- if (length(parts) >= 2) parts[2] else ""

  p <- p + labs(title = NULL)

  p <- p + annotate(
    "text", x = -Inf, y = Inf,
    hjust = hjust, vjust = vjust,
    label = line1, parse = FALSE,
    size = size, fontface = "italic", lineheight = 1.1
  )

  if (nzchar(line2)) {
    p <- p + annotate(
      "text", x = -Inf, y = Inf,
      hjust = hjust, vjust = vjust + offset,
      label = line2, parse = FALSE,
      size = size, fontface = "plain", lineheight = 1.1
    )
  }
  p
}

# tighten whitespace around panels
tight_theme <- theme(
  plot.margin       = margin(0, 0, 0, 0),
  legend.margin     = margin(0, 0, 0, 0),
  legend.box.margin = margin(0, 0, 0, 0),
  panel.spacing     = unit(2, "pt")
)


g_Aro  <- shinn_bay_Arostrata_mifish + tight_theme + size_scale_fixed + labs(x=NULL, y=NULL)
g_Aro  <- add_inset_title(g_Aro,  "Anguilla rostrata\nAmerican eel")

g_Gym  <- shinn_bay_Galtavela + tight_theme + size_scale_fixed + labs(x=NULL, y=NULL)
g_Gym  <- add_inset_title(g_Gym,  "Gymnura altavela\nSpiny butterfly ray")

g_Iso  <- shinn_bay_Ioxyrinchus_elas + tight_theme + size_scale_fixed + labs(x=NULL, y=NULL)
g_Iso  <- add_inset_title(g_Iso,  "Isurus oxyrinchus\nShortfin mako shark")

g_Psa  <- shinn_bay_Pamericanus + tight_theme + size_scale_fixed + labs(x=NULL, y=NULL)
g_Psa  <- add_inset_title(g_Psa,  "Pseudopleuronectes americanus\nWinter flounder")

g_Bat  <- shinn_bay_Bcentroura + tight_theme + size_scale_fixed + labs(x=NULL, y=NULL)
g_Bat  <- add_inset_title(g_Bat,  "Bathytoshia centroura\nRoughtail stingray")

g_Tau  <- shinn_bay_Tonitis + tight_theme + size_scale_fixed + labs(x=NULL, y=NULL)   # MiFish version
g_Tau  <- add_inset_title(g_Tau,  "Tautoga onitis\nTautog")

g_Scup <- shinn_bay_Schrysops + tight_theme + size_scale_fixed + labs(x=NULL, y=NULL)
g_Scup <- add_inset_title(g_Scup, "Stenotomus chrysops\nScup")

g_Oys  <- shinn_bay_Cvirginica + tight_theme + size_scale_fixed + labs(x=NULL, y=NULL)
g_Oys  <- add_inset_title(g_Oys,  "Crassostrea virginica\nEastern oyster")

g_Clam <- shinn_bay_Mmercenaria + tight_theme + size_scale_fixed + labs(x=NULL, y=NULL)
g_Clam <- add_inset_title(g_Clam, "Mercenaria mercenaria\nHard clam")

# put axis titles only on select panels
# Layout indices with ncol=2:
# left column: 1=g_Aro, 3=g_Iso, 5=g_Bat, 7=g_Scup, 9=g_Clam
# right column: 2=g_Gym, 4=g_Psa, 6=g_Tau, 8=g_Oys

# One y-axis title on the middle-left column 
g_Bat  <- g_Bat  + labs(y = "Latitude")  + theme(axis.title.y = element_text())

# Two x-axis titles on the bottom of each column
g_Oys  <- g_Oys  + labs(x = "Longitude") + theme(axis.title.x = element_text())
g_Clam <- g_Clam + labs(x = "Longitude") + theme(axis.title.x = element_text())

plots_list <- list(
  g_Aro, g_Gym,
  g_Iso, g_Psa,
  g_Bat, g_Tau,
  g_Scup, g_Oys,
  g_Clam
)

combined_hp <- wrap_plots(plots_list, ncol = 2, guides = "collect") &
  guides(size = guide_legend(override.aes = list(colour = "black"))) &
  theme(legend.position = "right")

combined_hp


ggsave("figures-expedition/high_priority_conservation_2col.eps",
       combined_hp, width = 8.5, height = 12.5, units = "in")
ggsave("figures-expedition/high_priority_conservation_2col.jpg",
       combined_hp, width = 8.5, height = 12.5, units = "in")

# (trim outer whitespace on the JPG
image_read("figures-expedition/high_priority_conservation_2col.jpg") |>
  image_trim() |>
  image_write("figures-expedition/high_priority_conservation_2col.jpg")

```



### f. Other detected species to watch:
- Investigate if any are bioindicators. Some candidates:
  - [Polygordius jouinae is a polychaete that might indicate well-sorted sandy bottoms](https://link.springer.com/article/10.1007/s00227-008-0936-9))
  - Streblospio benedicti, the Ram's horn worm, [is also a bioindicator](https://zakaslab.weebly.com/research.html). Old ref [here](https://elischolar.library.yale.edu/cgi/viewcontent.cgi?article=2288&context=journal_of_marine_research) and other example [here](https://link.springer.com/chapter/10.1007/978-3-031-70882-4_11)
  - Mediomastus ambiseta is another polychaete that also might be used as a bioindicator ([same red](https://link.springer.com/chapter/10.1007/978-3-031-70882-4_11)- read closely, results seem dif than what abstract states)
  - Amphitrite ornata is [potentially an indicator of hydrocarbon pollution](https://pubmed.ncbi.nlm.nih.gov/14961367/)
- Other HABs



### Save/ Re-load
```{r}
save.image(file = "figures-expedition/exp_ecol_analysis_environment_upto_maps.RData")
```

or load back in
```{r}
load(file = "figures-expedition/exp_ecol_analysis_environment_upto_maps.RData")
```


# IV. Replication
How do replicates compare?

## Paired barplots

### Mifish
Look at species level
```{r}
sample_data(ps2024_exp_mifish)$replicates
# 90 samples, with 73 unique levels. So there are 17 samples which were collected in duplicate

duplicate_IDs <- sample_data(ps2024_exp_mifish)$replicates[duplicated(sample_data(ps2024_exp_mifish)$replicates)]
duplicate_IDs

# make new phyloseq object with only replicates
ps2024_exp_reps_mifish <- subset_samples(ps2024_exp_mifish_glommed, replicates %in% duplicate_IDs)
ps2024_exp_reps_mifish_ra <- subset_samples(ps2024_exp_mifish_glommed_ra, replicates %in% duplicate_IDs)


ps2024_exp_barplot_replicates <- plot_bar(ps2024_exp_reps_mifish, x = "Name.Deploy_Cartr_Library", fill = "CommonName")+
  scale_fill_manual(values = myColors_comname)
ps2024_exp_barplot_replicates

ps2024_exp_ra_barplot_replicates_ra <- plot_bar(ps2024_exp_reps_mifish_ra, x = "Name.Deploy_Cartr_Library", fill = "CommonName")+
  scale_fill_manual(values = myColors_comname)
ps2024_exp_ra_barplot_replicates_ra

# view replicates pair-by-pair
ps2024_exp_ra_barplot_replicates_ra <- ps2024_exp_ra_barplot_replicates_ra +
    facet_grid(~replicates, scales = "free", space = "free", drop= TRUE)+
    scale_fill_manual(values = myColors_comname)+
    theme_minimal() +
    theme(legend.position = "none", 
          axis.title.x = element_blank(), 
          axis.text.x = element_text(size = 0), 
          strip.text = element_text(size = 12))
ps2024_exp_ra_barplot_replicates_ra


ggsave(plot = ps2024_exp_ra_barplot_replicates_ra, filename = "figures-expedition/barplot_2024_expedition_replicates_sidebyside.eps", width = 12, height = 7, units = "in")

ggsave(plot = ps2024_exp_ra_barplot_replicates_ra, filename = "figures-expedition/barplot_2024_expedition_replicates_sidebyside.jpg", width = 12, height = 7, units = "in")
```

- Some replicates look very close to each other (~10 of the 17) while others do not. I manually checked the Sample Inventory. One issue may be filtration volume- these are not always consistent bc of the issues with overpressuring
- I also notice that the more diverse the sample is, the less similar the replicates are. eg. 5_19 and 8_11a


### Elas02
Look at species level
```{r}
sample_data(ps2024_exp_elas)$replicates

duplicate_IDs <- sample_data(ps2024_exp_elas)$replicates[duplicated(sample_data(ps2024_exp_elas)$replicates)]
duplicate_IDs

# make new phyloseq object with only replicates
ps2024_exp_reps_elas <- subset_samples(ps2024_exp_elas_glommed, replicates %in% duplicate_IDs)
ps2024_exp_reps_elas_ra <- subset_samples(ps2024_exp_elas_glommed_ra, replicates %in% duplicate_IDs)


ps2024_exp_barplot_replicates <- plot_bar(ps2024_exp_reps_elas, x = "Name.Deploy_Cartr", fill = "CommonName")+
  scale_fill_manual(values = myColors_comname)
ps2024_exp_barplot_replicates

ps2024_exp_ra_barplot_replicates_ra <- plot_bar(ps2024_exp_reps_elas_ra, x = "Name.Deploy_Cartr", fill = "CommonName")+
  scale_fill_manual(values = myColors_comname)
ps2024_exp_ra_barplot_replicates_ra

# view replicates pair-by-pair
ps2024_exp_ra_barplot_replicates_ra <- ps2024_exp_ra_barplot_replicates_ra +
    facet_grid(~replicates, scales = "free", space = "free", drop= TRUE)+
    scale_fill_manual(values = myColors_comname)+
    theme_minimal() +
    theme(legend.position = "none", 
          axis.title.x = element_blank(), 
          axis.text.x = element_text(size = 0), 
          strip.text = element_text(size = 12))
ps2024_exp_ra_barplot_replicates_ra


ggsave(plot = ps2024_exp_ra_barplot_replicates_ra, filename = "figures-expedition/barplot_2024_expedition_replicates_sidebyside_elas02.eps", width = 8, height = 7, units = "in")

ggsave(plot = ps2024_exp_ra_barplot_replicates_ra, filename = "figures-expedition/barplot_2024_expedition_replicates_sidebyside_elas02.jpg", width = 8, height = 7, units = "in")
```
Replication is pretty big but there is not a lot of variability over all


### CO1
Look at Phlyum level
```{r}
sample_data(ps2024_exp_co1)$replicates

duplicate_IDs <- sample_data(ps2024_exp_co1)$replicates[duplicated(sample_data(ps2024_exp_co1)$replicates)]
duplicate_IDs

# make new phyloseq object with only replicates
ps2024_exp_reps_co1 <- subset_samples(ps2024_exp_co1_glommed, replicates %in% duplicate_IDs)
ps2024_exp_reps_co1_ra <- subset_samples(ps2024_exp_co1_glommed_ra, replicates %in% duplicate_IDs)


ps2024_exp_barplot_replicates <- plot_bar(ps2024_exp_reps_co1, x = "Name_Deploy_Cartr", fill = "Phylum")
ps2024_exp_barplot_replicates

ps2024_exp_ra_barplot_replicates_ra <- plot_bar(ps2024_exp_reps_co1_ra, x = "Name_Deploy_Cartr", fill = "Phylum")
ps2024_exp_ra_barplot_replicates_ra

# view replicates pair-by-pair
ps2024_exp_ra_barplot_replicates_ra <- ps2024_exp_ra_barplot_replicates_ra +
    facet_grid(~replicates, scales = "free", space = "free", drop= TRUE) +
    theme_minimal() +
    theme(axis.title.x = element_blank(), 
          axis.text.x = element_text(size = 0), 
          strip.text = element_text(size = 12))
ps2024_exp_ra_barplot_replicates_ra


ggsave(plot = ps2024_exp_ra_barplot_replicates_ra, filename = "figures-expedition/barplot_2024_expedition_replicates_sidebyside_co1.eps", width = 18, height = 6, units = "in")

ggsave(plot = ps2024_exp_ra_barplot_replicates_ra, filename = "figures-expedition/barplot_2024_expedition_replicates_sidebyside_co1.jpg", width = 18, height = 6, units = "in")
```
Replication looks pretty decent in most cases for the phylum level.


## Aitchison dissimilarity among repilcates


For [compositional data](https://www.frontiersin.org/journals/microbiology/articles/10.3389/fmicb.2017.02224/full), use Aitchison distance on CLR-transformed data


From [vegan](https://rdrr.io/cran/vegan/man/vegdist.html) documentation, "aitchison" method in `vegdist` automatically does the clr transformation before calculating the distance matrix. Phyloseq has [some options](https://joey711.github.io/phyloseq/distance.html) to do run vegdist with a phyloseq object using a `distance` function, however aitchison is not listed:
```{r}
dist_methods <- unlist(distanceMethodList)
print(dist_methods)
```

On the other hand, from the vegan documentation, Aitchison distance is just the Euclidean distance on clr-transformed data, so I can do a transformation first and then the Euclidean distance calculation.



I also spent a long time figuring out why clr transformation using 2 different packages was giving different distance matrices. Finally figured it out using practice dataset, dietswap, below. Next apply to real data:
```{r}
###

data(dietswap)

otu_df <- as.data.frame(otu_table(dietswap))

otu_df[otu_df == 0] <- 1e-8 # Small value replacement for zeros

otu_df


## FINALLY FIGURED THAT THESE 2 THINGS ARE EQUIVLENT:
data.frame(microbiome::transform(t(otu_df), transform = "clr") ) 
data.frame(compositions::clr(otu_df))

```

### Mifish
Dissimilarity between replicates
```{r}
# replace zeroes with very very small numbers
otu_df <- as.data.frame(otu_table(ps2024_exp_reps_mifish))
otu_df[otu_df == 0] <- 1e-8 

# check that
data.frame(microbiome::transform(t(otu_df), transform = 'clr'))
# and
data.frame(compositions::clr(otu_df))
# are equivalent


ps2024_exp_reps_clr_mifish <- microbiome::transform(t(otu_df), transform = 'clr')
  
ps2024_exp_reps_dist_mifish <- vegdist(ps2024_exp_reps_clr_mifish, method= "euclidean")

ps2024_exp_reps_dist_mat_mifish <- as.matrix(ps2024_exp_reps_dist_mifish)

ps2024_exp_reps_dist_df_mifish <- as.data.frame(ps2024_exp_reps_dist_mat_mifish)
ps2024_exp_reps_dist_df_mifish

write.csv(ps2024_exp_reps_dist_df_mifish,"figures-expedition/mifish_2024_exp_aitchisondistance_replicates.csv", row.names = TRUE)
```
Analyzed the above in Excel in the file, [mifish_2024_exp_aitchisondistance_replicates.xlsx](figures-expedition/mifish_2024_exp_aitchisondistance_replicates.xlsx)
- Highlighted dissimilarity index between replicates
- Calculated average dissimilarity between replicates = 47.13; SD = 24.94; SE = 6.05


Get dissimilarity indices and their average across whole dataset, for comparison:
```{r}
# replace zeroes with very very small numbers
otu_df <- as.data.frame(otu_table(ps2024_exp_mifish))
otu_df[otu_df == 0] <- 1e-8 

# check that
data.frame(microbiome::transform(t(otu_df), transform = 'clr'))
# and
data.frame(compositions::clr(otu_df))
# are equivalent


ps2024_exp_clr_mifish <- microbiome::transform(t(otu_df), transform = 'clr')
  
ps2024_exp_dist_mifish <- vegdist(ps2024_exp_clr_mifish, method= "euclidean")

ps2024_exp_dist_mat_mifish <- as.matrix(ps2024_exp_dist_mifish)

ps2024_exp_dist_df_mifish <- as.data.frame(ps2024_exp_dist_mat_mifish)
ps2024_exp_dist_df_mifish

# mean of all distance indices?
mean(ps2024_exp_dist_mifish)
sd(ps2024_exp_dist_mifish)
sd(ps2024_exp_dist_mifish)/sqrt(dim(ps2024_exp_dist_mifish)[1]*dim(ps2024_exp_dist_mifish)[2])

```
On average, across the whole dataset, the dissimilarity is 101.48 (SD 17.19; SE 0.19) while. Replicates are much less dissimilar than every sample compared to every other sample.


### Elas02
Dissimilarity between replicates
```{r}
# replace zeroes with very very small numbers
otu_df <- as.data.frame(otu_table(ps2024_exp_reps_elas))
otu_df[otu_df == 0] <- 1e-8 

# check that
data.frame(microbiome::transform(t(otu_df), transform = 'clr'))
# and
data.frame(compositions::clr(otu_df))
# are equivalent


ps2024_exp_reps_clr_elas <- microbiome::transform(t(otu_df), transform = 'clr')
  
ps2024_exp_reps_dist_elas <- vegdist(ps2024_exp_reps_clr_elas, method= "euclidean")

ps2024_exp_reps_dist_mat_elas <- as.matrix(ps2024_exp_reps_dist_elas)

ps2024_exp_reps_dist_df_elas <- as.data.frame(ps2024_exp_reps_dist_mat_elas)
ps2024_exp_reps_dist_df_elas

write.csv(ps2024_exp_reps_dist_df_elas,"figures-expedition/elas_2024_exp_aitchisondistance_replicates.csv", row.names = TRUE)
```

Analyzed the above in Excel in the file, [elas_2024_exp_aitchisondistance_replicates.xlsx](figures-expedition/elas_2024_exp_aitchisondistance_replicates.xlsx)
- Highlighted dissimilarity index between replicates
- Calculated average dissimilarity between replicates = 5.76; SD = 9.26; SE = 2.48


Get dissimilarity indices and their average across whole dataset, for comparison:
```{r}
# replace zeroes with very very small numbers
otu_df <- as.data.frame(otu_table(ps2024_exp_elas))
otu_df[otu_df == 0] <- 1e-8 

# check that
data.frame(microbiome::transform(t(otu_df), transform = 'clr'))
# and
data.frame(compositions::clr(otu_df))
# are equivalent


ps2024_exp_clr_elas <- microbiome::transform(t(otu_df), transform = 'clr')
  
ps2024_exp_dist_elas <- vegdist(ps2024_exp_clr_elas, method= "euclidean")

ps2024_exp_dist_mat_elas <- as.matrix(ps2024_exp_dist_elas)

ps2024_exp_dist_df_elas <- as.data.frame(ps2024_exp_dist_mat_elas)
ps2024_exp_dist_df_elas

# mean of all distance indices?
mean(ps2024_exp_dist_elas)
sd(ps2024_exp_dist_elas)
sd(ps2024_exp_dist_elas)/sqrt(dim(ps2024_exp_dist_elas)[1]*dim(ps2024_exp_dist_elas)[2])

```

On average, across the whole dataset, the dissimilarity is 168.04 (SD 25.87; SE 0.42) while. Replicates are much less dissimilar than every sample compared to every other sample.


### CO1
Dissimilarity between replicates
```{r}
# replace zeroes with very very small numbers
otu_df <- as.data.frame(otu_table(ps2024_exp_reps_co1))
otu_df[otu_df == 0] <- 1e-8 

# check that
data.frame(microbiome::transform(t(otu_df), transform = 'clr'))
# and
data.frame(compositions::clr(otu_df))
# are equivalent


ps2024_exp_reps_clr_co1 <- microbiome::transform(t(otu_df), transform = 'clr')
  
ps2024_exp_reps_dist_co1 <- vegdist(ps2024_exp_reps_clr_co1, method= "euclidean")

ps2024_exp_reps_dist_mat_co1 <- as.matrix(ps2024_exp_reps_dist_co1)

ps2024_exp_reps_dist_df_co1 <- as.data.frame(ps2024_exp_reps_dist_mat_co1)
ps2024_exp_reps_dist_df_co1

write.csv(ps2024_exp_reps_dist_df_co1,"figures-expedition/co1_2024_exp_aitchisondistance_replicates.csv", row.names = TRUE)
```


Analyzed the above in Excel in the file, [co1_2024_exp_aitchisondistance_replicates.xlsx](figures-expedition/co1_2024_exp_aitchisondistance_replicates.xlsx)
- Highlighted dissimilarity index between replicates
- Calculated average dissimilarity between replicates = 218.05; SD = 38.98; SE = 9.19


Get dissimilarity indices and their average across whole dataset, for comparison:
```{r}
# replace zeroes with very very small numbers
otu_df <- as.data.frame(otu_table(ps2024_exp_co1))
otu_df[otu_df == 0] <- 1e-8 

# check that
data.frame(microbiome::transform(t(otu_df), transform = 'clr'))
# and
data.frame(compositions::clr(otu_df))
# are equivalent


ps2024_exp_clr_co1 <- microbiome::transform(t(otu_df), transform = 'clr')
  
ps2024_exp_dist_co1 <- vegdist(ps2024_exp_clr_co1, method= "euclidean")

ps2024_exp_dist_mat_co1 <- as.matrix(ps2024_exp_dist_co1)

ps2024_exp_dist_df_co1 <- as.data.frame(ps2024_exp_dist_mat_co1)
ps2024_exp_dist_df_co1

# mean of all distance indices?
mean(ps2024_exp_dist_co1)
sd(ps2024_exp_dist_co1)
sd(ps2024_exp_dist_co1)/sqrt(dim(ps2024_exp_dist_co1)[1]*dim(ps2024_exp_dist_co1)[2])

```

On average, across the whole dataset, the dissimilarity is 1134.02 (SD 234.37; SE 2.49) while. Replicates are much less dissimilar than every sample compared to every other sample.





## Aitchison dissimilarity among stations
How does compositional distance compare from the same station as compared to the whole dataset? 

### MiFish
```{r}
# Pull metadata
meta <- data.frame(sample_data(ps2024_exp_mifish))

# Keep only the sample ID and station info
meta <- meta %>% 
  rownames_to_column(var = "SampleID") %>%
  select(SampleID, sites)

dist_mat <- as.matrix(ps2024_exp_dist_mifish)
dist_long <- as.data.frame(as.table(dist_mat))
colnames(dist_long) <- c("Sample1", "Sample2", "Distance")

dist_long <- dist_long %>%
  left_join(meta, by = c("Sample1" = "SampleID")) %>%
  rename(Station1 = sites) %>%
  left_join(meta, by = c("Sample2" = "SampleID")) %>%
  rename(Station2 = sites)

dist_long <- dist_long %>%
  mutate(WithinStation = ifelse(Station1 == Station2, TRUE, FALSE))

avg_within <- dist_long %>%
  filter(WithinStation  & Distance != 0) %>%
  group_by(Station1) %>%
  summarise(MeanDistance = mean(Distance))

overall_avg_within <- mean(avg_within$MeanDistance)

avg_overall <- mean(dist_long$Distance)

avg_within
overall_avg_within
sd(avg_within$MeanDistance)
avg_overall

```



### Elas02
```{r}
# Pull metadata
meta <- data.frame(sample_data(ps2024_exp_elas))

# Keep only the sample ID and station info
meta <- meta %>% 
  rownames_to_column(var = "SampleID") %>%
  select(SampleID, sites)

dist_mat <- as.matrix(ps2024_exp_dist_elas)
dist_long <- as.data.frame(as.table(dist_mat))
colnames(dist_long) <- c("Sample1", "Sample2", "Distance")

dist_long <- dist_long %>%
  left_join(meta, by = c("Sample1" = "SampleID")) %>%
  rename(Station1 = sites) %>%
  left_join(meta, by = c("Sample2" = "SampleID")) %>%
  rename(Station2 = sites)

dist_long <- dist_long %>%
  mutate(WithinStation = ifelse(Station1 == Station2, TRUE, FALSE))

avg_within <- dist_long %>%
  filter(WithinStation & Distance != 0) %>%
  group_by(Station1) %>%
  summarise(MeanDistance = mean(Distance))

overall_avg_within <- mean(avg_within$MeanDistance)

avg_overall <- mean(dist_long$Distance)

avg_within
overall_avg_within
sd(avg_within$MeanDistance)
avg_overall

```


CO1
```{r}
# Pull metadata
meta <- data.frame(sample_data(ps2024_exp_co1))

# Keep only the sample ID and station info
meta <- meta %>% 
  rownames_to_column(var = "SampleID") %>%
  select(SampleID, sites)

dist_mat <- as.matrix(ps2024_exp_dist_co1)
dist_long <- as.data.frame(as.table(dist_mat))
colnames(dist_long) <- c("Sample1", "Sample2", "Distance")

dist_long <- dist_long %>%
  left_join(meta, by = c("Sample1" = "SampleID")) %>%
  rename(Station1 = sites) %>%
  left_join(meta, by = c("Sample2" = "SampleID")) %>%
  rename(Station2 = sites)

dist_long <- dist_long %>%
  mutate(WithinStation = ifelse(Station1 == Station2, TRUE, FALSE))

avg_within <- dist_long %>%
  filter(WithinStation  & Distance != 0) %>%
  group_by(Station1) %>%
  summarise(MeanDistance = mean(Distance))

overall_avg_within <- mean(avg_within$MeanDistance)

avg_overall <- mean(dist_long$Distance)

avg_within
overall_avg_within
sd(avg_within$MeanDistance)
avg_overall

```







#### Save

```{r}
save.image(file = "figures-expedition/exp_ecol_analysis_environment_upto_Aitchison_reps.RData")
```


```{r}
load(file = "figures-expedition/exp_ecol_analysis_environment_upto_Aitchison_reps.RData")
```

# V. Occupancy

Present Presence/ Absence as site occupancy, eg. across all samples from XX habitat type or east/west etc etc, how many times did species X appear. Check out [Lawson Handley et al. 2019](https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.5)

### MiFIsh

```{r}
# How many total samples taken in each habitat type?
Total_samples_habitat <- as.data.frame(samples_2024_exp_mifish) %>%
  group_by(Habitat) %>%
  count(name = "Habitat_sample_total") %>%
  na.omit()

# in east vs west?
Total_samples_EW <- as.data.frame(samples_2024_exp_mifish) %>%
  group_by(Bayside) %>%
  count(name = "Bayside_sample_total") %>%
  filter(!Bayside=='Control')

# in day vs night?
Total_samples_DayNight <- as.data.frame(samples_2024_exp_mifish) %>%
  group_by(Night__Day) %>%
  count(name = "Night_day_sample_total") %>%
  na.omit()

Total_samples_habitat
Total_samples_EW
Total_samples_DayNight
```

```{r}
# join sample totals to dataframe so there is a denomenator for the calculation
ps2024_exp_mifish_glommed_df_2 <- full_join(ps2024_exp_mifish_glommed_df, Total_samples_habitat, by = "Habitat")
ps2024_exp_mifish_glommed_df_2 <- full_join(ps2024_exp_mifish_glommed_df_2, Total_samples_EW, by = "Bayside")
ps2024_exp_mifish_glommed_df_2 <- full_join(ps2024_exp_mifish_glommed_df_2, Total_samples_DayNight, by = "Night__Day")


ps2024_exp_mifish_glommed_df_2

```

Calculate site occupancy for each species
```{r}
# Habitat
Species_occurences_habitat <- ps2024_exp_mifish_glommed_df_2 %>%
  group_by(Species.CommonName, Habitat) %>%
  count(name = "Sp_occ_in_habitat")

ps2024_exp_mifish_glommed_df_2 <- full_join(ps2024_exp_mifish_glommed_df_2, Species_occurences_habitat, by = c("Habitat"="Habitat","Species.CommonName"="Species.CommonName"))

#Bayside
Species_occurences_bayside <- ps2024_exp_mifish_glommed_df_2 %>%
  group_by(Species.CommonName, Bayside) %>%
  count(name = "Sp_occ_in_bayside")

ps2024_exp_mifish_glommed_df_2 <- full_join(ps2024_exp_mifish_glommed_df_2, Species_occurences_bayside, by = c("Bayside"="Bayside","Species.CommonName"="Species.CommonName"))

#Daynight
Species_occurences_daynight <- ps2024_exp_mifish_glommed_df_2 %>%
  group_by(Species.CommonName, Night__Day) %>%
  count(name = "Sp_occ_in_DayNight")

ps2024_exp_mifish_glommed_df_2 <- full_join(ps2024_exp_mifish_glommed_df_2, Species_occurences_daynight, by = c("Night__Day"="Night__Day","Species.CommonName"="Species.CommonName"))


# Calculate occurrence over sample total
Species_occurences_habitat <- ps2024_exp_mifish_glommed_df_2 %>%
  group_by(Species.CommonName, Habitat, Habitat_sample_total, Sp_occ_in_habitat) %>%
  mutate(Species_occurences_in_habitat = Sp_occ_in_habitat/Habitat_sample_total) %>%
  select(Species.CommonName, CommonName, Habitat, Species_occurences_in_habitat) %>%
  distinct()
Species_occurences_habitat

Species_occurences_bayside <- ps2024_exp_mifish_glommed_df_2 %>%
  group_by(Species.CommonName, Bayside, Bayside_sample_total, Sp_occ_in_bayside) %>%
  mutate(Species_occurences_in_bayside = Sp_occ_in_bayside/Bayside_sample_total) %>%
  select(Species_occurences_in_bayside, CommonName, Bayside, Species_occurences_in_bayside) %>%
  distinct()
Species_occurences_bayside

Species_occurences_daynight <- ps2024_exp_mifish_glommed_df_2 %>%
  group_by(Species.CommonName, Night__Day, Night_day_sample_total, Sp_occ_in_DayNight) %>%
  mutate(Species_occurences_in_daynight = Sp_occ_in_DayNight/Night_day_sample_total) %>%
  select(Species.CommonName, CommonName, Night__Day, Species_occurences_in_daynight) %>%
  distinct()
Species_occurences_daynight


```

Plot
```{r}
speciesoccurrence_habitat <- ggplot(data = Species_occurences_habitat, aes(x = CommonName, y = Species_occurences_in_habitat, fill = Habitat))+
  geom_bar(stat = "identity", position = position_dodge(preserve = "single"), color = "black", linewidth = 0.25)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.title = element_blank(),
        text = element_text(size = 14)) +  ylab("Species Occurrence")+
  xlab("")+
  scale_fill_manual(values = c("azure2", "chartreuse4", "cadetblue1", "darkgrey"))
speciesoccurrence_habitat

speciesoccurrence_daynight <- ggplot(data = Species_occurences_daynight, aes(x = CommonName, y = Species_occurences_in_daynight, fill = Night__Day))+
  geom_bar(stat = "identity", position = position_dodge(preserve = "single"), color = "black", linewidth = 0.25)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.title = element_blank(),
        text = element_text(size = 14)) +  ylab("Species Occurrence")+
  xlab("")+
  scale_fill_manual(values = c("cornsilk", "antiquewhite4"))
speciesoccurrence_daynight

speciesoccurrence_bayside <- ggplot(data = Species_occurences_bayside, aes(x = CommonName, y = Species_occurences_in_bayside, fill = Bayside))+
  geom_bar(stat = "identity", position = position_dodge(preserve = "single"), color = "black", linewidth = 0.25)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.title = element_blank(),
        text = element_text(size = 14)) +
  ylab("Species Occurrence")+
  xlab("")+
  scale_fill_manual(values = c("coral", "cornflowerblue"))
speciesoccurrence_bayside


ggsave(plot = speciesoccurrence_habitat, filename = "figures-expedition/speciesoccurrence_habitat.eps", width = 12, height = 5, units = "in")

ggsave(plot = speciesoccurrence_daynight, filename = "figures-expedition/speciesoccurrence_daynight.eps", width = 12, height = 5, units = "in")

ggsave(plot = speciesoccurrence_bayside, filename = "figures-expedition/speciesoccurrence_bayside.eps", width = 12, height = 5, units = "in")

ggsave(plot = speciesoccurrence_habitat, filename = "figures-expedition/speciesoccurrence_habitat.jpg", width = 12, height = 5, units = "in")

ggsave(plot = speciesoccurrence_daynight, filename = "figures-expedition/speciesoccurrence_daynight.jpg", width = 12, height = 5, units = "in")

ggsave(plot = speciesoccurrence_bayside, filename = "figures-expedition/speciesoccurrence_bayside.jpg", width = 12, height = 5, units = "in")

```

### Elas02

```{r}
# How many total samples taken in each habitat type?
Total_samples_habitat <- as.data.frame(samples_2024_exp_elas) %>%
  group_by(Habitat) %>%
  count(name = "Habitat_sample_total") %>%
  na.omit()

# in east vs west?
Total_samples_EW <- as.data.frame(samples_2024_exp_elas) %>%
  group_by(Bayside) %>%
  count(name = "Bayside_sample_total") %>%
  filter(!Bayside=='Control')

# in day vs night?
Total_samples_DayNight <- as.data.frame(samples_2024_exp_elas) %>%
  group_by(Night__Day) %>%
  count(name = "Night_day_sample_total") %>%
  na.omit()

Total_samples_habitat
Total_samples_EW
Total_samples_DayNight
```



```{r}
# join sample totals to dataframe so there is a denomenator for the calculation
ps2024_exp_elas_glommed_df_2 <- full_join(ps2024_exp_elas_glommed_df, Total_samples_habitat, by = "Habitat")
ps2024_exp_elas_glommed_df_2 <- full_join(ps2024_exp_elas_glommed_df_2, Total_samples_EW, by = "Bayside")
ps2024_exp_elas_glommed_df_2 <- full_join(ps2024_exp_elas_glommed_df_2, Total_samples_DayNight, by = "Night__Day")


# there are no elasmos detected at oyster reef sites so there is an empty row. Delete
ps2024_exp_elas_glommed_df_2 <- ps2024_exp_elas_glommed_df_2 %>% filter(!is.na(OTU))


ps2024_exp_elas_glommed_df_2

```


Calculate site occupancy for each species
```{r}
# Habitat
Species_occurences_habitat <- ps2024_exp_elas_glommed_df_2 %>%
  group_by(Species.CommonName, Habitat) %>%
  count(name = "Sp_occ_in_habitat")

ps2024_exp_elas_glommed_df_2 <- full_join(ps2024_exp_elas_glommed_df_2, Species_occurences_habitat, by = c("Habitat"="Habitat","Species.CommonName"="Species.CommonName"))

#Bayside
Species_occurences_bayside <- ps2024_exp_elas_glommed_df_2 %>%
  group_by(Species.CommonName, Bayside) %>%
  count(name = "Sp_occ_in_bayside")

ps2024_exp_elas_glommed_df_2 <- full_join(ps2024_exp_elas_glommed_df_2, Species_occurences_bayside, by = c("Bayside"="Bayside","Species.CommonName"="Species.CommonName"))

#Daynight
Species_occurences_daynight <- ps2024_exp_elas_glommed_df_2 %>%
  group_by(Species.CommonName, Night__Day) %>%
  count(name = "Sp_occ_in_DayNight")

ps2024_exp_elas_glommed_df_2 <- full_join(ps2024_exp_elas_glommed_df_2, Species_occurences_daynight, by = c("Night__Day"="Night__Day","Species.CommonName"="Species.CommonName"))


# Calculate occurrence over sample total
Species_occurences_habitat <- ps2024_exp_elas_glommed_df_2 %>%
  group_by(Species.CommonName, Habitat, Habitat_sample_total, Sp_occ_in_habitat) %>%
  mutate(Species_occurences_in_habitat = Sp_occ_in_habitat/Habitat_sample_total) %>%
  select(Species.CommonName, CommonName, Habitat, Species_occurences_in_habitat) %>%
  distinct()
Species_occurences_habitat

Species_occurences_bayside <- ps2024_exp_elas_glommed_df_2 %>%
  group_by(Species.CommonName, Bayside, Bayside_sample_total, Sp_occ_in_bayside) %>%
  mutate(Species_occurences_in_bayside = Sp_occ_in_bayside/Bayside_sample_total) %>%
  select(Species.CommonName, CommonName, Bayside, Species_occurences_in_bayside) %>%
  distinct()
Species_occurences_bayside

Species_occurences_daynight <- ps2024_exp_elas_glommed_df_2 %>%
  group_by(Species.CommonName, Night__Day, Night_day_sample_total, Sp_occ_in_DayNight) %>%
  mutate(Species_occurences_in_daynight = Sp_occ_in_DayNight/Night_day_sample_total) %>%
  select(Species.CommonName, CommonName, Night__Day, Species_occurences_in_daynight) %>%
  distinct()
Species_occurences_daynight


```



Plot
```{r}
speciesoccurrence_habitat <- ggplot(data = Species_occurences_habitat, aes(x = CommonName, y = Species_occurences_in_habitat, fill = Habitat))+
  geom_bar(stat = "identity", position = position_dodge(preserve = "single"), color = "black", linewidth = 0.25)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.title = element_blank(),
        text = element_text(size = 14)) +
  ylab("Species Occurrence")+
  xlab("")+
  scale_fill_manual(values = c("azure2", "chartreuse4", "cadetblue1", "darkgrey"))
speciesoccurrence_habitat

speciesoccurrence_daynight <- ggplot(data = Species_occurences_daynight, aes(x = CommonName, y = Species_occurences_in_daynight, fill = Night__Day))+
  geom_bar(stat = "identity", position = position_dodge(preserve = "single"), color = "black", linewidth = 0.25)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.title = element_blank(),
        text = element_text(size = 14)) +
  ylab("Species Occurrence")+
  xlab("")+
  scale_fill_manual(values = c("cornsilk", "antiquewhite4"))
speciesoccurrence_daynight

speciesoccurrence_bayside <- ggplot(data = Species_occurences_bayside, aes(x = CommonName, y = Species_occurences_in_bayside, fill = Bayside))+
  geom_bar(stat = "identity", position = position_dodge(preserve = "single"), color = "black", linewidth = 0.25)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.title = element_blank(),
        text = element_text(size = 14)) +
  ylab("Species Occurrence")+
  xlab("")+
  scale_fill_manual(values = c("coral", "cornflowerblue"))
speciesoccurrence_bayside


ggsave(plot = speciesoccurrence_habitat, filename = "figures-expedition/speciesoccurrence_habitat_elas.eps", width = 5, height = 5, units = "in")

ggsave(plot = speciesoccurrence_daynight, filename = "figures-expedition/speciesoccurrence_daynight_elas.eps", width = 5, height = 5, units = "in")

ggsave(plot = speciesoccurrence_bayside, filename = "figures-expedition/speciesoccurrence_bayside_elas.eps", width = 5, height = 5, units = "in")




ggsave(plot = speciesoccurrence_habitat, filename = "figures-expedition/speciesoccurrence_habitat_elas.jpg", width = 5, height = 5, units = "in")

ggsave(plot = speciesoccurrence_daynight, filename = "figures-expedition/speciesoccurrence_daynight_elas.jpg", width = 5, height = 5, units = "in")

ggsave(plot = speciesoccurrence_bayside, filename = "figures-expedition/speciesoccurrence_bayside_elas.jpg", width = 5, height = 5, units = "in")

```




## spOccupancy
There are more sophisticated ways of examining occupancy that depend on modeling probabilities and that will give error estimates. Several R packages exist, [spOccupancy](https://doserlab.com/files/spoccupancy-web/) seems the most well developed and widely used, including on metabarcoding data. See [vignette](https://doserlab.com/files/spoccupancy-web/articles/modelfitting).

Start to format data set. 
- `spOccupancy` expects presence/absence data rather than counts
- assesses both "occurrence" covariates and "detection" covariates in separate matrices
  - "occurrence" covariates are "site-level" variables. Environmental parameters (salinity, depth, etc)
  - "detection" covariates are "observation/survey-level" variables due to sampling itself (day, time, etc.)
  
  
Notes on how to interpret:

1. Community-level Parameters (average effect of covariates across all species)
  - All the posterior means are on the logit scale (log-odds).
  - Rhat values > 1.1, and low ESS (effective sample size) are a sign of poor convergence, so treat with caution
  - If a credible interval does not exclude zero, theres no strong community-level signal. For example: if Avg_Temperature_C mean = 0.84, but CI: -1.79 to 3.85 --> inconclusive, however... 
  - Even if the 95% CI includes zero, a covariate whose posterior lies, for example, 80% above zero may still be interesting. Can pull those "beta" probabilies out with something like
  
  `post_prob_comm <- apply(model_out_elas$beta.comm.samples, 2, function(x) mean(x > 0))` and `post_prob_comm <- apply(model_out_elas$beta.samples, 2, function(x) mean(x > 0))`
  
  So it the posterior mean for temperature at the community level is 1.1368, for example, and the beta is 0.75, then the probability that temperature has a positive effect on occupancy is 0.75.

2. Species-specific Occupancy Effects. These show how each individual ASVs occupancy probability changes per unit change in the covariate.
  - Example:
    - Avg_Temperature_C-ASV_1: Mean = 1.99, SD = 3.41, CI = -2.45 to 11.14
      - --> ASV_1 may respond positively to temperature, though the CI is wide and crosses zero
    - Avg_Salinity_psu-ASV_9: Mean = -1.48, SD = 2.89, CI = -8.76 to 2.29
      - --> ASV_9 is negatively associated with salinity
  - Interpret with caution if ASVs have large standard deviations (including for intercepts) and wide credible intervals, especially if CI includes 0.
    - Rhat values above 1.2, and low ESS (<100), suggest parameters didn't converge well.
    - Might reflect either high variability in occupancy or model instability due to limited data for some ASVs.
    - Approach to plotting, for example, temperature effect on all species for comparison:
    

3. Detection Effects. These tell you how detection varies conditional on presence.
  - Example:
    - For specific ASVs (e.g., Day-ASV_7 = 4.58  2.2, CI does not include 0), day sampling clearly improves detection.
    - ALso have "INtercept" mean values, which are the strength of the detection under reference conditions. E.g. Intercept-ASV_7 = -74.8  35.9 means that even if present, detection is very unlikely unless covariates push it up.

4. Variance Terms. These describe variation among species in their responses to covariates.
  - Large variances (especially >1000) suggest strong heterogeneity across species.
  - Example: Variance-BaysideW = 14,263, Variance-Intercept = 3601 --> huge spread in species responses.
  - If convergence is poor (Rhat > 1.1, ESS < 100), dont over-interpret.
  - You can plot variances to see for example which taxa are most sensitive:

    ```
    temp_effects <- model_out_elas$beta.samples[, grep("Avg_Temperature_C", colnames(model_out_elas$beta.samples))]
    temp_long <- as.data.frame(temp_effects) %>%
    pivot_longer(
    cols      = everything(),
    names_to  = "ASV",
    values_to = "effect"
    )
    # make a horizontal boxplot per ASV, ordered by median
    ggplot(temp_long, aes(x = effect, y = fct_reorder(ASV, effect, .fun = median))) +
    geom_boxplot(fill = "steelblue", alpha = 0.7, outlier.size = 1) +
    stat_summary(fun = median, geom = "point", shape = 23, size = 2, fill = "white") + 
    coord_cartesian(expand = FALSE) +
    labs(
    x     = "Temperatureeffect posterior",
    y     = "ASV",
    title = "Specieslevel Temperature Effects"
    ) +
    theme_minimal(base_size = 12) +
    theme(
    axis.text.y = element_text(size = 6),
    panel.grid.major.y = element_blank()
    )
    ```



### Elas02
#### Prepare data
Test with Elas df to start since it's smaller...
Use dfs where controls were already removed. Simplify metadata variables
```{r}
elas_2024_exp_asv_table_taxbased
elas_2024_exp_sample_data_taxbased
elas_2024_exp_tax_table_taxbased
colnames(elas_2024_exp_sample_data_taxbased)
```


Simplify sample names, remove redundant or unuseful metadata
```{r}
# Simplify sample names in count table
elas_exp_df_counttable <- elas_2024_exp_asv_table_taxbased %>%
  rename_with(~str_extract(.x, "\\d+_\\d+"))

# Simplify sample names in sample data table
elas_exp_df_sampledata <- elas_2024_exp_sample_data_taxbased
rownames(elas_exp_df_sampledata) <- str_extract(rownames(elas_exp_df_sampledata), "\\d+_\\d+")

# Remove some columns in sample data
elas_exp_df_sampledata <- elas_exp_df_sampledata %>%
  select(
    -Name_Deploy_Cartr_Library,
    -Name.Deploy_Cartr,
    -Deployment,
    -Cartridge_ID,
    -Site_type,
    -controls,
    -Date,
    -End_Time__ET_,
    -Datecode,
    -Year,
    -Month,
    -Deploy_Cartr_Library)

elas_exp_df_counttable
glimpse(elas_exp_df_sampledata)

```







Convert counts to presence/ absence 
```{r}
elas_exp_df_countmatrix <- elas_exp_df_counttable
elas_exp_df_countmatrix[] <- ifelse(elas_exp_df_countmatrix > 0, 1, 0)

# compare
elas_exp_df_counttable
elas_exp_df_countmatrix
```


Occupancy and Detection Covariates
```{r}
# Helper function to get mean for numerics, mode for factors/characters
mean_or_mode <- function(x) {
  if (is.numeric(x)) {
    return(mean(x, na.rm = TRUE))
  } else if (is.factor(x) || is.character(x)) {
    ux <- unique(na.omit(x))
    if (length(ux) == 1) return(ux)
    return(ux[which.max(tabulate(match(x, ux)))])
  } else {
    return(NA)
  }
}


# Occupancy covariates: one row per unique replicate group
# Don't include spatial variables because that is built into coords later and would lead to redundancy
occ.covs <- elas_exp_df_sampledata %>%
  group_by(replicates) %>%
  summarize(across(c(Bayside, Habitat, Night__Day, Avg_Depth_m, Avg_Temperature_C, Avg_Salinity_psu, Avg_Chlorophyll_ugL, Avg_Turbidity_NTU), mean_or_mode)) %>%
  as.data.frame()
# remove rep names and use as IDs
rownames(occ.covs) <- occ.covs$replicates
occ.covs$replicates <- NULL



# Detection covariates: list of matrices for each sampling variable. Matrix contains sites and replicates
# Extract and sort by rep
det_grouped <- elas_exp_df_sampledata[, c("replicates", "Volume_liter", "Start_Time__ET_", "Day")] %>%
  group_by(replicates) %>%
  arrange(replicates) %>%
  mutate(rep_id = row_number()) %>%
  ungroup()

# Reshape to wide format for each covariate
vol_mat <- det_grouped %>%
  select(replicates, rep_id, Volume_liter) %>%
  pivot_wider(names_from = rep_id, values_from = Volume_liter) %>%
  column_to_rownames("replicates") %>%
  as.matrix()

day_mat <- det_grouped %>%
  select(replicates, rep_id, Day) %>%
  pivot_wider(names_from = rep_id, values_from = Day) %>%
  column_to_rownames("replicates") %>%
  as.matrix()

# use decimal hour for time
start_time_mat <- det_grouped %>%
  select(replicates, rep_id, Start_Time__ET_) %>%
  mutate(Start_Time__ET_ = hms::as_hms(as.character(Start_Time__ET_)),
         Start_Time__ET_ = hour(Start_Time__ET_) + 
                           minute(Start_Time__ET_) / 60 + 
                           second(Start_Time__ET_) / 3600) %>%
  pivot_wider(names_from = rep_id, values_from = Start_Time__ET_) %>%
  column_to_rownames("replicates") %>%
  as.matrix()

# Combine into a named list
det.covs <- list(
  Volume_liter = vol_mat,
  Day = day_mat,
  Start_Time = start_time_mat
)

occ.covs
det.covs
```

Drop strongly correlated covariates (leads to errors later)---
```{r}
# Get Pearson correlation matrix for numeric occupancy covariates
num_covs <- occ.covs[, sapply(occ.covs, is.numeric)]
cor_matrix <- cor(num_covs, use = "complete.obs")
round(cor_matrix, 2)
```
None are greater than 0.9. Keep all

Check categorical variables to see if any are represented in only 1-2 sites, which can cause errors
```{r}
table(occ.covs$Bayside)
table(occ.covs$Habitat)
```
Clam sanctuary only represented once...

Change both "CLAM SANCTUARY" and "EELGRASS" to "RESTORED" so they will be one category
```{r}
occ.covs$Habitat <- as.character(occ.covs$Habitat)  # convert to character if factor
occ.covs$Habitat[occ.covs$Habitat %in% c("CLAM SANCTUARY", "EELGRASS")] <- "RESTORED"
occ.covs$Habitat <- factor(occ.covs$Habitat)  # convert back to factor

occ.covs
```



Transform count matrix to a 3D array y[i,j,k], where:
i indexes species (ASVs),
j indexes sites (i.e., unique replicate groups),
k indexes replicate samples at that site.

Group samples based on replicates column. Reorganize so all replicates are aligned based on `occ.covs`
```{r}
# Unique replicate groups
replicate_groups <- rownames(occ.covs)

# Sort samples by replicate groups
elas_exp_df_sampledata <- elas_exp_df_sampledata[order(elas_exp_df_sampledata$replicates), ]

# Initialize 3D y array
n_species <- nrow(elas_exp_df_countmatrix)
n_sites <- length(unique(elas_exp_df_sampledata$replicates)) # "sites" are unique to time/day/location
max_reps <- max(table(elas_exp_df_sampledata$replicates))

y_array <- array(NA, dim = c(n_species, n_sites, max_reps))

# Populate the array
for (i in seq_along(replicate_groups)) {
  reps <- rownames(elas_exp_df_sampledata)[elas_exp_df_sampledata$replicates == replicate_groups[i]]
  for (j in seq_along(reps)) {
    y_array[, i, j] <- elas_exp_df_countmatrix[, reps[j]]
  }
}

# Retain names
dimnames(y_array) <- list(
  rownames(elas_exp_df_countmatrix),  # species (rows)
  unique(elas_exp_df_sampledata$replicates),     # sites (columns)
  as.character(seq_len(dim(y_array)[3]))       # replicate number (slices)
)

y_array
```
I triple checked that these columns match up with the same order of sample/ replicates in the covariate matrices.



and coords
```{r}
# Create coords data frame for spatial transformation
coords_df <- elas_exp_df_sampledata %>%
  group_by(replicates) %>%
  summarize(across(c(long, lat), mean_or_mode), .groups = "drop")  # .groups avoids grouping issues

# Convert to sf object
coords_sf <- st_as_sf(coords_df, coords = c("long", "lat"), crs = 4326)

# Transform to UTM Zone 18N
coords_utm <- st_transform(coords_sf, crs = 32618)

# Extract projected coordinates in meters
coords_projected <- st_coordinates(coords_utm)

# Set row names to match your occupancy covariates
rownames(coords_projected) <- rownames(occ.covs)

head(coords_projected)

```


Make into one list for spOccupancy
```{r}
# Final data list for spPGOcc
elas.exp.list <- list(
  y = y_array,
  occ.covs = occ.covs,
  det.covs = det.covs,
  coords = coords_projected
)

str(elas.exp.list)
```

#### Run non-spatial model (Multi-Species Occupancy Using Polya-Gamma Latent Variables)
Try runnning the multi species latency model (no spatial effect) first. Use default parameters (vignette says this is generally OK).
I kept messing with n.samples, n.burn, and n.thin based on Rhat and ESS values to optimize values.

I also learned that `scale()` works columnwise in a matrix or df, so it centers and scales column by its own mean and sd. Using it on the det.covs messes things up and means the day "10" ends up having two different z-scores depending on how many samples are in each replicate column. The occ.covs are vectors and do not have the same problem. The days are linear and I modfied the times to be decimal anyway, so do not `scale` any of the detection covariates

```{r}
set.seed(20250615)

# Set priors
priors <- list(
  beta.comm.normal = list(mean = 0, var = 2.72),
  alpha.comm.normal = list(mean = 0, var = 2.72),
  tau.sq.beta.ig = list(a = 0.1, b = 0.1),
  tau.sq.alpha.ig = list(a = 0.1, b = 0.1)
)

# Set initial values
inits <- list(
  beta.comm = rep(0, 7),  # Adjust to number of occupancy covariates
  alpha.comm = rep(0, 4), # Adjust to number of detection covariates
  tau.sq.beta = 1,
  tau.sq.alpha = 1
)

model_out_elas <- msPGOcc(
  occ.formula = ~ Bayside + Habitat + Night__Day + 
                 scale(Avg_Depth_m) + scale(Avg_Temperature_C) + 
                 scale(Avg_Salinity_psu),
  det.formula = ~ Volume_liter + Day + Start_Time,
  data = elas.exp.list,
  n.samples = 75000,
  n.burn = 25000,
  n.thin = 10,
  n.chains = 3,
  priors = priors, 
  inits = inits,
  verbose = TRUE,
  n.report = 1000
)


```

##### Save model
```{r}
# save(model_out_elas, file = "figures-expedition/model_out_elas")
# load("figures-expedition/model_out_elas")
```

##### Examine output
```{r}
# sink(file.path("figures-expedition", "model_out_elas_summary.txt"))
# summary(model_out_elas)
# sink()
```



##### Check Model diagnostics
###### 1. Convergence diagnostics
'Density` plots are a visual way of looking at mean and CI. See if the mean is far from zero and if the tails overlap zero.
Rhat values should ideally be close to 1.0 (below ~1.1);, especially for variances  which may suggest convergence issues.
Check Effective Sample Size (ESS): Low ESS (<200) can indicate poor sampling.

(for some reason doesn't plot in notebook- run in console)
NOTE- the model above was iteratively adjusted based on feedback from these diagnostics

```{r}
plot(model_out_elas, param = "beta")  # Fixed effects
plot(model_out_elas, param = "alpha") # Detection
```


What you want to see

- Good mixing: all three chains should overlap heavily, with no one chain stuck in a corner.
- Stationarity: after a short burn-in wiggle, the trace should look like random noise, not a slow trend upward or downward.
- Reasonable spread: the posterior density should be unimodal (one bump), not multi-peaked or extremely skewed (unless really expected).
- No crazy outliers or spikes that suggest the sampler is occasionally taking massive jumps.


Scanning through these, look for whether: 1) the posterior is centered away from zero. If it is, it suggests a non zero effect of the covariate on species occupancy, 2) if the 95% intervals are narrow and exclude zero, 3) that the shape is unimodal and smooth
- Overall, these are all unimodal and smooth although some have longish tails. The ones that center away from zero largely overlap with the interpretation based on mean and CI below

###### 2. Posterior predictive checks

From [here](https://doserlab.com/files/spoccupancy-web/articles/modelfitting):

- "The Bayesian p-value is the proportion of posterior samples of the fit statistic of the model generated data that are greater than the corresponding fit statistic of the true data, summed across all grouped data points"
- binning the data across sites (group = 1) may help reveal whether the model fails to adequately represent variation in occurrence and detection probability across space, while binning the data across replicates (group = 2) may help reveal whether the model fails to adequately represent variation in detection probability across the different replicate surveys. Similarly, we suggest exploring posterior predictive checks using both the Freeman-Tukey Statistic as well as the Chi-Squared statistic."

```{r}
ppc.out1 <- ppcOcc(model_out_elas, fit.stat = 'freeman-tukey', group = 1)
summary(ppc.out1)

ppc.out2 <- ppcOcc(model_out_elas, fit.stat = 'freeman-tukey', group = 2)
summary(ppc.out2)

ppc.out3 <- ppcOcc(model_out_elas, fit.stat = 'chi-squared', group = 1)
summary(ppc.out3)

ppc.out4 <- ppcOcc(model_out_elas, fit.stat = 'chi-squared', group = 2)
summary(ppc.out4)

```




--> Tells how well the model can replicate the observed data. This statistic is good for sparse or zero-inflated data (like eDNA) and down-weights large count differences

- A Bayesian p-value  0.5 is ideal.
- Values < 0.1 or > 0.9 suggest lack of fit.
- Slightly low/high values (e.g., 0.070.10 or 0.900.93) suggest potential mild misfit, but aren't typically cause for major concern.


Results:
Across all 4 checks, the communitylevel Bayesian pvalues are 0.110.13
--> not perfect, but not grossly misfitting either

At the species level:
- ASV_1, 2, 13 all have p<0.05 --> the models occupancy patterns for these taxa are consistently off
- ASV_9 is on the fence with p0.050.06
- ASV_7 and ASV_14 look fine


###### 3. WAIC for model comparison

```{r}
waicOcc(model_out_elas)

```


What each metric means:
1. WAIC (Widely Applicable Information Criterion) = 72.33
Lower WAIC is better when comparing models. The WAIC alone isnt meaningful unless comparing it to WAIC from another model.
It reflects both how well the model fits the data and how complex it is (i.e., it penalizes overfitting).

2. elpd (Expected Log Predictive Density) = -20.91
Measures the models predictive accuracy: how well it predicts new data.
More positive values indicate better predictive performance.
This number is related to WAIC by: WAIC  -2 * elpd.

3. pD (effective number of parameters) = 15.26
Reflects the models complexity.
A higher value indicates a more flexible (and potentially overfit) model.
Given that there are only have 6 species and a modest number of covariates, a pD around 15 is reasonable.

##### Summary for manuscript - Elas02 Figures

Non spatial model had better WAIC so present the non spatial in the paper. Examine further...


Make a table with community-level occupancy effects, as well as their probabilities. Contains the:
- log-odds ratio (logit)
- the SD of the logit score
- the 95% CI of the logit score
- the probability of the occupancy for that particular covariate being positive (Ppos)
- the probability of the occupancy for that particular covariate being negative (Pneg)
- the percentagepoint change in occupancy probability (DeltaP_mean). i.e. if DeltaP_mean = +0.25, then there is a 25% increase in occupancy probability due to that covariate. If DeltaP_mean = -0.25, then on average, occupancy probability drops by 25% percentage points when this covariate is applied.
  - DeltaP is calculated by propagating the entire posterior distribution of both the intercept, alpha, and the covariate effect (draws), beta, through the inverse-logit, `plogis(alpha + draws) - plogis(alpha)`
- the 5.5% and 94.5% quantiles of the DeltaP_mean (DeltaP_lo, DeltaP_hi), so the credible interval for the probability difference.
- the "effect" of the covariate on occupancy (depends on if Probability of being positive [or negative] is greater than 89%)
  - NOTE 89% cutoff [rather than 95%] was chosen based on [Tetzlaff et al.](https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.579) and is commonly used in Bayesian workflows

```{r}
occ_mat <- model_out_elas$beta.comm.samples   # occupancy
det_mat <- model_out_elas$alpha.comm.samples  # detection

# make sure rhat/ESS vectors are named to match columns
names(model_out_elas$rhat$beta.comm)  <- colnames(occ_mat)
names(model_out_elas$rhat$alpha.comm) <- colnames(det_mat)
names(model_out_elas$ESS$beta.comm)   <- colnames(occ_mat)
names(model_out_elas$ESS$alpha.comm)  <- colnames(det_mat)

summ_comm_block <- function(mat, type_label){
  params <- colnames(mat)
  intercept_name <- "(Intercept)"
  bind_rows(
    lapply(params, function(p){
      draws <- mat[, p]
      alpha <- mat[, intercept_name]
      
      # extract Rhat and ESS for this parameter
      rhat_val <- if(type_label == "Occurrence") model_out_elas$rhat$beta.comm[p]  else model_out_elas$rhat$alpha.comm[p]
      ess_val  <- if(type_label == "Occurrence") model_out_elas$ESS$beta.comm[p]   else model_out_elas$ESS$alpha.comm[p]
      
      m    <- mean(draws)
      s    <- sd(draws)
      ci   <- quantile(draws, c(0.055, 0.945))
      ppos <- mean(draws > 0)
      pneg <- mean(draws < 0)
      
      dp    <- plogis(alpha + draws) - plogis(alpha)
      dp_m  <- mean(dp)
      dp_ci <- quantile(dp, c(0.055, 0.945))
      
      tibble(
        Process      = type_label,
        Covariate    = p,
        Mean_logit   = m,
        SD_logit     = s,
        CI2.5_logit  = ci[1],
        CI97.5_logit = ci[2],
        Ppos         = ppos,
        Pneg         = pneg,
        Effect       = case_when(
                         ppos > 0.89 ~ "positive",
                         pneg > 0.89 ~ "negative",
                         TRUE        ~ "ambiguous"
                       ),
        DeltaP_mean  = dp_m,
        DeltaP_lo    = dp_ci[1],
        DeltaP_hi    = dp_ci[2],
        Rhat         = rhat_val,
        ESS          = ess_val,
        Convergence  = case_when(
                         Rhat > 1.1  ~ "High Rhat",
                         ESS < 200   ~ "Low ESS",
                         TRUE        ~ "Converged"
                       )
      )
    })
  )
}

summ_occ <- summ_comm_block(occ_mat, "Occurrence")
summ_det <- summ_comm_block(det_mat, "Detection")

summ_comm_all <- bind_rows(summ_occ, summ_det)

summ_comm_all
```





Species level. Do same but also add in sp names

```{r}
occ_mat <- as.matrix(model_out_elas$beta.samples)   # occurrence 
det_mat <- as.matrix(model_out_elas$alpha.samples)  # detection 

# name the specieslevel rhat/ESS to match columns
names(model_out_elas$rhat$beta)  <- colnames(occ_mat)
names(model_out_elas$rhat$alpha) <- colnames(det_mat)
names(model_out_elas$ESS$beta)   <- colnames(occ_mat)
names(model_out_elas$ESS$alpha)  <- colnames(det_mat)

summ_block_mat <- function(mat, process_label) {
  params   <- colnames(mat)
  species  <- unique(sub(".*-(ASV_\\d+)$", "\\1", params))
  covs     <- unique(sub("^(.*)-ASV_\\d+$", "\\1", params))

  bind_rows(
    lapply(species, function(sp) {
      alpha_draws <- mat[, paste0("(Intercept)-", sp)]

      bind_rows(
        lapply(covs, function(cov) {
          colnm <- paste0(cov, "-", sp)
          draws <- mat[, colnm]

          # extract Rhat and ESS for this parameter
          rhat_val <- if(process_label == "Occurrence") model_out_elas$rhat$beta[colnm]  else model_out_elas$rhat$alpha[colnm]
          ess_val  <- if(process_label == "Occurrence") model_out_elas$ESS$beta[colnm]   else model_out_elas$ESS$alpha[colnm]

          m    <- mean(draws)
          s    <- sd(draws)
          ci   <- quantile(draws, c(0.055, 0.945))
          ppos <- mean(draws > 0)
          pneg <- mean(draws < 0)

          dp    <- plogis(alpha_draws + draws) - plogis(alpha_draws)
          dp_m  <- mean(dp)
          dp_ci <- quantile(dp, c(0.055, 0.945))

          tibble(
            ASV           = sp,
            Process       = process_label,
            Covariate     = cov,
            Mean_logit    = m,
            SD_logit      = s,
            CI2.5_logit   = ci[1],
            CI97.5_logit  = ci[2],
            Ppos          = ppos,
            Pneg          = pneg,
            Effect        = case_when(
                              ppos > 0.89 ~ "positive",
                              pneg > 0.89 ~ "negative",
                              TRUE        ~ "ambiguous"
                            ),
            DeltaP_mean   = 100 * dp_m,       # percentagepoint units
            DeltaP_lo     = 100 * dp_ci[1],
            DeltaP_hi     = 100 * dp_ci[2],
            Rhat          = rhat_val,
            ESS           = ess_val,
            Convergence   = case_when(
                              Rhat > 1.1  ~ "High Rhat",
                              ESS < 200   ~ "Low ESS",
                              TRUE        ~ "Converged"
                            )
          )
        })
      )
    })
  )
}

summ_occ <- summ_block_mat(occ_mat, "Occurrence")
summ_det <- summ_block_mat(det_mat, "Detection")

summ_sp_all <- bind_rows(summ_occ, summ_det)

# attach species names
tax_df     <- as.data.frame(tax_table(ps2024_exp_elas_glommed))
tax_df$ASV <- rownames(tax_df)
tax_lookup <- tax_df %>% select(ASV, Species.CommonName)

summ_sp_all_named <- summ_sp_all %>%
  left_join(tax_lookup, by = "ASV") %>%
  relocate(Species.CommonName, .after = ASV)

summ_sp_all_named

# view only those rows that show an effect (positive or negative) AND model convergence parameters are acceptable
summ_sp_all_named %>%
  filter(Convergence == "Converged") %>%
  filter(Effect != "ambiguous")

```



save results tables

```{r}

write.csv(summ_comm_all,"figures-expedition/summ_comm_all_elas.csv", row.names = TRUE)
write.csv(summ_sp_all_named,"figures-expedition/summ_sp_all_named_elas.csv", row.names = TRUE)

```


*Results Summary*
--> No community level variables are significant at the 95% level
--> At the species-level many "converged well but have ambiguous probabilities. Gymnura altavela (Spiny Butterfly Ray), is the only which has a significant negative occurrence. This is likely a reflection of it being rare



Community-Level Detection Probability vs. Filtration Volume
```{r}
# posterior draws for the Volume_liter detection covariate
vol_samps <- as.matrix(model_out_elas$alpha.comm.samples)
draws_int <- vol_samps[, "(Intercept)"]
draws_vol <- vol_samps[, "Volume_liter"]

# Sequence of filtration volumes (in L) to predict over
v_seq <- seq(
  min(elas.exp.list$det.covs$Volume_liter, na.rm = TRUE),
  max(elas.exp.list$det.covs$Volume_liter, na.rm = TRUE),
  length.out = 100
)

# predicted detection probabilities across posterior draws
pred_matrix <- sapply(v_seq, function(v) {
  plogis(draws_int + draws_vol * v)
})  # dimensions: iterations  volumes

# Summarize across posterior draws
vol_df <- tibble(
  Volume_liter = v_seq,
  p_mean = colMeans(pred_matrix),
  p_lo   = apply(pred_matrix, 2, quantile, 0.025),
  p_hi   = apply(pred_matrix, 2, quantile, 0.975)
)

# Plot
elas_volume_effect_plot <- ggplot(vol_df, aes(x = Volume_liter, y = p_mean)) +
  geom_ribbon(aes(ymin = p_lo, ymax = p_hi), fill = "grey80", alpha = 0.5) +
  geom_line(size = 1.2, color = "black") +
  labs(
    x = "Filtration Volume (L)",
    y = "Estimated community-level detection probability",
    title = "Effect of Filtration Volume on eDNA Detection Probability: Elas02"
  ) +
  theme_bw()


elas_volume_effect_plot

ggsave(
  plot = elas_volume_effect_plot,
  filename = "figures-expedition/elas_volume_effect_community_detection.jpg",
  width = 6,
  height = 4,
  units = "in",
  dpi = 300
)

```





#### Run spatial model (Multi-Species Spatial Occupancy)
Try running the multi species spatial model, `sfMsPGOcc`

Already have the coordinates in the data object as `coords` but there is an error when same location is sampled twice, even on different days. These are not true replicates but model does want coords repeated (considers them as same site?).

Solution-- use `grid.index` which tells the model to apply the spatial effect at the site level, even if there are multiple samples per site. Preserves temporal replication while satisfying the models spatial requirements.

```{r}
# Convert coords to data frame with column names (these are already projected in meters)
elas.exp.list$coords <- as.data.frame(elas.exp.list$coords)
colnames(elas.exp.list$coords) <- c("long", "lat")

# Create a single string identifier for each coordinate pair
coord_strings <- paste(elas.exp.list$coords$long, elas.exp.list$coords$lat)

# Factor to assign unique grid index numbers for each site
grid.index <- as.integer(as.factor(coord_strings))

# Extract unique coordinates in the same order as grid.index levels
coords_unique <- elas.exp.list$coords[!duplicated(coord_strings), ]

# Make sure coords_unique is in the order of the factor levels
coords_unique <- coords_unique[order(as.integer(factor(coord_strings[!duplicated(coord_strings)]))), ]

# Assign back to data list
elas.exp.list$grid.index <- grid.index # an integer vector mapping the 48 samples to 38 site coordinates
elas.exp.list$coords <- coords_unique  # Must match order of grid.index

```

Check 

```{r}
dim(elas.exp.list$y)[1] # species
dim(elas.exp.list$y)[2] # sites
dim(elas.exp.list$y)[3] # replicates
length(elas.exp.list$grid.index) # one site per sample
nrow(elas.exp.list$coords) #unique sites
```

```{r}
set.seed(20250615)

# Set MCMC parameters
n.batch <- 7500
batch.length <- 10
n.samples <- n.batch * batch.length

# Define priors and tuning
priors <- list(
  beta.comm.normal = list(mean = 0, var = 2.72),
  alpha.comm.normal = list(mean = 0, var = 2.72),
  tau.sq.beta.ig = list(a = 0.1, b = 0.1),
  tau.sq.alpha.ig = list(a = 0.1, b = 0.1)
)

tuning.list <- list(phi = rep(1, 2))  # 2 latent factors

# Lambda initialization
n.factors <- 2
n.species <- dim(elas.exp.list$y)[1]
lambda.inits <- matrix(0, nrow = n.species, ncol = n.factors)
diag(lambda.inits) <- 1
lambda.inits[lower.tri(lambda.inits)] <- rnorm(sum(lower.tri(lambda.inits)))

# Initial values
inits.list <- list(
  alpha.comm = 0,
  beta.comm = 0,
  beta = 0,
  alpha = 0,
  tau.sq.beta = 1,
  tau.sq.alpha = 1,
  phi = rep(3 / mean(dist(elas.exp.list$coords)), n.factors),
  lambda = lambda.inits,
  z = apply(elas.exp.list$y, c(1, 2), max, na.rm = TRUE)
)

# Run the model
sf.elas.out <- sfMsPGOcc(
  occ.formula = ~ Bayside + Habitat + Night__Day + 
                 scale(Avg_Depth_m) + scale(Avg_Temperature_C) + 
                 scale(Avg_Salinity_psu),
  det.formula = ~ Volume_liter + Day + Start_Time,
  data = list(
    y = elas.exp.list$y,
    occ.covs = elas.exp.list$occ.covs,
    det.covs = elas.exp.list$det.covs,
    coords = elas.exp.list$coords,
    grid.index = elas.exp.list$grid.index
  ),
  inits = inits.list,
  priors = priors.list,
  tuning = tuning.list,
  cov.model = "exponential",
  NNGP = TRUE,
  n.neighbors = 20,
  n.factors = n.factors,
  n.batch = n.batch,
  batch.length = batch.length,
  n.burn = 25000,
  n.thin = 10,
  n.chains = 3,
  n.report = 1000,
  n.omp.threads = 3,
  verbose = TRUE)
```



##### Save model
```{r}
# save(sf.elas.out, file = "figures-expedition/sf.elas.out")
# load("figures-expedition/sf.elas.out")
```

##### Examine output

Summarize results
I've been iteratively adjusting parameters in model above to optimize model convergence (Rhat, ESS), and SDs for means/ variances. Variances are no longer extreme (e.g., ~12, not 100+).
```{r}
# sink(file.path("figures-expedition", "model_out_spatial_elas_summary.txt"))
# summary(sf.elas.out)
# sink()

```




##### Check Model diagnostics
###### 1. Convergence diagnostics

```{r}
plot(sf.elas.out, param = "beta")  
plot(sf.elas.out, param = "alpha")
```

--> All traces look like "fuzzy caterpillars," i.e. overlap among 3 chains and nothing stands out too much from other chains. Density plots are unimodal


###### 2. Posterior predictive checks


```{r}
ppc.out1 <- ppcOcc(sf.elas.out, fit.stat = 'freeman-tukey', group = 1)
summary(ppc.out1)

ppc.out2 <- ppcOcc(sf.elas.out, fit.stat = 'freeman-tukey', group = 2)
summary(ppc.out2)

ppc.out3 <- ppcOcc(sf.elas.out, fit.stat = 'chi-squared', group = 1)
summary(ppc.out3)

ppc.out4 <- ppcOcc(sf.elas.out, fit.stat = 'chi-squared', group = 2)
summary(ppc.out4)

```



Results:
Across all 4 checks, the communitylevel Bayesian pvalues are 0.150.20
--> not perfect, but not grossly misfitting either

At the species level:
- ASV_1, 2, and sometimes 13 all have p<0.05 --> the models occupancy patterns for these taxa are consistently off
- ASV_9 is on the fence with p0.060.08
- ASV_7 and ASV_14 look fine
- This is similar to the non spatial model


###### 3. WAIC for model comparison

```{r}
waicOcc(sf.elas.out)

```

--> WAIC for the non spatial model was 71.3, therefore the non spatial model is  more suitable. Stick with Summary for manuscript above








### MiFish
Run libraries as separate models because there is some overlap in detected species- that would conflate things.

#### Prepare data
Use dfs where controls were already removed. Simplify metadata variables

```{r}
mifish_2024_exp_asv_table_taxbased
mifish_2024_exp_sample_data_taxbased
mifish_2024_exp_tax_table_taxbased
colnames(mifish_2024_exp_sample_data_taxbased)
```


Simplify sample names, remove redundant or unuseful metadata, remove controls (MP_C_4ES2_S25_L001,MP_C_5ES2_S25_L001)
```{r}
# Simplify sample names in count table
mifish_exp_df_counttable <- mifish_2024_exp_asv_table_taxbased %>% select(-c(MP_C_4ES2_S25_L001,MP_C_5ES2_S25_L001))
colnames(mifish_exp_df_counttable) <- str_extract(colnames(mifish_exp_df_counttable), "(?<=MP_)[0-9]+_[0-9]+")

# Simplify sample names in sample data table
mifish_exp_df_sampledata <- mifish_2024_exp_sample_data_taxbased %>% filter(!rownames(.) %in% c("MP_C_4ES2_S25_L001","MP_C_5ES2_S25_L001"))
rownames(mifish_exp_df_sampledata) <- str_extract(rownames(mifish_exp_df_sampledata), "(?<=MP_)[0-9]+_[0-9]+")

# Remove some columns in sample data
mifish_exp_df_sampledata <- mifish_exp_df_sampledata %>%
  select(
    -Name.Deploy_Cartr_Library,
    -Deployment,
    -Cartridge_ID,
    -Site_type,
    -site_altname,
    -controls,
    -Date,
    -End_Time__ET_,
    -Datecode,
    -Year,
    -Month,
    -Name.Deploy_Cartr)

mifish_exp_df_counttable
glimpse(mifish_exp_df_sampledata)

```







Convert counts to presence/ absence 
```{r}
mifish_exp_df_countmatrix <- mifish_exp_df_counttable
mifish_exp_df_countmatrix[] <- ifelse(mifish_exp_df_countmatrix > 0, 1, 0)

# compare
mifish_exp_df_counttable
mifish_exp_df_countmatrix
```


Occupancy and Detection Covariates
```{r}
# Occupancy covariates: one row per unique replicate group
# Don't include spatial variables because that is built into coords later and would lead to redundancy
occ.covs <- mifish_exp_df_sampledata %>%
  group_by(replicates) %>%
  summarize(across(c(Bayside, Habitat, Night__Day, Avg_Depth_m, Avg_Temperature_C, Avg_Salinity_psu, Avg_Chlorophyll_ugL, Avg_Turbidity_NTU), mean_or_mode)) %>%
  as.data.frame()
# remove rep names and use as IDs
rownames(occ.covs) <- occ.covs$replicates
occ.covs$replicates <- NULL


# Detection covariates: list of matrices for each sampling variable. Matrix contains sites and replicates
# Extract and sort by rep
det_grouped <- mifish_exp_df_sampledata[, c("replicates", "Volume_liter", "Start_Time__ET_", "Day")] %>%
  group_by(replicates) %>%
  arrange(replicates) %>%
  mutate(rep_id = row_number()) %>%
  ungroup()

# Reshape to wide format for each covariate
vol_mat <- det_grouped %>%
  select(replicates, rep_id, Volume_liter) %>%
  pivot_wider(names_from = rep_id, values_from = Volume_liter) %>%
  column_to_rownames("replicates") %>%
  as.matrix()

day_mat <- det_grouped %>%
  select(replicates, rep_id, Day) %>%
  pivot_wider(names_from = rep_id, values_from = Day) %>%
  column_to_rownames("replicates") %>%
  as.matrix()

# use decimal hour for time
start_time_mat <- det_grouped %>%
  select(replicates, rep_id, Start_Time__ET_) %>%
  mutate(Start_Time__ET_ = hms::as_hms(as.character(Start_Time__ET_)),
         Start_Time__ET_ = hour(Start_Time__ET_) + 
                           minute(Start_Time__ET_) / 60 + 
                           second(Start_Time__ET_) / 3600) %>%
  pivot_wider(names_from = rep_id, values_from = Start_Time__ET_) %>%
  column_to_rownames("replicates") %>%
  as.matrix()

# Combine into a named list
det.covs <- list(
  Volume_liter = vol_mat,
  Day = day_mat,
  Start_Time = start_time_mat
)

occ.covs
det.covs
```

Drop strongly correlated covariates (leads to errors later)---
```{r}
# Get Pearson correlation matrix for numeric occupancy covariates
num_covs <- occ.covs[, sapply(occ.covs, is.numeric)]
cor_matrix <- cor(num_covs, use = "complete.obs")
round(cor_matrix, 2)
```
None are greater than 0.9. Keep all for now

Check categorical variables to see if any are represented in only 1-2 sites, which can cause errors
```{r}
table(occ.covs$Bayside)
table(occ.covs$Habitat)
```
Clam sanctuary and ousyer reef only represented 4 times each. May come back later and just categorize into "restored" as for Elasmos above. Keep an eye out for now

Change both "CLAM SANCTUARY" and "EELGRASS" to "RESTORED" so they will be one category
```{r}
# occ.covs$Habitat <- as.character(occ.covs$Habitat)  # convert to character if factor
# occ.covs$Habitat[occ.covs$Habitat %in% c("CLAM SANCTUARY", "EELGRASS")] <- "RESTORED"
# occ.covs$Habitat <- factor(occ.covs$Habitat)  # convert back to factor
# 
# occ.covs
```



Transform count matrix to a 3D array y[i,j,k], where:
i indexes species (ASVs),
j indexes sites (i.e., unique replicate groups),
k indexes replicate samples at that site.

Group samples based on replicates column. Reorganize so all replicates are aligned based on `occ.covs`
```{r}
# Unique replicate groups
replicate_groups <- rownames(occ.covs)

# Sort samples by replicate groups
mifish_exp_df_sampledata <- mifish_exp_df_sampledata[order(mifish_exp_df_sampledata$replicates), ]

# Initialize 3D y array
n_species <- nrow(mifish_exp_df_countmatrix)
n_sites <- length(unique(mifish_exp_df_sampledata$replicates)) # "sites" are unique to time/day/location
max_reps <- max(table(mifish_exp_df_sampledata$replicates))

y_array <- array(NA, dim = c(n_species, n_sites, max_reps))

# Populate the array
for (i in seq_along(replicate_groups)) {
  reps <- rownames(mifish_exp_df_sampledata)[mifish_exp_df_sampledata$replicates == replicate_groups[i]]
  for (j in seq_along(reps)) {
    y_array[, i, j] <- mifish_exp_df_countmatrix[, reps[j]]
  }
}

# Retain names
dimnames(y_array) <- list(
  rownames(mifish_exp_df_countmatrix),  # species (rows)
  unique(mifish_exp_df_sampledata$replicates),     # sites (columns)
  as.character(seq_len(dim(y_array)[3]))       # replicate number (slices)
)

data.frame(y_array[,,1])
data.frame(y_array[,,2])
```
I triple checked that these columns match up with the same order of sample/ replicates in the covariate matrices.



and coords- prject in meters
```{r}
# Create coords data frame for spatial transformation
coords_df <- mifish_exp_df_sampledata %>%
  group_by(replicates) %>%
  summarize(across(c(long, lat), mean_or_mode), .groups = "drop")  # .groups avoids grouping issues

# Convert to sf object
coords_sf <- st_as_sf(coords_df, coords = c("long", "lat"), crs = 4326)

# Transform to UTM Zone 18N
coords_utm <- st_transform(coords_sf, crs = 32618)

# Extract projected coordinates in meters
coords_projected <- st_coordinates(coords_utm)

# Set row names to match your occupancy covariates
rownames(coords_projected) <- rownames(occ.covs)


head(coords_projected)


```

Make into one list for spOccupancy
```{r}
# Final data list for spPGOcc
mifish.exp.list <- list(
  y = y_array,
  occ.covs = occ.covs,
  det.covs = det.covs,
  coords = coords_projected
)

str(mifish.exp.list)
```



Grid index the repeated coordinates
```{r}
# Convert coords to data frame with column names
mifish.exp.list$coords <- as.data.frame(mifish.exp.list$coords)
colnames(mifish.exp.list$coords) <- c("long", "lat")

# Create a single string identifier for each coordinate pair
coord_strings <- paste(mifish.exp.list$coords$long, mifish.exp.list$coords$lat)

# Factor to assign unique grid index numbers for each site
grid.index <- as.integer(as.factor(coord_strings))

# Extract unique coordinates in the same order as grid.index levels
coords_unique <- mifish.exp.list$coords[!duplicated(coord_strings), ]

# Make sure coords_unique is in the order of the factor levels
coords_unique <- coords_unique[order(as.integer(factor(coord_strings[!duplicated(coord_strings)]))), ]

# Assign back to data list
mifish.exp.list$grid.index <- grid.index # an integer vector mapping the 48 samples to 38 site coordinates
mifish.exp.list$coords <- coords_unique  # Must match order of grid.index

```


Check dimensions

```{r}
dim(mifish.exp.list$y)[1] # species
dim(mifish.exp.list$y)[2] # sites
dim(mifish.exp.list$y)[3] # replicates
length(mifish.exp.list$grid.index) # one site per sample
nrow(mifish.exp.list$coords) #unique sites
```

#### Run non-spatial model 

```{r}
# Set OPEN WATER as the reference level
mifish.exp.list$occ.covs$Habitat <- 
  relevel(factor(mifish.exp.list$occ.covs$Habitat), ref = "OPEN WATER")

set.seed(20250615)

# Priors
priors <- list(
  beta.comm.normal  = list(mean = 0, var = 2.72),
  alpha.comm.normal = list(mean = 0, var = 2.72),
  tau.sq.beta.ig     = list(a = 0.1, b = 0.1),
  tau.sq.alpha.ig    = list(a = 0.1, b = 0.1)
)

# Inits: length must match # of covariates in each submodel
inits <- list(
  beta.comm  = rep(0, 11),  
  alpha.comm = rep(0, 4), 
  tau.sq.beta  = 1,
  tau.sq.alpha = 1
)

# Run nonspatial msPGOcc
model_out_mifish <- msPGOcc(
  occ.formula = ~ Bayside + Habitat + Night__Day +
                 scale(Avg_Depth_m) + scale(Avg_Temperature_C) +
                 scale(Avg_Salinity_psu) + scale(Avg_Chlorophyll_ugL) +
                 scale(Avg_Turbidity_NTU),
  det.formula = ~ Volume_liter + Day + Start_Time,
  data        = mifish.exp.list,
  n.samples   = 75000,
  n.burn      = 25000,
  n.thin      = 10,
  n.chains    = 3,
  priors      = priors,
  inits       = inits,
  verbose     = TRUE,
  n.report    = 1000
)
```



##### Save model
```{r}
# save(model_out_mifish, file = "figures-expedition/model_out_mifish")
# load("figures-expedition/model_out_mifish")
```

##### Examine output

Summarize results
```{r}
options(max.print = 10000)
sink(file.path("figures-expedition", "model_out_mifish_summary.txt"))
summary(model_out_mifish)
sink()
```




##### Check Model diagnostics
###### 1. Convergence diagnostics
'Density` plots are a visual way of looking at mean and CI. See if the mean is far from zero and if the tails overlap zero.
Rhat values should ideally be close to 1.0 (below ~1.1);, especially for variances  which may suggest convergence issues.
Check Effective Sample Size (ESS): Low ESS (<200) can indicate poor sampling.

(for some reason doesn't plot in notebook- run in console)
NOTE- the model above was iteratively adjusted based on feedback from these diagnostics

```{r}
plot(model_out_mifish, param = "beta")  # Fixed effects
plot(model_out_mifish, param = "alpha") # Detection
```

###### 2. Posterior predictive checks

From [here](https://doserlab.com/files/spoccupancy-web/articles/modelfitting):

- "The Bayesian p-value is the proportion of posterior samples of the fit statistic of the model generated data that are greater than the corresponding fit statistic of the true data, summed across all grouped data points"
- binning the data across sites (group = 1) may help reveal whether the model fails to adequately represent variation in occurrence and detection probability across space, while binning the data across replicates (group = 2) may help reveal whether the model fails to adequately represent variation in detection probability across the different replicate surveys. Similarly, we suggest exploring posterior predictive checks using both the Freeman-Tukey Statistic as well as the Chi-Squared statistic."

Above for elas02, I was inspecting this manually but there are 52 ASVs for MiFish and more for CO1. Sort the ppc results so they are easier to look at. Flagging them into three groups:

- unacceptable: posterior pvalue < 0.025 or > 0.975
- borderline: posterior pvalue between 0.0250.10 or 0.900.975
- acceptable: posterior pvalue in 0.100.90

```{r}
ppc_specs <- tribble(
  ~name,     ~fit.stat,           ~group,
  "ft_comm", "freeman-tukey",       1L,
  "ft_species", "freeman-tukey",    2L,
  "chi_comm",  "chi-squared",        1L,
  "chi_species","chi-squared",      2L
)

ppc_results <- ppc_specs %>%
  mutate(
    ppc_obj = pmap(
      list(fit.stat, group),
      ~ ppcOcc(model_out_mifish, fit.stat = ..1, group = ..2)
    )
  )

# helper to pull ppcOcc pvalues from the printed summary
extract_ppc_pvals <- function(ppc_obj) {
  txt <- capture.output(summary(ppc_obj))
  com_i <- grep("Community Level", txt) + 1
  comm_line <- grep("Bayesian p-value", txt[com_i:length(txt)], value=TRUE)[1]
  comm_p <- as.numeric(str_extract(comm_line, "\\d+\\.\\d+"))
  
  spec_lines <- grep("^ASV_", txt, value=TRUE)
  sp_df <- tibble(
    ASV     = str_extract(spec_lines, "^ASV_[0-9]+"),
    p.value = as.numeric(str_extract(spec_lines, "\\d+\\.\\d+$"))
  )
  
  list(community = comm_p, species = sp_df)
}



# communitylevel  
comm_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  transmute(
    check   = name,
    level   = "community",
    ASV     = NA_character_,
    p.value = map_dbl(tmp, "community")
  )

# specieslevel 
spec_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  select(name, tmp) %>%
  unnest_longer(tmp, indices_to="which", values_to="block") %>%    # yields two blocks: community & species
  filter(which=="species") %>%                                      # keep species block
  unnest(block) %>%                                                 # expands to columns ASV, p.value
  transmute(
    check   = name,
    level   = "species",
    ASV,
    p.value
  )


ppc_pvals <- bind_rows(comm_tbl, spec_tbl)

# now ppc_pvals has columns: check, level, ASV, p.value
ppc_pvals

ppc_flagged <- ppc_pvals %>%
  mutate(
    fit_flag = case_when(
       p.value < 0.025 | p.value > 0.975 ~ "unacceptable",
       p.value < 0.10  | p.value > 0.90  ~ "borderline",
       TRUE                              ~ "acceptable"
    )
  )

# full table
ppc_flagged

# acceptable
filter(ppc_flagged, fit_flag=="acceptable")

# unacceptable
filter(ppc_flagged, fit_flag=="unacceptable")

# borderline
filter(ppc_flagged, fit_flag=="borderline")


```

Results:
Across all 4 checks, the communitylevel Bayesian pvalues are acceptable, from 0.36-0.42

At the species level:
- Majority of species are acceptable, between 0.1 and 0.9. None are unacceptable (<0.05 or >0.95)
- ASV_32, 88 89, 147 are borderline (0.9-0.95 or 0.05-0.1) by both freeman tukey and chi square
- ASV_36, 44, 160, 248 are also borderline by freeman tukey


###### 3. WAIC for model comparison

```{r}
waicOcc(model_out_mifish)

```



This is better than spatial model (below). Continue with extracting results

##### Summary for manuscript - MiFish Figures


```{r}
occ_mat <- model_out_mifish$beta.comm.samples   # occupancy
det_mat <- model_out_mifish$alpha.comm.samples  # detection

# make sure rhat/ESS vectors are named to match columns
names(model_out_mifish$rhat$beta.comm)  <- colnames(occ_mat)
names(model_out_mifish$rhat$alpha.comm) <- colnames(det_mat)
names(model_out_mifish$ESS$beta.comm)   <- colnames(occ_mat)
names(model_out_mifish$ESS$alpha.comm)  <- colnames(det_mat)

summ_comm_block <- function(mat, type_label){
  params <- colnames(mat)
  intercept_name <- "(Intercept)"
  bind_rows(
    lapply(params, function(p){
      draws <- mat[, p]
      alpha <- mat[, intercept_name]
      
      # extract Rhat and ESS for this parameter
      rhat_val <- if(type_label == "Occurrence") model_out_mifish$rhat$beta.comm[p]  else model_out_mifish$rhat$alpha.comm[p]
      ess_val  <- if(type_label == "Occurrence") model_out_mifish$ESS$beta.comm[p]   else model_out_mifish$ESS$alpha.comm[p]
      
      m    <- mean(draws)
      s    <- sd(draws)
      ci   <- quantile(draws, c(0.055, 0.945))
      ppos <- mean(draws > 0)
      pneg <- mean(draws < 0)
      
      dp    <- plogis(alpha + draws) - plogis(alpha)
      dp_m  <- mean(dp)
      dp_ci <- quantile(dp, c(0.055, 0.945))
      
      tibble(
        Process      = type_label,
        Covariate    = p,
        Mean_logit   = m,
        SD_logit     = s,
        CI2.5_logit  = ci[1],
        CI97.5_logit = ci[2],
        Ppos         = ppos,
        Pneg         = pneg,
        Effect       = case_when(
                         ppos > 0.89 ~ "positive",
                         pneg > 0.89 ~ "negative",
                         TRUE        ~ "ambiguous"
                       ),
        DeltaP_mean  = dp_m,
        DeltaP_lo    = dp_ci[1],
        DeltaP_hi    = dp_ci[2],
        Rhat         = rhat_val,
        ESS          = ess_val,
        Convergence  = case_when(
                         Rhat > 1.1  ~ "High Rhat",
                         ESS < 200   ~ "Low ESS",
                         TRUE        ~ "Converged"
                       )
      )
    })
  )
}

summ_occ <- summ_comm_block(occ_mat, "Occurrence")
summ_det <- summ_comm_block(det_mat, "Detection")

summ_comm_all <- bind_rows(summ_occ, summ_det)

summ_comm_all

summ_comm_all %>%
  filter(Convergence == "Converged") %>%
  filter(Effect != "ambiguous")
```

Community level
--> many covariates are ambiguous, meaning no significant impacts at community level
--> Impacts of Chla and turbidity are NEGATIVE, i.e. mifish-species are less likely to be detected when these parameters are high. Could be avoidance of eutrophic areas or due to filter clogging by algal biomass rather than fish. But these had flagged convergence parameters- high Rhats
--> Detection intercept is negative, meaning the baseline logodds of detecting the species if its present is below zero



Species level. Do same but also add in sp names

```{r}
occ_mat <- as.matrix(model_out_mifish$beta.samples)   # occurrence 
det_mat <- as.matrix(model_out_mifish$alpha.samples)  # detection 

# name the specieslevel rhat/ESS to match columns
names(model_out_mifish$rhat$beta)  <- colnames(occ_mat)
names(model_out_mifish$rhat$alpha) <- colnames(det_mat)
names(model_out_mifish$ESS$beta)   <- colnames(occ_mat)
names(model_out_mifish$ESS$alpha)  <- colnames(det_mat)

summ_block_mat <- function(mat, process_label) {
  params   <- colnames(mat)
  species  <- unique(sub(".*-(ASV_\\d+)$", "\\1", params))
  covs     <- unique(sub("^(.*)-ASV_\\d+$", "\\1", params))

  bind_rows(
    lapply(species, function(sp) {
      alpha_draws <- mat[, paste0("(Intercept)-", sp)]

      bind_rows(
        lapply(covs, function(cov) {
          colnm <- paste0(cov, "-", sp)
          draws <- mat[, colnm]

          # extract Rhat and ESS for this parameter
          rhat_val <- if(process_label == "Occurrence") model_out_mifish$rhat$beta[colnm]  else model_out_mifish$rhat$alpha[colnm]
          ess_val  <- if(process_label == "Occurrence") model_out_mifish$ESS$beta[colnm]   else model_out_mifish$ESS$alpha[colnm]

          m    <- mean(draws)
          s    <- sd(draws)
          ci   <- quantile(draws, c(0.055, 0.945))
          ppos <- mean(draws > 0)
          pneg <- mean(draws < 0)

          dp    <- plogis(alpha_draws + draws) - plogis(alpha_draws)
          dp_m  <- mean(dp)
          dp_ci <- quantile(dp, c(0.055, 0.945))

          tibble(
            ASV           = sp,
            Process       = process_label,
            Covariate     = cov,
            Mean_logit    = m,
            SD_logit      = s,
            CI2.5_logit   = ci[1],
            CI97.5_logit  = ci[2],
            Ppos          = ppos,
            Pneg          = pneg,
            Effect        = case_when(
                              ppos > 0.89 ~ "positive",
                              pneg > 0.89 ~ "negative",
                              TRUE        ~ "ambiguous"
                            ),
            DeltaP_mean   = 100 * dp_m,       # percentagepoint units
            DeltaP_lo     = 100 * dp_ci[1],
            DeltaP_hi     = 100 * dp_ci[2],
            Rhat          = rhat_val,
            ESS           = ess_val,
            Convergence   = case_when(
                              Rhat > 1.1  ~ "High Rhat",
                              ESS < 200   ~ "Low ESS",
                              TRUE        ~ "Converged"
                            )
          )
        })
      )
    })
  )
}

summ_occ <- summ_block_mat(occ_mat, "Occurrence")
summ_det <- summ_block_mat(det_mat, "Detection")

summ_sp_all <- bind_rows(summ_occ, summ_det)

# attach species names
tax_df     <- as.data.frame(tax_table(ps2024_exp_mifish_glommed))
tax_df$ASV <- rownames(tax_df)
tax_lookup <- tax_df %>% select(ASV, Species.CommonName)

summ_sp_all_named <- summ_sp_all %>%
  left_join(tax_lookup, by = "ASV") %>%
  relocate(Species.CommonName, .after = ASV)

summ_sp_all_named

# view only those rows that show an effect (positive or negative) AND model convergence parameters are acceptable
summ_sp_all_named %>%
  filter(Convergence == "Converged") %>%
  filter(Effect != "ambiguous")

```



save results tables

```{r}

write.csv(summ_comm_all,"figures-expedition/summ_comm_all_mifish.csv", row.names = TRUE)
write.csv(summ_sp_all_named,"figures-expedition/summ_sp_all_named_mifish.csv", row.names = TRUE)

```


Species-level Occurrence
- Scombriformes, Altantic silverside, anchovies all have positive occurrence at baseline (because they are very common)
- Chla has a negative effect on Scombriformes occurrence
- Salinity has positive effect on occurrence for anchovies

Species-level Detection
--> Similar to community-level, many ASVs have negative detection probability intercept suggesting that they are more likely not to be detected when present
--> Several have positive impact of Start Time on detection: Atlantic menhaden, Seaboard Goby, Altantic silverside, Anchovies, Spot, Darter goby. Suggests these are more likely to be detected at later times of day. Make a plot showing their probability with time of day:

```{r}

asvs <- c("ASV_1","ASV_4","ASV_5","ASV_6","ASV_12","ASV_23")
tax_df     <- as.data.frame(tax_table(ps2024_exp_mifish_glommed))
tax_df$ASV <- rownames(tax_df)
tax_lookup <- tax_df %>% select(ASV, Species.CommonName)

# Pull out the posterior draws of the detection submodel
det_draws <- as.matrix(model_out_mifish$alpha.samples)

# Build a grid of Start_Time values (in original units)
st_vals <- seq(
  min(mifish.exp.list$det.covs$Start_Time, na.rm=TRUE),
  max(mifish.exp.list$det.covs$Start_Time, na.rm=TRUE),
  length.out = 100
)

# 4. For each ASV, for each st_vals, compute posterior detection probability draws
pred_df <- map_dfr(asvs, function(sp) {
  int_draws <- det_draws[, paste0("(Intercept)-", sp)]
  b_st      <- det_draws[, paste0("Start_Time-", sp)]
  
  # for each Start_Time value, get vector of p_draws
  p_mat <- sapply(st_vals, function(x) {
    plogis(int_draws + b_st * x)
  })  # dimension: iterations  length(st_vals)
  
  #  summarize across iterations for each st_vals
  tibble(
    ASV        = sp,
    Start_Time = st_vals,
    p_mean     = colMeans(p_mat),
    p_lo       = apply(p_mat, 2, quantile, 0.025),
    p_hi       = apply(p_mat, 2, quantile, 0.975)
  )
})

# Attach common names
pred_df <- pred_df %>%
  left_join(tax_lookup, by = "ASV")

# plot
timeofdayeffects_mifish_plot <- ggplot(pred_df, aes(x = Start_Time, y = p_mean)) +
  geom_ribbon(aes(ymin = p_lo, ymax = p_hi), fill = "grey80", alpha = 0.5) +
  geom_line(size = 1) +
  facet_wrap(~ Species.CommonName, scales = "free_y") +
  labs(
    x = "Start Time (Hour)",
    y = "Detection probability",
    title = "Effect of Start Time on eDNA detection",
    subtitle = "ASVs with positive time-of-day effects"
  ) +
  theme_bw()


timeofdayeffects_mifish_plot


ggsave(plot = timeofdayeffects_mifish_plot, filename = "figures-expedition/timeofdayeffects_mifish_plot.jpg", width = 8, height = 7, units = "in")

```




Community-Level Detection Probability vs. Filtration Volume
```{r}
# posterior draws for the Volume_liter detection covariate
vol_samps <- as.matrix(model_out_mifish$alpha.comm.samples)
draws_int <- vol_samps[, "(Intercept)"]
draws_vol <- vol_samps[, "Volume_liter"]

# Sequence of filtration volumes (in L) to predict over
v_seq <- seq(
  min(mifish.exp.list$det.covs$Volume_liter, na.rm = TRUE),
  max(mifish.exp.list$det.covs$Volume_liter, na.rm = TRUE),
  length.out = 100
)

# predicted detection probabilities across posterior draws
pred_matrix <- sapply(v_seq, function(v) {
  plogis(draws_int + draws_vol * v)
})  # dimensions: iterations  volumes

# Summarize across posterior draws
vol_df <- tibble(
  Volume_liter = v_seq,
  p_mean = colMeans(pred_matrix),
  p_lo   = apply(pred_matrix, 2, quantile, 0.025),
  p_hi   = apply(pred_matrix, 2, quantile, 0.975)
)

# Plot
mifish_volume_effect_plot <- ggplot(vol_df, aes(x = Volume_liter, y = p_mean)) +
  geom_ribbon(aes(ymin = p_lo, ymax = p_hi), fill = "grey80", alpha = 0.5) +
  geom_line(size = 1.2, color = "black") +
  labs(
    x = "Filtration Volume (L)",
    y = "Estimated community-level detection probability",
    title = "Effect of Filtration Volume on eDNA Detection Probability: MiFish"
  ) +
  theme_bw()


mifish_volume_effect_plot

ggsave(
  plot = mifish_volume_effect_plot,
  filename = "figures-expedition/mifish_volume_effect_community_detection.jpg",
  width = 6,
  height = 4,
  units = "in",
  dpi = 300
)

```


#### Run spatial model

```{r}
# Set OPEN WATER as the reference level. This means the model will calculate occupancy at the other 3 Habitats relative to open water
mifish.exp.list$occ.covs$Habitat <- relevel(factor(mifish.exp.list$occ.covs$Habitat), ref = "OPEN WATER")


set.seed(20250615)

n.batch <- 75000
batch.length <- 10
n.samples <- n.batch * batch.length
n.factors <- 2
n.species <- dim(mifish.exp.list$y)[1]

priors.list <- list(
  beta.comm.normal = list(mean = 0, var = 2.72),
  alpha.comm.normal = list(mean = 0, var = 2.72),
  tau.sq.beta.ig = list(a = 2, b = 2),
  tau.sq.alpha.ig = list(a = 2, b = 2)
)

tuning.list <- list(phi = rep(1, n.factors))

lambda.inits <- matrix(0, nrow = n.species, ncol = n.factors)
for (k in 1:min(n.species, n.factors)) {
  lambda.inits[k, k] <- 1
}
lambda.inits[lower.tri(lambda.inits)] <- rnorm(sum(lower.tri(lambda.inits)))

inits.list <- list(
  alpha.comm = 0,
  beta.comm = 0,
  beta = 0,
  alpha = 0,
  tau.sq.beta = 1,
  tau.sq.alpha = 1,
  phi = rep(3 / mean(dist(mifish.exp.list$coords)), n.factors),
  lambda = lambda.inits,
  z = apply(mifish.exp.list$y, c(1, 2), max, na.rm = TRUE)
)

sf.mifish.out <- sfMsPGOcc(
  occ.formula = ~ Bayside + Habitat + Night__Day + 
                 scale(Avg_Depth_m) + scale(Avg_Temperature_C) + 
                 scale(Avg_Salinity_psu) + scale(Avg_Chlorophyll_ugL) + scale(Avg_Turbidity_NTU),
  det.formula = ~ Volume_liter + Day + Start_Time,
  data = list(
    y = mifish.exp.list$y,
    occ.covs = mifish.exp.list$occ.covs,
    det.covs = mifish.exp.list$det.covs,
    coords = mifish.exp.list$coords,
    grid.index = mifish.exp.list$grid.index
  ),
  inits = inits.list,
  priors = priors.list,
  tuning = tuning.list,
  cov.model = "exponential",
  NNGP = TRUE,
  n.neighbors = 20,
  n.factors = n.factors,
  n.batch = n.batch,
  batch.length = batch.length,
  n.burn = 25000,
  n.thin = 10,
  n.chains = 3,
  n.report = 1000,
  n.omp.threads = 3,
  verbose = TRUE
)

```



##### Save model
```{r}
# save(sf.mifish.out, file = "figures-expedition/sf.mifish.out")
# load("figures-expedition/sf.mifish.out")
```

##### Examine output

Summarize results
```{r}
# options(max.print = 10000)
# sink(file.path("figures-expedition", "model_out_mifish_spatial_summary.txt"))
# summary(sf.mifish.out)
# sink()
```





###### 1. Convergence diagnostics
'Density` plots are a visual way of looking at mean and CI. See if the mean is far from zero and if the tails overlap zero.
Rhat values should ideally be close to 1.0 (below ~1.1);, especially for variances  which may suggest convergence issues.
Check Effective Sample Size (ESS): Low ESS (<200) can indicate poor sampling.

(for some reason doesn't plot in notebook- run in console)
NOTE- the model above was iteratively adjusted based on feedback from these diagnostics

```{r}
plot(sf.mifish.out, param = "beta")  # Fixed effects
plot(sf.mifish.out, param = "alpha") # Detection
```

###### 2. Posterior predictive checks


```{r}
ppc_specs <- tribble(
  ~name,     ~fit.stat,           ~group,
  "ft_comm", "freeman-tukey",       1L,
  "ft_species", "freeman-tukey",    2L,
  "chi_comm",  "chi-squared",        1L,
  "chi_species","chi-squared",      2L
)

ppc_results <- ppc_specs %>%
  mutate(
    ppc_obj = pmap(
      list(fit.stat, group),
      ~ ppcOcc(sf.mifish.out, fit.stat = ..1, group = ..2)
    )
  )

# helper to pull ppcOcc pvalues from the printed summary
extract_ppc_pvals <- function(ppc_obj) {
  txt <- capture.output(summary(ppc_obj))
  com_i <- grep("Community Level", txt) + 1
  comm_line <- grep("Bayesian p-value", txt[com_i:length(txt)], value=TRUE)[1]
  comm_p <- as.numeric(str_extract(comm_line, "\\d+\\.\\d+"))
  
  spec_lines <- grep("^ASV_", txt, value=TRUE)
  sp_df <- tibble(
    ASV     = str_extract(spec_lines, "^ASV_[0-9]+"),
    p.value = as.numeric(str_extract(spec_lines, "\\d+\\.\\d+$"))
  )
  
  list(community = comm_p, species = sp_df)
}



# communitylevel  
comm_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  transmute(
    check   = name,
    level   = "community",
    ASV     = NA_character_,
    p.value = map_dbl(tmp, "community")
  )

# specieslevel 
spec_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  select(name, tmp) %>%
  unnest_longer(tmp, indices_to="which", values_to="block") %>%    # yields two blocks: community & species
  filter(which=="species") %>%                                      # keep species block
  unnest(block) %>%                                                 # expands to columns ASV, p.value
  transmute(
    check   = name,
    level   = "species",
    ASV,
    p.value
  )


ppc_pvals <- bind_rows(comm_tbl, spec_tbl)

# now ppc_pvals has columns: check, level, ASV, p.value
ppc_pvals

ppc_flagged <- ppc_pvals %>%
  mutate(
    fit_flag = case_when(
       p.value < 0.025 | p.value > 0.975 ~ "unacceptable",
       p.value < 0.10  | p.value > 0.90  ~ "borderline",
       TRUE                              ~ "acceptable"
    )
  )

# full table
ppc_flagged

# acceptable
filter(ppc_flagged, fit_flag=="acceptable")

# unacceptable
filter(ppc_flagged, fit_flag=="unacceptable")

# borderline
filter(ppc_flagged, fit_flag=="borderline")

```




Results:
Didn't run because based on WAIC, I am going with the non spatial model.


###### 3. WAIC for model comparison

```{r}
waicOcc(sf.mifish.out)

```

--> the non spatial model is slightly better, 1494.6. Continue with results from non spatial model above









### CO1


#### Prepare data
Use dfs where controls were already removed. Simplify metadata variables

```{r}
co1_2024_exp_asv_table_taxbased
co1_2024_exp_sample_data_taxbased
co1_2024_exp_tax_table_taxbased
colnames(co1_2024_exp_sample_data_taxbased)
```

Import and join CTD values averaged over each eDNA sampling interval (was only done for Elas and MiFish above)
```{r}
# rename df and remove controls
co1_exp_df_sampledata <- co1_2024_exp_sample_data_taxbased  %>% filter(is.na(controls))

# Store original row names
rownames_original <- rownames(co1_exp_df_sampledata)

# Simplify sample names in sample data table
co1_exp_df_sampledata$Name_Deploy_Cartr <- gsub("_$", "", gsub("\\.", "_", trimws(co1_exp_df_sampledata$Name_Deploy_Cartr)))

# import
sample_metadata2 <- read.csv("/Volumes/easystore/eDNA/shirp-edna/figures-expedition/CTD_avg_eDNA_sample_intervals.csv")

# join
co1_exp_df_sampledata <- left_join(co1_exp_df_sampledata, sample_metadata2, by = c("Name_Deploy_Cartr" = "Name.Deploy_Cartr"))

# Restore row names (for now)
rownames(co1_exp_df_sampledata) <- rownames_original

co1_exp_df_sampledata
```



Simplify sample names, remove redundant or unuseful metadata, remove controls. Data and sample ID format is slightly different than for mifish/ elas02
```{r}
# Rename
co1_exp_df_counttable <- co1_2024_exp_asv_table_taxbased
# Subset to keep only columns present in the filtered sampledata
co1_exp_df_counttable <- co1_exp_df_counttable[, rownames(co1_exp_df_sampledata), drop = FALSE]
# Rename the columns of the count table using the simplified names (note- these were in the same order)
colnames(co1_exp_df_counttable) <- co1_exp_df_sampledata$Name_Deploy_Cartr

# back to sample data- make sample names row names and drop long weird sample names
rownames(co1_exp_df_sampledata) <- co1_exp_df_sampledata$Name_Deploy_Cartr

# Remove some redundant columns in sample data
co1_exp_df_sampledata <- co1_exp_df_sampledata %>%
  select(
    -Name_Deploy_Cartr,
    -Deployment,
    -Cartridge_ID,
    -Site_type,
    -site_altname,
    -Station,
    -controls,
    -Date,
    -End_Time__ET_,
    -Datecode,
    -Year,
    -Month,
    -DO,
    -Temperature,
    -Salinity,
    -Time,
    -Weather)


# view
co1_exp_df_counttable
co1_exp_df_sampledata
glimpse(co1_exp_df_sampledata)

```







Convert counts to presence/ absence 
```{r}
co1_exp_df_countmatrix <- co1_exp_df_counttable
co1_exp_df_countmatrix[] <- ifelse(co1_exp_df_countmatrix > 0, 1, 0)

# compare
co1_exp_df_counttable
co1_exp_df_countmatrix
```


Occupancy and Detection Covariates
```{r}
# Occupancy covariates: one row per unique replicate group
# Don't include spatial variables because that is built into coords later and would lead to redundancy
occ.covs <- co1_exp_df_sampledata %>%
  group_by(replicates) %>%
  summarize(across(c(Bayside, Habitat, Night__Day, Avg_Depth_m, Avg_Temperature_C, Avg_Salinity_psu, Avg_Chlorophyll_ugL, Avg_Turbidity_NTU), mean_or_mode)) %>%
  as.data.frame()
# remove rep names and use as IDs
rownames(occ.covs) <- occ.covs$replicates
occ.covs$replicates <- NULL


# Detection covariates: list of matrices for each sampling variable. Matrix contains sites and replicates
# Extract and sort by rep
det_grouped <- co1_exp_df_sampledata[, c("replicates", "Volume_liter", "Start_Time__ET_", "Day")] %>%
  group_by(replicates) %>%
  arrange(replicates) %>%
  mutate(rep_id = row_number()) %>%
  ungroup()

# Reshape to wide format for each covariate
vol_mat <- det_grouped %>%
  select(replicates, rep_id, Volume_liter) %>%
  pivot_wider(names_from = rep_id, values_from = Volume_liter) %>%
  column_to_rownames("replicates") %>%
  as.matrix()

day_mat <- det_grouped %>%
  select(replicates, rep_id, Day) %>%
  pivot_wider(names_from = rep_id, values_from = Day) %>%
  column_to_rownames("replicates") %>%
  as.matrix()

# use decimal hour for time
start_time_mat <- det_grouped %>%
  select(replicates, rep_id, Start_Time__ET_) %>%
  mutate(Start_Time__ET_ = hms::as_hms(as.character(Start_Time__ET_)),
         Start_Time__ET_ = hour(Start_Time__ET_) + 
                           minute(Start_Time__ET_) / 60 + 
                           second(Start_Time__ET_) / 3600) %>%
  pivot_wider(names_from = rep_id, values_from = Start_Time__ET_) %>%
  column_to_rownames("replicates") %>%
  as.matrix()

# Combine into a named list
det.covs <- list(
  Volume_liter = vol_mat,
  Day = day_mat,
  Start_Time = start_time_mat
)

occ.covs
det.covs
```

Drop strongly correlated covariates (leads to errors later)---
```{r}
# Get Pearson correlation matrix for numeric occupancy covariates
num_covs <- occ.covs[, sapply(occ.covs, is.numeric)]
cor_matrix <- cor(num_covs, use = "complete.obs")
round(cor_matrix, 2)
```
None are greater than 0.9. Keep all for now

Check categorical variables to see if any are represented in only 1-2 sites, which can cause errors
```{r}
table(occ.covs$Bayside)
table(occ.covs$Habitat)
```
Clam sanctuary and ousyer reef only represented 4 times each. May come back later and just categorize into "restored" as for Elasmos above. Keep an eye out for now

Change both "CLAM SANCTUARY" and "EELGRASS" to "RESTORED" so they will be one category
```{r}
# occ.covs$Habitat <- as.character(occ.covs$Habitat)  # convert to character if factor
# occ.covs$Habitat[occ.covs$Habitat %in% c("CLAM SANCTUARY", "EELGRASS")] <- "RESTORED"
# occ.covs$Habitat <- factor(occ.covs$Habitat)  # convert back to factor
# 
# occ.covs
```



Transform count matrix to a 3D array y[i,j,k], where:
i indexes species (ASVs),
j indexes sites (i.e., unique replicate groups),
k indexes replicate samples at that site.

Group samples based on replicates column. Reorganize so all replicates are aligned based on `occ.covs`
```{r}
# Unique replicate groups
replicate_groups <- rownames(occ.covs)

# Sort samples by replicate groups
co1_exp_df_sampledata <- co1_exp_df_sampledata[order(co1_exp_df_sampledata$replicates), ]

# Initialize 3D y array
n_species <- nrow(co1_exp_df_countmatrix)
n_sites <- length(unique(co1_exp_df_sampledata$replicates)) # "sites" are unique to time/day/location
max_reps <- max(table(co1_exp_df_sampledata$replicates))

y_array <- array(NA, dim = c(n_species, n_sites, max_reps))

# Populate the array
for (i in seq_along(replicate_groups)) {
  reps <- rownames(co1_exp_df_sampledata)[co1_exp_df_sampledata$replicates == replicate_groups[i]]
  for (j in seq_along(reps)) {
    y_array[, i, j] <- co1_exp_df_countmatrix[, reps[j]]
  }
}

# Retain names
dimnames(y_array) <- list(
  rownames(co1_exp_df_countmatrix),  # species (rows)
  unique(co1_exp_df_sampledata$replicates),     # sites (columns)
  as.character(seq_len(dim(y_array)[3]))       # replicate number (slices)
)

data.frame(y_array[,,1])
data.frame(y_array[,,2])
data.frame(y_array[,,3])

```
I triple checked that these columns match up with the same order of sample/ replicates in the covariate matrices.



and coords
```{r}
# Create coords data frame for spatial transformation
coords_df <- co1_exp_df_sampledata %>%
  group_by(replicates) %>%
  summarize(across(c(long, lat), mean_or_mode), .groups = "drop")  # .groups avoids grouping issues

# Convert to sf object
coords_sf <- st_as_sf(coords_df, coords = c("long", "lat"), crs = 4326)

# Transform to UTM Zone 18N
coords_utm <- st_transform(coords_sf, crs = 32618)

# Extract projected coordinates in meters
coords_projected <- st_coordinates(coords_utm)

# Set row names to match your occupancy covariates
rownames(coords_projected) <- rownames(occ.covs)


head(coords_projected)


```

Make into one list for spOccupancy
```{r}
# Final data list for spPGOcc
co1.exp.list <- list(
  y = y_array,
  occ.covs = occ.covs,
  det.covs = det.covs,
  coords = as.matrix(coords_projected)
)

str(co1.exp.list)
```



Grid index the repeated coordinates
```{r}
# Convert coords to data frame with column names
co1.exp.list$coords <- as.data.frame(co1.exp.list$coords)
colnames(co1.exp.list$coords) <- c("long", "lat")

# Create a single string identifier for each coordinate pair
coord_strings <- paste(co1.exp.list$coords$long, co1.exp.list$coords$lat)

# Factor to assign unique grid index numbers for each site
grid.index <- as.integer(as.factor(coord_strings))

# Extract unique coordinates in the same order as grid.index levels
coords_unique <- co1.exp.list$coords[!duplicated(coord_strings), ]

# Make sure coords_unique is in the order of the factor levels
coords_unique <- coords_unique[order(as.integer(factor(coord_strings[!duplicated(coord_strings)]))), ]

# Assign back to data list
co1.exp.list$grid.index <- grid.index # an integer vector mapping the samples to site coordinates
co1.exp.list$coords <- as.matrix(coords_unique)  # Must match order of grid.index

```


Check dimensions

```{r}
dim(co1.exp.list$y)[1] # species
dim(co1.exp.list$y)[2] # samples
dim(co1.exp.list$y)[3] # replicates
length(co1.exp.list$grid.index) # one site per sample
nrow(co1.exp.list$coords) #unique locations
```
Note- CO1 has many more ASVs than MiFish or Elas02. Might need to adjust some parameters to get reasonable run times...






#### Run non-spatial model 

```{r}
# Set OPEN WATER as the reference level
co1.exp.list$occ.covs$Habitat <- 
  relevel(factor(co1.exp.list$occ.covs$Habitat), ref = "OPEN WATER")

set.seed(20250615)

# Priors
priors <- list(
  beta.comm.normal  = list(mean = 0, var = 2.72),
  alpha.comm.normal = list(mean = 0, var = 2.72),
  tau.sq.beta.ig     = list(a = 0.1, b = 0.1),
  tau.sq.alpha.ig    = list(a = 0.1, b = 0.1)
)

# Inits: length must match # of covariates in each submodel
inits <- list(
  beta.comm  = rep(0, 11),  
  alpha.comm = rep(0, 4), 
  tau.sq.beta  = 1,
  tau.sq.alpha = 1
)

# Run nonspatial msPGOcc
model_out_co1 <- msPGOcc(
  occ.formula = ~ Bayside + Habitat + Night__Day +
                 scale(Avg_Depth_m) + scale(Avg_Temperature_C) +
                 scale(Avg_Salinity_psu) + scale(Avg_Chlorophyll_ugL) +
                 scale(Avg_Turbidity_NTU),
  det.formula = ~ Volume_liter + Day + Start_Time,
  data        = co1.exp.list,
  n.samples   = 75000,
  n.burn      = 25000,
  n.thin      = 10,
  n.chains    = 3,
  priors      = priors,
  inits       = inits,
  verbose     = TRUE,
  n.report    = 1000,
  n.omp.threads = 3,
)
```


##### Save model
```{r}
# save(model_out_co1, file = "figures-expedition/model_out_co1")
# load("figures-expedition/model_out_co1")
```

##### Examine output

Summarize results
```{r}
options(max.print = 100000)
sink(file.path("figures-expedition", "model_out_co1_summary.txt"))
summary(model_out_co1)
sink()
```




##### Check Model diagnostics
###### 1. Convergence diagnostics

```{r}
plot(model_out_co1, param = "beta")  # Fixed effects
plot(model_out_co1, param = "alpha") # Detection
```

###### 2. Posterior predictive checks


```{r}
ppc_specs <- tribble(
  ~name,     ~fit.stat,           ~group,
  "ft_comm", "freeman-tukey",       1L,
  "ft_species", "freeman-tukey",    2L,
  "chi_comm",  "chi-squared",        1L,
  "chi_species","chi-squared",      2L
)

ppc_results <- ppc_specs %>%
  mutate(
    ppc_obj = pmap(
      list(fit.stat, group),
      ~ ppcOcc(model_out_co1, fit.stat = ..1, group = ..2)
    )
  )

# helper to pull ppcOcc pvalues from the printed summary
extract_ppc_pvals <- function(ppc_obj) {
  txt <- capture.output(summary(ppc_obj))
  com_i <- grep("Community Level", txt) + 1
  comm_line <- grep("Bayesian p-value", txt[com_i:length(txt)], value=TRUE)[1]
  comm_p <- as.numeric(str_extract(comm_line, "\\d+\\.\\d+"))
  
  spec_lines <- grep("^ASV_", txt, value=TRUE)
  sp_df <- tibble(
    ASV     = str_extract(spec_lines, "^ASV_[0-9]+"),
    p.value = as.numeric(str_extract(spec_lines, "\\d+\\.\\d+$"))
  )
  
  list(community = comm_p, species = sp_df)
}



# communitylevel  
comm_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  transmute(
    check   = name,
    level   = "community",
    ASV     = NA_character_,
    p.value = map_dbl(tmp, "community")
  )

# specieslevel 
spec_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  select(name, tmp) %>%
  unnest_longer(tmp, indices_to="which", values_to="block") %>%    # yields two blocks: community & species
  filter(which=="species") %>%                                      # keep species block
  unnest(block) %>%                                                 # expands to columns ASV, p.value
  transmute(
    check   = name,
    level   = "species",
    ASV,
    p.value
  )


ppc_pvals <- bind_rows(comm_tbl, spec_tbl)

# now ppc_pvals has columns: check, level, ASV, p.value
ppc_pvals

ppc_flagged <- ppc_pvals %>%
  mutate(
    fit_flag = case_when(
       p.value < 0.025 | p.value > 0.975 ~ "unacceptable",
       p.value < 0.10  | p.value > 0.90  ~ "borderline",
       TRUE                              ~ "acceptable"
    )
  )

# full table
ppc_flagged

# acceptable
filter(ppc_flagged, fit_flag=="acceptable")

# unacceptable
filter(ppc_flagged, fit_flag=="unacceptable")

# borderline
filter(ppc_flagged, fit_flag=="borderline")


```

Results: waiting to run to see if spatial or non spatial model is better


###### 3. WAIC for model comparison

```{r}
waicOcc(model_out_co1)

```

Spatial model is better (WAIC = 44,723.661).Continue analysis with spatial model













#### Run spatial model
I changed some parameters here to make the model a little bit faster since this dataset is much bigger. Keep iteratively adjusting the batch length, the n factors, the n batch, and the number of neighbors in order to optimize R-hat and ESS and balance that with run time. 



```{r}
# Set OPEN WATER as the reference level. This means the model will calculate occupancy at the other 3 Habitats relative to open water
co1.exp.list$occ.covs$Habitat <- relevel(factor(co1.exp.list$occ.covs$Habitat), ref = "OPEN WATER")


set.seed(20250615)

n.batch <- 7500
batch.length <- 10
# n.samples <- 75000
n.factors <- 1
n.thin <-  10
n.burn <-  25000
n.species <- dim(co1.exp.list$y)[1]

# keep phi in reasonable range to help convergence
a <- 1 / max(dist(co1.exp.list$coords))
b <- 1 / min(dist(co1.exp.list$coords[!duplicated(co1.exp.list$grid.index), ]))

priors.list <- list(
  beta.comm.normal = list(mean = 0, var = 2.72),
  alpha.comm.normal = list(mean = 0, var = 2.72),
  tau.sq.beta.ig = list(a = 2, b = 2),
  tau.sq.alpha.ig = list(a = 2, b = 2)
#  ,phi.unif = list(a = a, b = b) Actually when NGGP = TRUE, the models sets its own phi bounds and sfMsPGOcc is currently only implemented for NNGPs, not full Gaussian Processes. NNGP has to be TRUE
)

tuning.list <- list(phi = rep(1, n.factors))

lambda.inits <- matrix(0, nrow = n.species, ncol = n.factors)
for (k in 1:min(n.species, n.factors)) {
  lambda.inits[k, k] <- 1
}
lambda.inits[lower.tri(lambda.inits)] <- rnorm(sum(lower.tri(lambda.inits)))

inits.list <- list(
  alpha.comm = 0,
  beta.comm = 0,
  beta = 0,
  alpha = 0,
  tau.sq.beta = 1,
  tau.sq.alpha = 1,
  phi = rep(3 / mean(dist(co1.exp.list$coords)), n.factors),
  lambda = lambda.inits,
  z = apply(co1.exp.list$y, c(1, 2), max, na.rm = TRUE)
)

sf.co1.out <- sfMsPGOcc(
  occ.formula = ~ Bayside + Habitat + Night__Day + 
                 scale(Avg_Depth_m) + scale(Avg_Temperature_C) + 
                 scale(Avg_Salinity_psu) + scale(Avg_Chlorophyll_ugL) + scale(Avg_Turbidity_NTU),
  det.formula = ~ Volume_liter + Day + Start_Time,
  data = list(
    y = co1.exp.list$y,
    occ.covs = co1.exp.list$occ.covs,
    det.covs = co1.exp.list$det.covs,
    coords = co1.exp.list$coords,
    grid.index = co1.exp.list$grid.index
  ),
  inits = inits.list,
  prior = priors.list,
  tuning = tuning.list,
  cov.model = "exponential",
  NNGP = TRUE,
  n.neighbors = 20,
  n.factors = n.factors,
  n.batch = n.batch,
  batch.length = batch.length,
  n.burn = n.burn,
  n.thin = n.thin,
  n.chains = 3,
  n.report = 750,
  n.omp.threads = 4,
  verbose = TRUE
)

```





##### Save model
```{r}
# save(sf.co1.out, file = "figures-expedition/sf.co1.out")
# load("figures-expedition/sf.co1.out")
```


##### Examine output

Summarize results
```{r}
options(max.print = 100000)
sink(file.path("figures-expedition", "model_out_co1_spatial_summary.txt"))
summary(sf.co1.out)
sink()
```


###### 1. Convergence diagnostics


```{r}
plot(sf.co1.out, param = "beta")  # Fixed effects
plot(sf.co1.out, param = "alpha") # Detection
```

###### 2. Posterior predictive checks


```{r}
ppc_specs <- tribble(
  ~name,     ~fit.stat,           ~group,
  "ft_comm", "freeman-tukey",       1L,
  "ft_species", "freeman-tukey",    2L,
  "chi_comm",  "chi-squared",        1L,
  "chi_species","chi-squared",      2L
)

ppc_results <- ppc_specs %>%
  mutate(
    ppc_obj = pmap(
      list(fit.stat, group),
      ~ ppcOcc(sf.co1.out, fit.stat = ..1, group = ..2)
    )
  )

# helper to pull ppcOcc pvalues from the printed summary
extract_ppc_pvals <- function(ppc_obj) {
  txt <- capture.output(summary(ppc_obj))
  com_i <- grep("Community Level", txt) + 1
  comm_line <- grep("Bayesian p-value", txt[com_i:length(txt)], value=TRUE)[1]
  comm_p <- as.numeric(str_extract(comm_line, "\\d+\\.\\d+"))
  
  spec_lines <- grep("^ASV_", txt, value=TRUE)
  sp_df <- tibble(
    ASV     = str_extract(spec_lines, "^ASV_[0-9]+"),
    p.value = as.numeric(str_extract(spec_lines, "\\d+\\.\\d+$"))
  )
  
  list(community = comm_p, species = sp_df)
}



# communitylevel  
comm_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  transmute(
    check   = name,
    level   = "community",
    ASV     = NA_character_,
    p.value = map_dbl(tmp, "community")
  )

# specieslevel 
spec_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  select(name, tmp) %>%
  unnest_longer(tmp, indices_to="which", values_to="block") %>%    # yields two blocks: community & species
  filter(which=="species") %>%                                      # keep species block
  unnest(block) %>%                                                 # expands to columns ASV, p.value
  transmute(
    check   = name,
    level   = "species",
    ASV,
    p.value
  )


ppc_pvals <- bind_rows(comm_tbl, spec_tbl)

# now ppc_pvals has columns: check, level, ASV, p.value
ppc_pvals

ppc_flagged <- ppc_pvals %>%
  mutate(
    fit_flag = case_when(
       p.value < 0.025 | p.value > 0.975 ~ "unacceptable",
       p.value < 0.10  | p.value > 0.90  ~ "borderline",
       TRUE                              ~ "acceptable"
    )
  )

# full table
ppc_flagged

# acceptable
filter(ppc_flagged, fit_flag=="acceptable")

# unacceptable
filter(ppc_flagged, fit_flag=="unacceptable")

# borderline
filter(ppc_flagged, fit_flag=="borderline")

```




Results:



###### 3. WAIC for model comparison

```{r}
waicOcc(sf.co1.out)

```



WAIC is lower than non spatial model. Use spatial model for analysis.....




##### Summary for manuscript - CO1 Figures

```{r}
occ_mat <- sf.co1.out$beta.comm.samples   # occupancy
det_mat <- sf.co1.out$alpha.comm.samples  # detection

# make sure rhat/ESS vectors are named to match columns
names(sf.co1.out$rhat$beta.comm)  <- colnames(occ_mat)
names(sf.co1.out$rhat$alpha.comm) <- colnames(det_mat)
names(sf.co1.out$ESS$beta.comm)   <- colnames(occ_mat)
names(sf.co1.out$ESS$alpha.comm)  <- colnames(det_mat)

summ_comm_block <- function(mat, type_label){
  params <- colnames(mat)
  intercept_name <- "(Intercept)"
  bind_rows(
    lapply(params, function(p){
      draws <- mat[, p]
      alpha <- mat[, intercept_name]
      
      # extract Rhat and ESS for this parameter
      rhat_val <- if(type_label == "Occurrence") sf.co1.out$rhat$beta.comm[p]  else sf.co1.out$rhat$alpha.comm[p]
      ess_val  <- if(type_label == "Occurrence") sf.co1.out$ESS$beta.comm[p]   else sf.co1.out$ESS$alpha.comm[p]
      
      m    <- mean(draws)
      s    <- sd(draws)
      ci   <- quantile(draws, c(0.055, 0.945))
      ppos <- mean(draws > 0)
      pneg <- mean(draws < 0)
      
      dp    <- plogis(alpha + draws) - plogis(alpha)
      dp_m  <- mean(dp)
      dp_ci <- quantile(dp, c(0.055, 0.945))
      
      tibble(
        Process      = type_label,
        Covariate    = p,
        Mean_logit   = m,
        SD_logit     = s,
        CI2.5_logit  = ci[1],
        CI97.5_logit = ci[2],
        Ppos         = ppos,
        Pneg         = pneg,
        Effect       = case_when(
                         ppos > 0.89 ~ "positive",
                         pneg > 0.89 ~ "negative",
                         TRUE        ~ "ambiguous"
                       ),
        DeltaP_mean  = dp_m,
        DeltaP_lo    = dp_ci[1],
        DeltaP_hi    = dp_ci[2],
        Rhat         = rhat_val,
        ESS          = ess_val,
        Convergence  = case_when(
                         Rhat > 1.1  ~ "High Rhat",
                         ESS < 200   ~ "Low ESS",
                         TRUE        ~ "Converged"
                       )
      )
    })
  )
}

summ_occ <- summ_comm_block(occ_mat, "Occurrence")
summ_det <- summ_comm_block(det_mat, "Detection")

summ_comm_all <- bind_rows(summ_occ, summ_det)

summ_comm_all

summ_comm_all %>%
  filter(Convergence == "Converged") %>%
  filter(Effect != "ambiguous")
```

Community level- 
--> Negative impacts of west and night (makes sense- more occurrence in eastern bay and day time)
--> negative impacts of oyster reef and clam sanctuary but positive impact of occurrence at eelgrass sites
--> Positive impcats of temperature, salinity, chlorophyll (Chl makes sense bc many COI-taxa are phyto)
--> But negative impact of turbidity- interesting contract with Chla
--> Detection intercept is negative, meaning the baseline logodds of detecting the species if its present is below zero, similar to MiFish
--> Positive impact of filtration volume and start time on detection



Species level. Do same but also add in sp names

```{r}
occ_mat <- as.matrix(sf.co1.out$beta.samples)
det_mat <- as.matrix(sf.co1.out$alpha.samples)

names(sf.co1.out$rhat$beta)  <- colnames(occ_mat)
names(sf.co1.out$rhat$alpha) <- colnames(det_mat)
names(sf.co1.out$ESS$beta)   <- colnames(occ_mat)
names(sf.co1.out$ESS$alpha)  <- colnames(det_mat)

summ_block_mat <- function(mat, process_label) {
  params <- colnames(mat)
  # split each covariate-ASV_full into its two pieces:
  parts  <- str_split(params, "-", n = 2)
  covs   <- unique(map_chr(parts, 1))
  species_full <- unique(map_chr(parts, 2))
  
  bind_rows(
    lapply(species_full, function(sp) {
      alpha_draws <- mat[, paste0("(Intercept)-", sp)]
      
      bind_rows(
        lapply(covs, function(cov) {
          param_name <- paste0(cov, "-", sp)
          draws      <- mat[, param_name]
          
          rhat_val <- if (process_label=="Occurrence") sf.co1.out$rhat$beta[param_name] 
                      else                   sf.co1.out$rhat$alpha[param_name]
          ess_val  <- if (process_label=="Occurrence") sf.co1.out$ESS$beta[param_name]  
                      else                   sf.co1.out$ESS$alpha[param_name]
          
          m    <- mean(draws)
          s    <- sd(draws)
          ci   <- quantile(draws, c(0.055, 0.945))
          ppos <- mean(draws > 0)
          pneg <- mean(draws < 0)
          
          dp    <- plogis(alpha_draws + draws) - plogis(alpha_draws)
          dp_m  <- mean(dp)
          dp_ci <- quantile(dp, c(0.055, 0.945))
          
          tibble(
            ASV_full     = sp,
            Process      = process_label,
            Covariate    = cov,
            Mean_logit   = m,
            SD_logit     = s,
            CI2.5_logit  = ci[1],
            CI97.5_logit = ci[2],
            Ppos         = ppos,
            Pneg         = pneg,
            Effect       = case_when(
                             ppos > 0.89 ~ "positive",
                             pneg > 0.89 ~ "negative",
                             TRUE        ~ "ambiguous"
                           ),
            DeltaP_mean  = 100 * dp_m,
            DeltaP_lo    = 100 * dp_ci[1],
            DeltaP_hi    = 100 * dp_ci[2],
            Rhat         = rhat_val,
            ESS          = ess_val,
            Convergence  = case_when(
                             Rhat > 1.1  ~ "High Rhat",
                             ESS < 200   ~ "Low ESS",
                             TRUE        ~ "Converged"
                           )
          )
        })
      )
    })
  )
}

summ_occ <- summ_block_mat(occ_mat, "Occurrence")
summ_det <- summ_block_mat(det_mat, "Detection")
summ_sp_all <- bind_rows(summ_occ, summ_det)

tax_df      <- as.data.frame(tax_table(ps2024_exp_co1_glommed))
tax_df$ASV_full <- rownames(tax_df)

tax_lookup  <- tax_df %>%
  select(ASV_full, Kingdom, Phylum, Class, Order, Family, Genus, Species)

summ_sp_all_named <- summ_sp_all %>%
  left_join(tax_lookup, by = "ASV_full") %>%
  relocate(Kingdom:Species, .after = ASV_full)

summ_sp_all_named

summ_sp_all_named %>%
  filter(Convergence=="Converged", Effect!="ambiguous") %>%
  arrange(Covariate, Process, Effect, desc(Mean_logit))


```




save results tables

```{r}

write.csv(summ_comm_all,"figures-expedition/summ_comm_all_co1.csv", row.names = TRUE)
write.csv(summ_sp_all_named,"figures-expedition/summ_sp_all_named_co1.csv", row.names = TRUE)

```


Lot of interesting things:
- Many species have negative occurrence in western bay (i.e. higher occurrence in east) except a few like Gemma gemma, Haminella solitaria, Unknown Cylindrotheca (Genus), Halichondria bowerbanki (Yellow sun sponge- INVASIVE!), Unknown Grateloupia (Genus)- PROBABLY DEVIL'S TONGUE WEED- INVASIVE, Unknown Cordycipitaceae (Family), Unknown Asteronema__f__o (Order), Unknown Olpidiopsidaceae (Family), Glycinde multidens, Nanomia bijuga, Agardhiella subulata, Unknown Paraliales (Order), Unknown Toxariales (Order)-- inspect these a little further for bioindicators and possible HABs
- Most positively associated ASV with eelgrass was Cheilostomatida Order, Bryozoans that grow on surfaces including seagrasses. Also among the many positive occurrences with eelgrass: Ctenogobius boleosoma (Darter goby), Centropages typicus (free-living copepod), Sphyraena borealis (Northern sennet), Bivalves: Unknown Venerida (Order) and Unknown Ensis (Genus) and Ameritella agilis and Yoldia limatula, Unknown Octopoda (Order), Unknown Menidia (Genus), Unknown Aves (Class), Chaetodon ocellatus (Spotfin butterfly), lots of Hydrozoa, Cancer irroratus (Atlantic rock crab), Mercenaria mercenaria, Syngnathus fuscus, Syngnathus fuscus (Northern pipefish), Dyspanopeus sayi (mud crab),  (Northern dwarf-tellin clam), Crepidula fornicata (Slipper limpet), many others
- MANY negative occurrences with night, no positive occurrence. Most strongly positive was Ulvophyceae
- MANY positive occurrences with salinity


Examine only animals of interest and occurrence covariates
```{r}
summ_sp_all_named_animalsofinterest <- summ_sp_all_named %>%
  filter(Phylum %in% c("Arthropoda","Mollusca","Chordata","Echinodermata"),
    ! Class %in% c("Insecta","Arachnida"),
    ! Covariate %in% c("(Intercept)")
  )

summ_sp_all_named_animalsofinterest
```


save results tables

```{r}

write.csv(summ_sp_all_named_animalsofinterest,"figures-expedition/summ_sp_all_named_animalsofinterest_co1.csv", row.names = TRUE)

```


Eastern bayside occupancy:
  
```{r}
# Pick some ASVs (There are many so stick with some strongly associated with East)
target_asvs <- c(
  "ASV_4238_c","ASV_3903_a","ASV_3675_a","ASV_1247_c","ASV_2062_b",
  "ASV_2052_a","ASV_509_c","ASV_4900_b","ASV_15697_a","ASV_2498_c",
  "ASV_5194_c","ASV_6074_a"
)

# pull out the posterior draws matrix and its column names
beta_mat    <- as.matrix(sf.co1.out$beta.samples)
param_names <- colnames(beta_mat)

# extract the interceptdraws and BaysideWdraws
res_list <- lapply(target_asvs, function(asv) {
  int_col   <- paste0("(Intercept)-", asv)
  slope_col <- paste0("BaysideW-",     asv)
  
  if (!int_col %in% param_names || !slope_col %in% param_names) {
    warning("ASV not found in beta.samples: ", asv)
    return(NULL)
  }
  
  draws_int <- beta_mat[, int_col]
  draws_bs  <- beta_mat[, slope_col]
  
  # occupancy probability in West (baseline) vs East (baseline+slope)
  p_w <- plogis(draws_int)
  p_e <- plogis(draws_int + draws_bs)
  dp  <- p_e - p_w
  
  tibble(
    ASV         = asv,
    DeltaP_mean = mean(dp) * 100,            # %-pts
    DeltaP_lo   = quantile(dp, .055) * 100,  # 89% lower
    DeltaP_hi   = quantile(dp, .945) * 100   # 89% upper
  )
})

plot_df <- bind_rows(res_list)

# attach scientific species name from phyloseq
tax_df <- as.data.frame(tax_table(ps2024_exp_co1_glommed)) %>%
  rownames_to_column("ASV") %>%
  select(ASV, Species)

plot_df <- left_join(plot_df, tax_df, by = "ASV")

# bring in common names and make the y-axis label (prefer common, fallback to scientific)
commonnames <- readr::read_csv("../eDNA-databases/commonnames.csv") %>%
  # standardize and make the dot-name easier to use
  mutate(
    taxon     = stringr::str_squish(Taxon),
    taxon_com = `Taxon.CommonName`
  ) %>%
  select(taxon, taxon_com)

plot_df <- plot_df %>%
  mutate(Species = stringr::str_squish(Species)) %>%
  left_join(commonnames, by = c("Species" = "taxon")) %>%
  mutate(
    y_label = dplyr::coalesce(taxon_com, Species)
  )

# horizontal forest plot using common names on the y-axis
co1_eastbay_occupancy_ASVs_forestplot <- ggplot(
  plot_df,
  aes(x = reorder(y_label, DeltaP_mean), y = DeltaP_mean)
) +
  geom_point() +
  geom_errorbar(aes(ymin = DeltaP_lo, ymax = DeltaP_hi), width = 0.2) +
  coord_flip() +
  labs(
    x = NULL,
    y = "P occupancy probability (%)",
    title = "Species with higher occupancy in East"
  ) +
  theme_bw() +
  theme(
    axis.text.y = element_text(size = 9),
    plot.title  = element_text(size = 11)
  )

co1_eastbay_occupancy_ASVs_forestplot

ggsave(
  plot     = co1_eastbay_occupancy_ASVs_forestplot,
  filename = "figures-expedition/co1_eastbay_occupancy_ASVs_forestplot.jpg",
  width = 5, height = 3, units = "in", dpi = 300
)

```



Western bayside occupancy:

```{r}
# West-leaning ASVs
target_asvs <- c(
  "ASV_1036_a","ASV_134_a","ASV_234_a","ASV_923_a","ASV_64_b",
  "ASV_365_c","ASV_41_b","ASV_1359_b","ASV_1021_b","ASV_2356_a"
)

# posterior draws
beta_mat    <- as.matrix(sf.co1.out$beta.samples)
param_names <- colnames(beta_mat)

# compute P = P_West  P_East for each ASV
res_list <- lapply(target_asvs, function(asv) {
  int_col   <- paste0("(Intercept)-", asv)
  slope_col <- paste0("BaysideW-",     asv)
  
  if (!int_col %in% param_names || !slope_col %in% param_names) {
    warning("ASV not found in beta.samples: ", asv)
    return(NULL)
  }
  
  draws_int <- beta_mat[, int_col]
  draws_bs  <- beta_mat[, slope_col]
  
  p_w <- plogis(draws_int)            # West = reference
  p_e <- plogis(draws_int + draws_bs) # East = West + slope
  dp  <- p_e - p_w                    # West minus East
  
  tibble(
    ASV         = asv,
    DeltaP_mean = mean(dp) * 100,            # %-points
    DeltaP_lo   = quantile(dp, .055) * 100,  # 89% lower
    DeltaP_hi   = quantile(dp, .945) * 100   # 89% upper
  )
})

plot_df <- bind_rows(res_list)

# attach scientific species name from phyloseq
tax_df <- as.data.frame(tax_table(ps2024_exp_co1_glommed)) %>%
  rownames_to_column("ASV") %>%
  select(ASV, Species)

plot_df <- left_join(plot_df, tax_df, by = "ASV")

# bring in common names (Taxon, Taxon.CommonName) and build label
commonnames <- readr::read_csv("../eDNA-databases/commonnames.csv") %>%
  mutate(
    taxon     = stringr::str_squish(Taxon),
    taxon_com = `Taxon.CommonName`
  ) %>%
  select(taxon, taxon_com)

plot_df <- plot_df %>%
  mutate(Species = stringr::str_squish(Species)) %>%
  left_join(commonnames, by = c("Species" = "taxon")) %>%
  mutate(y_label = dplyr::coalesce(taxon_com, Species))

# forest plot (West  East) with common names on y-axis
co1_westbay_occupancy_ASVs_forestplot <- ggplot(
  plot_df,
  aes(x = reorder(y_label, DeltaP_mean), y = DeltaP_mean)
) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = DeltaP_lo, ymax = DeltaP_hi), width = 0.2) +
  coord_flip() +
  labs(
    x = NULL,
    y = "P occupancy probability (%)",
    title = "Species with higher occupancy in West"
  ) +
  theme_bw() +
  theme(
    axis.text.y = element_text(size = 9),
    plot.title  = element_text(size = 11)
  )

co1_westbay_occupancy_ASVs_forestplot

ggsave(
  plot     = co1_westbay_occupancy_ASVs_forestplot,
  filename = "figures-expedition/co1_westbay_occupancy_ASVs_forestplot.jpg",
  width    = 5, height = 3, units = "in", dpi = 300
)

```


Combined figure
```{r}
# Define label strings 
label_east <- "Higher in East ()"
label_west <- "Higher in West (+)"

# helpers
norm_sciname <- function(x) {
  x %>%
    stringr::str_to_lower() %>%
    stringr::str_replace_all("[^a-z ]", " ") %>%
    stringr::str_squish()
}

# targets
target_asvs_east <- c(
  "ASV_4238_c","ASV_3903_a","ASV_3675_a","ASV_1247_c","ASV_2062_b",
  "ASV_2052_a","ASV_509_c","ASV_4900_b","ASV_15697_a","ASV_2498_c",
  "ASV_5194_c","ASV_6074_a"
)
target_asvs_west <- c(
  "ASV_1036_a","ASV_134_a","ASV_234_a","ASV_923_a","ASV_64_b",
  "ASV_365_c","ASV_41_b","ASV_1359_b","ASV_1021_b","ASV_2356_a"
)

# Posterior draws
beta_mat    <- as.matrix(sf.co1.out$beta.samples)
param_names <- colnames(beta_mat)

# Function to compute P = East - West
deltaP_west_minus_east <- function(asv_vec) {
  res <- lapply(asv_vec, function(asv) {
    int_col   <- paste0("(Intercept)-", asv)
    slope_col <- paste0("BaysideW-",     asv)
    if (!int_col %in% param_names || !slope_col %in% param_names) return(NULL)
    draws_int <- beta_mat[, int_col]
    draws_bs  <- beta_mat[, slope_col]
    # West is reference; East = West + slope
    p_w <- plogis(draws_int)
    p_e <- plogis(draws_int + draws_bs)
    dp  <-  p_e - p_w
    tibble(
      ASV         = asv,
      DeltaP_mean = mean(dp) * 100,
      DeltaP_lo   = quantile(dp, .055) * 100,
      DeltaP_hi   = quantile(dp, .945) * 100
    )
  })
  bind_rows(res)
}

# Compute deltas
east_df <- deltaP_west_minus_east(target_asvs_east) %>% mutate(set = "East-leaning (negative)")
west_df <- deltaP_west_minus_east(target_asvs_west) %>% mutate(set = "West-leaning (positive)")

comb_df <- bind_rows(east_df, west_df)

# Attach scientific  name
tax_df <- as.data.frame(tax_table(ps2024_exp_co1_glommed)) %>%
  rownames_to_column("ASV") %>%
  select(ASV, Species)

comb_df <- comb_df %>%
  left_join(tax_df, by = "ASV")

# common names (Taxon, Taxon.CommonName)
commonnames <- readr::read_csv("../eDNA-databases/commonnames.csv") %>%
  transmute(Taxon,
            taxon_com  = `Taxon.CommonName`,
            Taxon_norm = norm_sciname(Taxon))

# Labeling
comb_df <- comb_df %>%
  mutate(Species_norm = norm_sciname(Species)) %>%
  left_join(select(commonnames, Taxon_norm, taxon_com),
            by = c("Species_norm" = "Taxon_norm")) %>%
  mutate(
    y_label   = dplyr::coalesce(taxon_com, Species),
    Direction = factor(
    if_else(DeltaP_mean >= 0, label_west, label_east),
    levels = c(label_west, label_east)))

# Axis limits
lim <- max(abs(c(comb_df$DeltaP_lo, comb_df$DeltaP_hi)), na.rm = TRUE)

# Final plot
one_forest <- ggplot(
  comb_df,
  aes(x = reorder(y_label, DeltaP_mean), y = DeltaP_mean, colour = Direction)
) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = DeltaP_lo, ymax = DeltaP_hi), width = 0.2) +
  coord_flip() +
  scale_y_reverse(limits = c(lim, -lim)) +
  scale_colour_manual(values = c(
    "Higher in West (+)" = "cornflowerblue",
    "Higher in East ()" = "coral"
  )) +
  labs(
    x = NULL,
    y = "P occupancy probability (%)",
    title = "Species with differential occupancy across the Bay",
    colour = NULL
  ) +
  theme_bw() +
  theme(
    axis.text.y = element_text(size = 9),
    plot.title  = element_text(size = 10, face = "bold"),
    legend.position = "top"
  )

# Show plot
print(one_forest)

# Save
ggsave(
  "figures-expedition/co1_combined_east_west_forest.jpg",
  one_forest, width = 6.5, height = 6.5, units = "in", dpi = 300
)
ggsave(
  "figures-expedition/co1_combined_east_west_forest.eps",
  one_forest, width = 6.5, height = 6.5, units = "in"
)

```



Eel grass occupancy


```{r}
# helpers
norm_sciname <- function(x) {
  x %>%
    stringr::str_to_lower() %>%
    stringr::str_replace_all("[^a-z ]", " ") %>%
    stringr::str_squish()
}

# Target ASVs with higher occupancy in Eelgrass
target_asvs <- c("ASV_6718_c",
  "ASV_694_a","ASV_3315_a","ASV_210_c","ASV_709_c","ASV_8572_a",
  "ASV_6255_c","ASV_779_b","ASV_4900_b","ASV_2504_a","ASV_2132_c",
  "ASV_7857_b","ASV_9025_c","ASV_15697_a","ASV_7823_b",
  "ASV_268_c","ASV_5391_a","ASV_979_a","ASV_6192_a","ASV_480_b",
  "ASV_897_a","ASV_5289_a","ASV_2599_a","ASV_4189_b","ASV_3166_a",
  "ASV_639_c","ASV_8432_a","ASV_10195_c","ASV_6074_a","ASV_1529_a"
)

# Posterior draws matrix
beta_mat    <- as.matrix(sf.co1.out$beta.samples)
param_names <- colnames(beta_mat)

# Compute P = P(Eelgrass)  P(Open water)
res_list <- lapply(target_asvs, function(asv) {
  int_col    <- paste0("(Intercept)-",       asv)
  slope_col  <- paste0("HabitatEELGRASS-",   asv)

  if (!int_col %in% param_names || !slope_col %in% param_names) {
    warning("ASV not found in beta.samples: ", asv)
    return(NULL)
  }

  draws_int <- beta_mat[, int_col]
  draws_h   <- beta_mat[, slope_col]

  p_open    <- plogis(draws_int)
  p_eel     <- plogis(draws_int + draws_h)
  dp        <- p_eel - p_open

  tibble(
    ASV         = asv,
    DeltaP_mean = mean(dp) * 100,
    DeltaP_lo   = quantile(dp, .055) * 100,
    DeltaP_hi   = quantile(dp, .945) * 100
  )
})

plot_df <- bind_rows(res_list)

# Join species names
tax_df <- as.data.frame(tax_table(ps2024_exp_co1_glommed)) %>%
  rownames_to_column("ASV") %>%
  select(ASV, Species)

plot_df <- left_join(plot_df, tax_df, by = "ASV")

# common names
commonnames <- readr::read_csv("../eDNA-databases/commonnames.csv") %>%
  transmute(Taxon,
            taxon_com  = `Taxon.CommonName`,
            Taxon_norm = norm_sciname(Taxon))

plot_df <- plot_df %>%
  mutate(Species_norm = norm_sciname(Species)) %>%
  left_join(select(commonnames, Taxon_norm, taxon_com),
            by = c("Species_norm" = "Taxon_norm")) %>%
  mutate(label = dplyr::coalesce(taxon_com, Species))

# Forest plot
co1_eelgrass_occupancy_ASVs_forestplot <- ggplot(plot_df, aes(
    x = reorder(label, DeltaP_mean),
    y = DeltaP_mean
  )) +
  geom_point(size = 2, color = "chartreuse4") +
  geom_errorbar(aes(ymin = DeltaP_lo, ymax = DeltaP_hi), width = 0.2, color = "chartreuse4") +
  coord_flip() +
  labs(
    x     = NULL,
    y     = "P occupancy probability (%)",
    title = "Species with higher occupancy in Eelgrass"
  ) +
  theme_bw() +
  theme(
    axis.text.y = element_text(size = 9),
    plot.title  = element_text(size = 10, face = "bold")
  )

# Show plot
co1_eelgrass_occupancy_ASVs_forestplot

# Save
ggsave(
  plot     = co1_eelgrass_occupancy_ASVs_forestplot,
  filename = "figures-expedition/co1_eelgrass_occupancy_ASVs_forestplot.jpg",
  width    = 6,
  height   = 5,
  units    = "in"
)

```

Relationship with time of day
ASV_3368_a, ASV_2498_c, ASV_7758_b


```{r}

asvs <- c("ASV_3368_a","ASV_2498_c","ASV_7758_b")
tax_df     <- as.data.frame(tax_table(ps2024_exp_co1_glommed))
tax_df$ASV <- rownames(tax_df)
tax_lookup <- tax_df %>% select(ASV, Species)

# Pull out the posterior draws
det_draws <- as.matrix(sf.co1.out$alpha.samples)

# Build a grid of Start_Time values (in original units)
st_vals <- seq(
  min(co1.exp.list$det.covs$Start_Time, na.rm=TRUE),
  max(co1.exp.list$det.covs$Start_Time, na.rm=TRUE),
  length.out = 100
)

# compute posterior detection probability draws
pred_df <- map_dfr(asvs, function(sp) {
  int_draws <- det_draws[, paste0("(Intercept)-", sp)]
  b_st      <- det_draws[, paste0("Start_Time-", sp)]
  
  # for each Start_Time , get vector of p_draws
  p_mat <- sapply(st_vals, function(x) {
    plogis(int_draws + b_st * x)
  })  # dimension: iterations  length(st_vals)
  
  #  summarize across iterations for each st_vals
  tibble(
    ASV        = sp,
    Start_Time = st_vals,
    p_mean     = colMeans(p_mat),
    p_lo       = apply(p_mat, 2, quantile, 0.025),
    p_hi       = apply(p_mat, 2, quantile, 0.975)
  )
})

# common names
pred_df <- pred_df %>%
  left_join(tax_lookup, by = "ASV")

# plot
timeofdayeffects_co1_plot <- ggplot(pred_df, aes(x = Start_Time, y = p_mean)) +
  geom_ribbon(aes(ymin = p_lo, ymax = p_hi), fill = "grey80", alpha = 0.5) +
  geom_line(size = 1) +
  facet_wrap(~ Species, scales = "free_y") +
  labs(
    x = "Start Time (Hour)",
    y = "Detection probability",
    title = "Effect of Start Time on eDNA detection",
    subtitle = "ASVs with positive time-of-day effects"
  ) +
  theme_bw()


timeofdayeffects_co1_plot


ggsave(plot = timeofdayeffects_co1_plot, filename = "figures-expedition/timeofdayeffects_co1_plot.jpg", width = 8, height = 4, units = "in")

```



Community-Level Detection Probability vs. Filtration Volume
```{r}
# posterior draws for the Volume_liter detection covariate
vol_samps <- as.matrix(sf.co1.out$alpha.comm.samples)
draws_int <- vol_samps[, "(Intercept)"]
draws_vol <- vol_samps[, "Volume_liter"]

# Sequence of filtration volumes (in L) to predict over
v_seq <- seq(
  min(co1.exp.list$det.covs$Volume_liter, na.rm = TRUE),
  max(co1.exp.list$det.covs$Volume_liter, na.rm = TRUE),
  length.out = 100
)

# predicted detection probabilities across posterior draws
pred_matrix <- sapply(v_seq, function(v) {
  plogis(draws_int + draws_vol * v)
})  # dimensions: iterations  volumes

# Summarize across posterior draws
vol_df <- tibble(
  Volume_liter = v_seq,
  p_mean = colMeans(pred_matrix),
  p_lo   = apply(pred_matrix, 2, quantile, 0.025),
  p_hi   = apply(pred_matrix, 2, quantile, 0.975)
)

# Plot
co1_volume_effect_plot <- ggplot(vol_df, aes(x = Volume_liter, y = p_mean)) +
  geom_ribbon(aes(ymin = p_lo, ymax = p_hi), fill = "grey80", alpha = 0.5) +
  geom_line(size = 1.2, color = "black") +
  labs(
    x = "Filtration Volume (L)",
    y = "Estimated community-level detection probability",
    title = "Effect of Filtration Volume on eDNA Detection Probability: CO1"
  ) +
  theme_bw()


co1_volume_effect_plot

ggsave(
  plot = co1_volume_effect_plot,
  filename = "figures-expedition/co1_volume_effect_community_detection.jpg",
  width = 6,
  height = 4,
  units = "in",
  dpi = 300
)

```







##### Check Model diagnostics
###### 1. Convergence diagnostics

```{r}
plot(sf.co1.out, param = "beta")  
plot(sf.co1.out, param = "alpha")
```

--> 

###### 2. Posterior predictive checks



```{r}
ppc_specs <- tribble(
  ~name,     ~fit.stat,           ~group,
  "ft_comm", "freeman-tukey",       1L,
  "ft_species", "freeman-tukey",    2L,
  "chi_comm",  "chi-squared",        1L,
  "chi_species","chi-squared",      2L
)

ppc_results <- ppc_specs %>%
  mutate(
    ppc_obj = pmap(
      list(fit.stat, group),
      ~ ppcOcc(sf.co1.out, fit.stat = ..1, group = ..2)
    )
  )

# helper to pull ppcOcc pvalues from the printed summary
extract_ppc_pvals <- function(ppc_obj) {
  txt <- capture.output(summary(ppc_obj))
  com_i <- grep("Community Level", txt) + 1
  comm_line <- grep("Bayesian p-value", txt[com_i:length(txt)], value=TRUE)[1]
  comm_p <- as.numeric(str_extract(comm_line, "\\d+\\.\\d+"))
  
  spec_lines <- grep("^ASV_", txt, value=TRUE)
  sp_df <- tibble(
    ASV     = str_extract(spec_lines, "^ASV_[0-9]+"),
    p.value = as.numeric(str_extract(spec_lines, "\\d+\\.\\d+$"))
  )
  
  list(community = comm_p, species = sp_df)
}



# communitylevel  
comm_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  transmute(
    check   = name,
    level   = "community",
    ASV     = NA_character_,
    p.value = map_dbl(tmp, "community")
  )

# specieslevel 
spec_tbl <- ppc_results %>%
  mutate(tmp = map(ppc_obj, extract_ppc_pvals)) %>%
  select(name, tmp) %>%
  unnest_longer(tmp, indices_to="which", values_to="block") %>%    # yields two blocks: community & species
  filter(which=="species") %>%                                      # keep species block
  unnest(block) %>%                                                 # expands to columns ASV, p.value
  transmute(
    check   = name,
    level   = "species",
    ASV,
    p.value
  )


ppc_pvals <- bind_rows(comm_tbl, spec_tbl)

# now ppc_pvals has columns: check, level, ASV, p.value
ppc_pvals

ppc_flagged <- ppc_pvals %>%
  mutate(
    fit_flag = case_when(
       p.value < 0.025 | p.value > 0.975 ~ "unacceptable",
       p.value < 0.10  | p.value > 0.90  ~ "borderline",
       TRUE                              ~ "acceptable"
    )
  )

# full table
ppc_flagged

# acceptable
filter(ppc_flagged, fit_flag=="acceptable")

# unacceptable
filter(ppc_flagged, fit_flag=="unacceptable")

# borderline
filter(ppc_flagged, fit_flag=="borderline")

```



###### 3. WAIC for model comparison

```{r}
waicOcc(sf.co1.out)

```







#### Save environment
```{r}
# the data objects and model outputs are huge and slow up saving/loading. remove before running- will just have to rerun making the lists every time (it's quick). models saved above as their own separate files

# rm(elas.exp.list,mifish.exp.list,co1.exp.list,model_out_elas,sf.elas.out,sf.mifish.out,sf.co1.out,sf.co1.out.thin,sf.elas.out,beta_mat,model_out_mifish,model_out_elas,occ_mat)

# save.image(file = "figures-expedition/exp_ecol_analysis_environment_upto_spOccupancyModels.RData")
```


```{r}
# load(file = "figures-expedition/exp_ecol_analysis_environment_upto_spOccupancyModels.RData")
```


# Phi interpretation
From [here](https://doserlab.com/files/spoccupancy-web/articles/modelconsiderations): " the spatial decay parameter 
 has a nice interpretation in that 3 is the effective spatial range. The effective spatial range is defined as the distance between sites at which the spatial autocorrelation falls to a small value (0.05), and thus can be interpreted as how far across space the spatial autocorrelation between two sites goes. From an ecological perspective, this is a fairly intuitive parameter that can be related to a lot of interesting processes such as the dispersal distance of the species youre working with, the underlying spatial pattern of any missing covariates that are not included in the model, or a result of the specific study design chosen (e.g., if sites are collected in a cluster sampling design). However, in the type of spatial models we fit in spOccupancy (i.e., point-referenced spatial models), the spatial decay parameter  and the spatial variance parameter 2 (which controls the magnitude of the spatial variability) are only weakly identifiable. Theoretical work shows the product of the two parameters is identifiable, but that the two parameters individually are only weakly identifiable..."

--> The phi values for all models are large (400-450), meaning the spatial decay is very rapid/ spatial autocorrelation is basically non existent (3/400 = 0.0075 meters)
Justifies using the non spatial models in addition to comparing WAICs....



# VI. Species Richness- 
## Avg sample richness
```{r}
# species_counts_exp_mifish <- ps2024_exp_mifish_glommed_df %>%
#   group_by(Sample, Deployment, sites, replicates, site_altname, Volume_liter, lat, long, Bayside_f, Habitat, Site_type, Night__Day, Datecode, Month, Day, Avg_Depth_m, Avg_Temperature_C, Avg_Salinity_psu, Avg_Chlorophyll_ugL, Avg_Turbidity_NTU) %>%
#   summarise(UniqueSpeciesCount = n_distinct(Species), .groups = "drop")

species_counts_exp_mifish <- ps2024_exp_mifish_glommed_df %>%
  group_by(Sample, Habitat, Bayside_f) %>%
  summarise(UniqueSpeciesCount = n_distinct(Species), .groups = "drop")

species_counts_exp_elas <- ps2024_exp_elas_glommed_df %>%
  group_by(Sample, Habitat, Bayside_f) %>%
  summarise(UniqueSpeciesCount = n_distinct(Species), .groups = "drop")


species_counts_exp_mifish
species_counts_exp_elas

```

Calculate averages
```{r}
species_stats_by_habitat_mifish <- species_counts_exp_mifish %>%
  group_by(Habitat) %>%
  summarise(
    AverageUniqueSpeciesCount = mean(UniqueSpeciesCount, na.rm = TRUE),
    StdDevUniqueSpeciesCount = sd(UniqueSpeciesCount, na.rm = TRUE)
  )

species_stats_by_habitat_mifish

species_stats_by_bayside_mifish <- species_counts_exp_mifish %>%
  group_by(Bayside_f) %>%
  summarise(
    AverageUniqueSpeciesCount = mean(UniqueSpeciesCount, na.rm = TRUE),
    StdDevUniqueSpeciesCount = sd(UniqueSpeciesCount, na.rm = TRUE)
  )

species_stats_by_bayside_mifish


species_stats_by_habitat_elas <- species_counts_exp_elas %>%
  group_by(Habitat) %>%
  summarise(
    AverageUniqueSpeciesCount = mean(UniqueSpeciesCount, na.rm = TRUE),
    StdDevUniqueSpeciesCount = sd(UniqueSpeciesCount, na.rm = TRUE)
  )

species_stats_by_habitat_elas

species_stats_by_bayside_elas <- species_counts_exp_elas %>%
  group_by(Bayside_f) %>%
  summarise(
    AverageUniqueSpeciesCount = mean(UniqueSpeciesCount, na.rm = TRUE),
    StdDevUniqueSpeciesCount = sd(UniqueSpeciesCount, na.rm = TRUE)
  )

species_stats_by_bayside_elas
```

### Plot
```{r}
# Put line breaks in x-tick labels for plotting
species_stats_by_habitat_mifish$Habitat <- gsub(" ", "\n", species_stats_by_habitat_mifish$Habitat)
species_stats_by_habitat_elas$Habitat <- gsub(" ", "\n", species_stats_by_habitat_elas$Habitat)


#Plot
species_richness_by_habitat_mifish_plot <- 
ggplot(species_stats_by_habitat_mifish, aes(x = Habitat, y = AverageUniqueSpeciesCount)) +
  geom_bar(stat = "identity", fill = c("azure2", "chartreuse4", "cadetblue1", "darkgrey"), alpha = 0.8) +  
  geom_errorbar(aes(ymin = AverageUniqueSpeciesCount - StdDevUniqueSpeciesCount,
                    ymax = AverageUniqueSpeciesCount + StdDevUniqueSpeciesCount), 
                width = 0.2, color = "black") +  # Error bars
  labs(x = "", y = "Avg Species Richness") +  
  theme_minimal() 
species_richness_by_habitat_mifish_plot

species_richness_by_bayside_mifish_plot <- 
ggplot(species_stats_by_bayside_mifish, aes(x = Bayside_f, y = AverageUniqueSpeciesCount)) +
  geom_bar(stat = "identity", fill = c("cornflowerblue", "coral"), alpha = 0.8) +  
  geom_errorbar(aes(ymin = AverageUniqueSpeciesCount - StdDevUniqueSpeciesCount,
                    ymax = AverageUniqueSpeciesCount + StdDevUniqueSpeciesCount), 
                width = 0.2, color = "black") +  # Error bars
  labs(x = "", y = "Avg Species Richness") +  
  theme_minimal() 
species_richness_by_bayside_mifish_plot

species_richness_by_habitat_elas_plot <- 
ggplot(species_stats_by_habitat_elas, aes(x = Habitat, y = AverageUniqueSpeciesCount)) +
  geom_bar(stat = "identity", fill = c("azure2", "chartreuse4", "cadetblue1"), alpha = 0.8) +  
  geom_errorbar(aes(ymin = AverageUniqueSpeciesCount - StdDevUniqueSpeciesCount,
                    ymax = AverageUniqueSpeciesCount + StdDevUniqueSpeciesCount), 
                width = 0.2, color = "black") +  # Error bars
  labs(x = "", y = "Avg Species Richness") +  
  theme_minimal() 
species_richness_by_habitat_elas_plot

species_richness_by_bayside_elas_plot <- 
ggplot(species_stats_by_bayside_elas, aes(x = Bayside_f, y = AverageUniqueSpeciesCount)) +
  geom_bar(stat = "identity", fill = c("cornflowerblue", "coral"), alpha = 0.8) +  
  geom_errorbar(aes(ymin = AverageUniqueSpeciesCount - StdDevUniqueSpeciesCount,
                    ymax = AverageUniqueSpeciesCount + StdDevUniqueSpeciesCount), 
                width = 0.2, color = "black") +  # Error bars
  labs(x = "", y = "Avg Species Richness") +  
  theme_minimal() 
species_richness_by_bayside_elas_plot


```

save
```{r}
ggsave(plot = species_richness_by_habitat_mifish_plot, filename = "figures-expedition/species_richness_by_habitat_mifish_plot.jpg", width = 4, height = 4, units = "in")

ggsave(plot = species_richness_by_bayside_mifish_plot, filename = "figures-expedition/species_richness_by_bayside_mifish_plot.jpg", width = 2.5, height = 4, units = "in")

ggsave(plot = species_richness_by_habitat_elas_plot, filename = "figures-expedition/species_richness_by_habitat_elas_plot.jpg", width = 4, height = 4, units = "in")

ggsave(plot = species_richness_by_bayside_elas_plot, filename = "figures-expedition/species_richness_by_bayside_elas_plot.jpg", width = 2.5, height = 4, units = "in")

```


## Overall richness by site type
```{r}
species_counts_bayside_mifish <- ps2024_exp_mifish_glommed_df %>%
  group_by(Bayside_f) %>%
  summarise(UniqueSpeciesCount = n_distinct(`Species.CommonName`), .groups = "drop")

species_counts_bayside_mifish

species_counts_habitat_mifish <- ps2024_exp_mifish_glommed_df %>%
  group_by(Habitat) %>%
  summarise(UniqueSpeciesCount = n_distinct(`Species.CommonName`), .groups = "drop")

species_counts_habitat_mifish

species_counts_bayside_elas <- ps2024_exp_elas_glommed_df %>%
  group_by(Bayside_f) %>%
  summarise(UniqueSpeciesCount = n_distinct(`Species.CommonName`), .groups = "drop")

species_counts_bayside_elas

species_counts_habitat_elas <- ps2024_exp_elas_glommed_df %>%
  group_by(Habitat) %>%
  summarise(UniqueSpeciesCount = n_distinct(`Species.CommonName`), .groups = "drop")

species_counts_habitat_elas

```

### Plot
```{r}
# Put line breaks in x-tick labels for plotting
species_counts_habitat_mifish$Habitat <- gsub(" ", "\n", species_counts_habitat_mifish$Habitat)
species_counts_habitat_elas$Habitat <- gsub(" ", "\n", species_counts_habitat_elas$Habitat)


#Plot
species_counts_by_habitat_mifish_plot <- 
ggplot(species_counts_habitat_mifish, aes(x = Habitat, y = UniqueSpeciesCount)) +
  geom_bar(stat = "identity", fill = c("azure2", "chartreuse4", "cadetblue1", "darkgrey"), alpha = 0.8) +  
  labs(x = "", y = "Total Species Richness") +  
  theme_minimal() 
species_counts_by_habitat_mifish_plot

species_counts_by_bayside_mifish_plot <- 
ggplot(species_counts_bayside_mifish, aes(x = Bayside_f, y = UniqueSpeciesCount)) +
  geom_bar(stat = "identity", fill = c("cornflowerblue", "coral"), alpha = 0.8) +  
  labs(x = "", y = "Total Species Richness") +  
  theme_minimal() 
species_counts_by_bayside_mifish_plot

species_counts_by_habitat_elas_plot <- 
ggplot(species_counts_habitat_elas, aes(x = Habitat, y = UniqueSpeciesCount)) +
  geom_bar(stat = "identity", fill = c("azure2", "chartreuse4", "cadetblue1"), alpha = 0.8) +  
  labs(x = "", y = "Total Species Richness") +  
  theme_minimal() 
species_counts_by_habitat_elas_plot

species_counts_by_bayside_elas_plot <- 
ggplot(species_counts_bayside_elas, aes(x = Bayside_f, y = UniqueSpeciesCount)) +
  geom_bar(stat = "identity", fill = c("cornflowerblue", "coral"), alpha = 0.8) +  
  labs(x = "", y = "Total Species Richness") +  
  theme_minimal() 
species_counts_by_bayside_elas_plot


```

save
```{r}
ggsave(plot = species_counts_by_habitat_mifish_plot, filename = "figures-expedition/species_counts_by_habitat_mifish_plot.jpg", width = 4, height = 4, units = "in")

ggsave(plot = species_counts_by_bayside_mifish_plot, filename = "figures-expedition/species_counts_by_bayside_mifish_plot.jpg", width = 2.5, height = 4, units = "in")

ggsave(plot = species_counts_by_habitat_elas_plot, filename = "figures-expedition/species_counts_by_habitat_elas_plot.jpg", width = 4, height = 4, units = "in")

ggsave(plot = species_counts_by_bayside_elas_plot, filename = "figures-expedition/species_counts_by_bayside_elas_plot.jpg", width = 2.5, height = 4, units = "in")

```


# VII. Multivariate Analysis

## PCA
PCA is essentially a type of PCoA using the Euclidean distance matrix as input. When combined with a log-ratio transformation of the count table, this is appropriate for compositional datasets. It is also recommended as a first step in exploratory analyses of sequencing datasets.

### CLR Transformation
First do a CLR, centered log ratio transformation of the absolute abundance data (after filtering), as suggested by [Gloor et al. 2017](https://www.frontiersin.org/journals/microbiology/articles/10.3389/fmicb.2017.02224/full) for compositional data

#### Estimate covariance matrix for CLR-transformed ASV table
`compositions::clr` expects samples in columns, species in rows.
Multivariate analyses cannot handle zeroes but clr should remove them... check for zeroes after transformation.
```{r}

# replace zeroes with very very small numbers
ps2024_exp_mifish_glommed_zerosubbed <- as.data.frame(otu_table(ps2024_exp_mifish_glommed))
ps2024_exp_mifish_glommed_zerosubbed[ps2024_exp_mifish_glommed_zerosubbed == 0] <- 1e-10 

ps2024_exp_elas_glommed_zerosubbed <- as.data.frame(otu_table(ps2024_exp_elas_glommed))
ps2024_exp_elas_glommed_zerosubbed[ps2024_exp_elas_glommed_zerosubbed == 0] <- 1e-10 

ps2024_exp_co1_glommed_zerosubbed <- as.data.frame(otu_table(ps2024_exp_co1_glommed))
ps2024_exp_co1_glommed_zerosubbed[ps2024_exp_co1_glommed_zerosubbed == 0] <- 1e-10 


exp_mifish_glommed_clr <- data.frame(compositions::clr(ps2024_exp_mifish_glommed_zerosubbed))
exp_elas_glommed_clr <- data.frame(compositions::clr(ps2024_exp_elas_glommed_zerosubbed))
exp_co1_glommed_clr <- data.frame(compositions::clr(ps2024_exp_co1_glommed_zerosubbed))

any(exp_mifish_glommed_clr==0)
any(exp_elas_glommed_clr==0)
any(exp_co1_glommed_clr==0)

```


Generate PCA. Leaving scaling off (default) because these are already scaled by CLR.
`prcomp` generally expects samples are rows and variables are columns.
```{r}
lograt_pca_mifish_exp <- prcomp(t(exp_mifish_glommed_clr), rank. = 10)
lograt_pca_elas_exp <- prcomp(t(exp_elas_glommed_clr), rank. = 10)
lograt_pca_co1_exp <- prcomp(t(exp_co1_glommed_clr), rank. = 10)

summary(lograt_pca_mifish_exp)
summary(lograt_pca_elas_exp)
summary(lograt_pca_co1_exp)
```

Screeplots
```{r}
lograt_variances_mifish_exp <- as.data.frame(lograt_pca_mifish_exp$sdev^2/sum(lograt_pca_mifish_exp$sdev^2)) %>% #Extract axes
  # Format to plot
  select(PercVar = 'lograt_pca_mifish_exp$sdev^2/sum(lograt_pca_mifish_exp$sdev^2)') %>% 
  rownames_to_column(var = "PCaxis") %>% 
  data.frame
head(lograt_variances_mifish_exp)

ggplot(lograt_variances_mifish_exp, aes(x = as.numeric(PCaxis), y = PercVar)) + 
  geom_bar(stat = "identity", fill = "grey", color = "black") +
  theme_minimal() +
  theme(axis.title = element_text(color = "black", face = "bold", size = 10),
        axis.text.y = element_text(color = "black", face = "bold"),
        axis.text.x = element_blank()) +
  labs(x = "PC axis", y = "% Variance", title = "Log-Ratio PCA Screeplot, CLR Tranformation- MiFish/ Expedition")


lograt_variances_elas_exp <- as.data.frame(lograt_pca_elas_exp$sdev^2/sum(lograt_pca_elas_exp$sdev^2)) %>% #Extract axes
  # Format to plot
  select(PercVar = 'lograt_pca_elas_exp$sdev^2/sum(lograt_pca_elas_exp$sdev^2)') %>% 
  rownames_to_column(var = "PCaxis") %>% 
  data.frame
head(lograt_variances_elas_exp)

ggplot(lograt_variances_elas_exp, aes(x = as.numeric(PCaxis), y = PercVar)) + 
  geom_bar(stat = "identity", fill = "grey", color = "black") +
  theme_minimal() +
  theme(axis.title = element_text(color = "black", face = "bold", size = 10),
        axis.text.y = element_text(color = "black", face = "bold"),
        axis.text.x = element_blank()) +
  labs(x = "PC axis", y = "% Variance", title = "Log-Ratio PCA Screeplot, CLR Tranformation- Elas02/ Expedition")

lograt_variances_co1_exp <- as.data.frame(lograt_pca_co1_exp$sdev^2/sum(lograt_pca_co1_exp$sdev^2)) %>% #Extract axes
  # Format to plot
  select(PercVar = 'lograt_pca_co1_exp$sdev^2/sum(lograt_pca_co1_exp$sdev^2)') %>% 
  rownames_to_column(var = "PCaxis") %>% 
  data.frame
head(lograt_variances_co1_exp)

ggplot(lograt_variances_co1_exp, aes(x = as.numeric(PCaxis), y = PercVar)) + 
  geom_bar(stat = "identity", fill = "grey", color = "black") +
  theme_minimal() +
  theme(axis.title = element_text(color = "black", face = "bold", size = 10),
        axis.text.y = element_text(color = "black", face = "bold"),
        axis.text.x = element_blank()) +
  labs(x = "PC axis", y = "% Variance", title = "Log-Ratio PCA Screeplot, CLR Tranformation- CO1/ Expedition")


```
First two axes are moderate for MiFish and CO1 and better for Elas


Extract variances from the clr pca
(Note [this issue](https://github.com/joey711/phyloseq/issues/1322) with converting rownames to column from a phyloseq object.... it was giving me a square 28x28 table rather than the full table. Needed to modify)
```{r}
pca_lograt_mifish_exp_df <- data.frame(lograt_pca_mifish_exp$x) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata into the pca data table
pca_lograt_mifish_exp_df <- sample_data(ps2024_exp_mifish_glommed) %>% data.frame() %>% 
  rownames_to_column(var = "SampleID") %>% 
right_join(pca_lograt_mifish_exp_df, by = "SampleID")

pca_lograt_mifish_exp_df


pca_lograt_elas_exp_df <- data.frame(lograt_pca_elas_exp$x) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata into the pca data table
pca_lograt_elas_exp_df <- sample_data(ps2024_exp_elas_glommed) %>% data.frame() %>% 
  rownames_to_column(var = "SampleID") %>% 
right_join(pca_lograt_elas_exp_df, by = "SampleID")

pca_lograt_elas_exp_df

pca_lograt_co1_exp_df <- data.frame(lograt_pca_co1_exp$x) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata into the pca data table
pca_lograt_co1_exp_df <- sample_data(ps2024_exp_co1_glommed) %>% data.frame() %>% 
  rownames_to_column(var = "SampleID") %>% 
right_join(pca_lograt_co1_exp_df, by = "SampleID")

pca_lograt_co1_exp_df

```

Select eigenvalues from dataframe, round to 4 places and multiply by 100 for plotting. These will be the axes for the 3-D plot
```{r}
eigenvalues_pca_mifish_exp <-round(lograt_variances_mifish_exp[,2], digits = 4)*100
eigenvalues_pca_elas_exp <-round(lograt_variances_elas_exp[,2], digits = 4)*100
eigenvalues_pca_co1_exp <-round(lograt_variances_co1_exp[,2], digits = 4)*100


```

### Plot PCA
Use 1st two axes 
```{r}
pca_mifish_exp_bayside_plot <- ggplot(pca_lograt_mifish_exp_df, aes(x = PC1, y = PC2, color = Bayside)) +
  geom_point(size = 3, alpha = 0.8) + 
  labs(x = paste0('PC1 ',eigenvalues_pca_mifish_exp[1],'%'), y = paste0('PC2 ',eigenvalues_pca_mifish_exp[2],'%'), color = "Bayside") +  
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12),   
    legend.text = element_text(size = 12), 
    legend.title = element_text(size = 14)
  ) +
  labs(title="PCA: MiFish") +
  scale_color_manual(values = c("coral","cornflowerblue"))
pca_mifish_exp_bayside_plot

pca_elas_exp_bayside_plot <- ggplot(pca_lograt_elas_exp_df, aes(x = PC1, y = PC2, color = Bayside)) +
  geom_point(size = 3, alpha = 0.8) + 
  labs(x = paste0('PC1 ',eigenvalues_pca_elas_exp[1],'%'), y = paste0('PC2 ',eigenvalues_pca_elas_exp[2],'%'), color = "Bayside") +  
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12),   
    legend.text = element_text(size = 12), 
    legend.title = element_text(size = 14) #
  ) +
    labs(title="PCA: Elas02") +
  scale_color_manual(values = c("coral","cornflowerblue"))
pca_elas_exp_bayside_plot

pca_co1_exp_bayside_plot <- ggplot(pca_lograt_co1_exp_df, aes(x = PC1, y = PC2, color = Bayside)) +
  geom_point(size = 3, alpha = 0.8) + 
  labs(x = paste0('PC1 ',eigenvalues_pca_co1_exp[1],'%'), y = paste0('PC2 ',eigenvalues_pca_co1_exp[2],'%'), color = "Bayside") +  
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12),   
    legend.text = element_text(size = 12), 
    legend.title = element_text(size = 14)
  ) +
  labs(title="PCA: CO1") +
  scale_color_manual(values = c("coral","cornflowerblue"))
pca_co1_exp_bayside_plot

#

pca_mifish_exp_habitat_plot <- ggplot(pca_lograt_mifish_exp_df, aes(x = PC1, y = PC2, fill = Habitat)) +
  geom_point(size = 3, shape = 21, stroke = 0.5, color = "black") + 
  labs(x = paste0('PC1 ',eigenvalues_pca_mifish_exp[1],'%'), y = paste0('PC2 ',eigenvalues_pca_mifish_exp[2],'%'), color = "Habitat") +  
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12),   
    legend.text = element_text(size = 12), 
    legend.title = element_text(size = 14) #
  ) +
    labs(title="PCA: MiFish") +
  scale_fill_manual(values = c("azure2", "chartreuse4", "cadetblue1", "darkgrey"))
pca_mifish_exp_habitat_plot


pca_elas_exp_habitat_plot <- ggplot(pca_lograt_elas_exp_df, aes(x = PC1, y = PC2, fill = Habitat)) +
  geom_point(size = 3, shape = 21, stroke = 0.5, color = "black") + 
  labs(x = paste0('PC1 ',eigenvalues_pca_elas_exp[1],'%'), y = paste0('PC2 ',eigenvalues_pca_elas_exp[2],'%'), color = "Habitat") +  
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12),   
    legend.text = element_text(size = 12), 
    legend.title = element_text(size = 14) #
  ) +
    labs(title="PCA: Elas02") +
  scale_fill_manual(values = c("azure2", "chartreuse4", "cadetblue1"))
pca_elas_exp_habitat_plot


pca_co1_exp_habitat_plot <- ggplot(pca_lograt_co1_exp_df, aes(x = PC1, y = PC2, fill = Habitat)) +
  geom_point(size = 3, shape = 21, stroke = 0.5, color = "black") + 
  labs(x = paste0('PC1 ',eigenvalues_pca_co1_exp[1],'%'), y = paste0('PC2 ',eigenvalues_pca_co1_exp[2],'%'), color = "Habitat") +  
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12),   
    legend.text = element_text(size = 12), 
    legend.title = element_text(size = 14) #
  ) +
    labs(title="PCA: CO1") +
  scale_fill_manual(values = c("azure2", "chartreuse4", "cadetblue1", "darkgrey"))
pca_co1_exp_habitat_plot


#

pca_mifish_exp_nightday_plot <- ggplot(pca_lograt_mifish_exp_df, aes(x = PC1, y = PC2, fill = Night__Day)) +
  geom_point(size = 3, shape = 21, stroke = 0.5, color = "black") + 
  labs(
    x = paste0('PC1 ', eigenvalues_pca_mifish_exp[1], '%'), 
    y = paste0('PC2 ', eigenvalues_pca_mifish_exp[2], '%'), 
    fill = ""
  ) +  
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12),   
    legend.text = element_text(size = 12), 
    legend.title = element_text(size = 14)
  ) +
    labs(title="PCA: MiFish") +
  scale_fill_manual(values = c("cornsilk", "antiquewhite4"))
pca_mifish_exp_nightday_plot

pca_elas_exp_nightday_plot <- ggplot(pca_lograt_elas_exp_df, aes(x = PC1, y = PC2, fill = Night__Day)) +
  geom_point(size = 3, shape = 21, stroke = 0.5, color = "black") + 
  labs(
    x = paste0('PC1 ', eigenvalues_pca_elas_exp[1], '%'), 
    y = paste0('PC2 ', eigenvalues_pca_elas_exp[2], '%'), 
    fill = ""
  ) +  
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12),   
    legend.text = element_text(size = 12), 
    legend.title = element_text(size = 14)
  ) +
    labs(title="PCA: Elas02") +
  scale_fill_manual(values = c("cornsilk", "antiquewhite4"))
pca_elas_exp_nightday_plot


pca_co1_exp_nightday_plot <- ggplot(pca_lograt_co1_exp_df, aes(x = PC1, y = PC2, fill = Night__Day)) +
  geom_point(size = 3, shape = 21, stroke = 0.5, color = "black") + 
  labs(
    x = paste0('PC1 ', eigenvalues_pca_co1_exp[1], '%'), 
    y = paste0('PC2 ', eigenvalues_pca_co1_exp[2], '%'), 
    fill = ""
  ) +  
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12),   
    legend.text = element_text(size = 12), 
    legend.title = element_text(size = 14)
  ) +
    labs(title="PCA: CO1") +
  scale_fill_manual(values = c("cornsilk", "antiquewhite4"))
pca_co1_exp_nightday_plot

```

save
bayside plots for now
```{r}
ggsave(plot = pca_mifish_exp_bayside_plot, filename = "figures-expedition/pca_mifish_exp_bayside_plot.jpg", width = 7, height = 5, units = "in")

ggsave(plot = pca_elas_exp_bayside_plot, filename = "figures-expedition/pca_elas_exp_bayside_plot.jpg", width = 7, height = 5, units = "in")

ggsave(plot = pca_co1_exp_bayside_plot, filename = "figures-expedition/pca_co1_exp_bayside_plot.jpg", width = 7, height = 5, units = "in")

```



### Env Fit
#### MiFish
```{r}
# sort metadata in same order as the pca matrix
metadata_mifish_exp <- sample_data(ps2024_exp_mifish) %>% data.frame() %>% 
  rownames_to_column(var = "SampleID") %>% arrange(factor(SampleID, levels = rownames(lograt_pca_mifish_exp$x)))

# Fix time and date so it can be used as input

metadata_mifish_exp$DateTime <- as.POSIXct(force_tz((mdy_hms(paste(metadata_mifish_exp$Date, metadata_mifish_exp$Start_Time__ET_))), tzone = "America/New_York"))

# Convert Start Time (from RocSI filtration time) to continuous variable rather than factor. This will be a "time-of-day" variable
metadata_mifish_exp$Time_numeric <- as.numeric(as_hms(as.character(metadata_mifish_exp$Start_Time__ET_)))

# Convert Datecode to numeric
metadata_mifish_exp$Datecode <- as.numeric(metadata_mifish_exp$Datecode)

# Remove some columns of metadate- only retain the env data that I am testing. Leave out the repetitive ID columns, etc.
metadata_mifish_exp <- select(metadata_mifish_exp, -"Name.Deploy_Cartr_Library", -Deployment, -Cartridge_ID, -sites, -replicates, -site_altname, -controls, -Date, -Year, -Month, -Day, -Name.Deploy_Cartr, -Start_Time__ET_, -End_Time__ET_)

# fit environmental factors and save stats output
pca_envfit_mifish_exp <- envfit(lograt_pca_mifish_exp, metadata_mifish_exp, permutations = 10000, na.rm = TRUE)

pca_envfit_mifish_exp
capture.output(pca_envfit_mifish_exp, file = "figures-expedition/pca_envfit_mifish_exp.txt")

```
*SUMMARY- MiFish EnvFir Results that were sig*
Salinity, Time, Site_type



#### Elas02
```{r}
# sort metadata in same order as the pca matrix
metadata_elas_exp <- sample_data(ps2024_exp_elas) %>% data.frame() %>% 
  rownames_to_column(var = "SampleID") %>% arrange(factor(SampleID, levels = rownames(lograt_pca_elas_exp$x)))

# Fix time and date so it can be used as input
metadata_elas_exp$DateTime <- as.POSIXct(force_tz((mdy_hms(paste(metadata_elas_exp$Date, metadata_elas_exp$Start_Time__ET_))), tzone = "America/New_York"))

# Convert Start Time (from RocSI filtration time) to continuous variable rather than factor. This will be a "time-of-day" variable
metadata_elas_exp$Time_numeric <- as.numeric(as_hms(as.character(metadata_elas_exp$Start_Time__ET_)))

# Convert Datecode to numeric
metadata_elas_exp$Datecode <- as.numeric(metadata_elas_exp$Datecode)

# Remove some columns of metadata- only retain the env data that I am testing. Leave out the repetitive ID columns, etc.
metadata_elas_exp <- select(metadata_elas_exp, -Deployment, -Cartridge_ID, -sites, -replicates, -controls, -Date, -Year, -Month, -Day, -Name_Deploy_Cartr_Library, -Start_Time__ET_, -End_Time__ET_)

# fit environmental factors and save stats output
pca_envfit_elas_exp <- envfit(lograt_pca_elas_exp, metadata_elas_exp, permutations = 10000, na.rm = TRUE)

pca_envfit_elas_exp
capture.output(pca_envfit_elas_exp, file = "figures-expedition/pca_envfit_elas_exp.txt")

```

*Summary of Envfit to Elas02 library*
Date, salinity, site_type, night-day



#### CO1
the `sample_data(ps2024_exp_co1)` does not have the calculated avg temp, etc. Grab it from the metadata file 
```{r}
# Import complete table with temp, etc
metadata_co1_exp_complete <- read.csv(file = "figures-expedition/CTD_avg_eDNA_sample_intervals.csv")


# sort metadata in same order as the pca matrix, remove empty columns
metadata_co1_exp <- sample_data(ps2024_exp_co1) %>% 
  data.frame() %>% 
  rownames_to_column(var = "SampleID") %>% 
  arrange(factor(SampleID, levels = rownames(lograt_pca_co1_exp$x))) %>%
  select(-DO, -Temperature, -Salinity, -Time, -Weather) %>%
  mutate(Name.Deploy_Cartr = gsub("\\.", "_", gsub("_$", "", as.character(Name_Deploy_Cartr))))


# join
metadata_co1_exp <- full_join(metadata_co1_exp, metadata_co1_exp_complete, by = join_by(Name.Deploy_Cartr))


# Fix time and date so it can be used as input
metadata_co1_exp$DateTime <- as.POSIXct(force_tz((mdy_hms(paste(metadata_co1_exp$Date, metadata_co1_exp$Start_Time__ET_))), tzone = "America/New_York"))

# Convert Start Time (from RocSI filtration time) to continuous variable rather than factor. This will be a "time-of-day" variable
metadata_co1_exp$Time_numeric <- as.numeric(as_hms(as.character(metadata_co1_exp$Start_Time__ET_)))

# Convert Datecode to numeric
metadata_co1_exp$Datecode <- as.numeric(metadata_co1_exp$Datecode)

# Remove some columns of metadata- only retain the env data that I am testing. Leave out the repetitive ID columns, etc.
metadata_co1_exp <- select(metadata_co1_exp, -"Name_Deploy_Cartr", -Station, -Deployment, -Cartridge_ID, -sites, -replicates, -site_altname, -controls, -Date, -Year, -Month, -Day, -Start_Time__ET_, -End_Time__ET_, -"Name.Deploy_Cartr", -"Deploy_Cartr_Library")

# fit environmental factors and save stats output
pca_envfit_co1_exp <- envfit(lograt_pca_co1_exp, metadata_co1_exp, permutations = 10000, na.rm = TRUE)

pca_envfit_co1_exp
capture.output(pca_envfit_co1_exp, file = "figures-expedition/pca_envfit_co1_exp.txt")

```

Volume, lat, long, date, temp, salinity, bayside, habitat, night/day are all significant





##### Plot EnvFit, Categorical 
```{r}
pca_mifish_exp_bayside_plot <- pca_mifish_exp_bayside_plot +
  stat_ellipse(aes(color = factor(Bayside)), level = 0.99)

pca_elas_exp_bayside_plot <- pca_elas_exp_bayside_plot +
  stat_ellipse(aes(color = factor(Bayside)), level = 0.99)

pca_co1_exp_bayside_plot <- pca_co1_exp_bayside_plot +
  stat_ellipse(aes(color = factor(Bayside)), level = 0.99)


pca_mifish_exp_habitat_plot <- pca_mifish_exp_habitat_plot +
  stat_ellipse(aes(color = factor(Habitat)), level = 0.99) +
  scale_color_manual(values = c("azure2", "chartreuse4", "cadetblue1", "darkgrey")) 


pca_elas_exp_habitat_plot <- pca_elas_exp_habitat_plot +
  stat_ellipse(aes(color = factor(Habitat)), level = 0.99) +
    scale_color_manual(values = c("azure2", "chartreuse4", "cadetblue1")) 

pca_co1_exp_habitat_plot <- pca_co1_exp_habitat_plot +
  stat_ellipse(aes(color = factor(Habitat)), level = 0.99) +
    scale_color_manual(values = c("azure2", "chartreuse4", "cadetblue1", "darkgrey")) 


pca_mifish_exp_nightday_plot <- pca_mifish_exp_nightday_plot +
  stat_ellipse(aes(color = factor(Night__Day)), level = 0.99) +
  scale_color_manual(values = c("cornsilk", "antiquewhite4")) +
  guides(color = "none") 


pca_elas_exp_nightday_plot <- pca_elas_exp_nightday_plot +
  stat_ellipse(aes(color = factor(Night__Day)), level = 0.99) +
  scale_color_manual(values = c("cornsilk", "antiquewhite4")) +
  guides(color = "none") 

pca_co1_exp_nightday_plot <- pca_co1_exp_nightday_plot +
  stat_ellipse(aes(color = factor(Night__Day)), level = 0.99) +
  scale_color_manual(values = c("cornsilk", "antiquewhite4")) +
  guides(color = "none") 



pca_mifish_exp_bayside_plot
pca_elas_exp_bayside_plot
pca_co1_exp_bayside_plot

pca_mifish_exp_habitat_plot
pca_elas_exp_habitat_plot
pca_co1_exp_habitat_plot

pca_mifish_exp_nightday_plot
pca_elas_exp_nightday_plot
pca_co1_exp_nightday_plot

```

###### Plot Envfit + Numerical: Mifish
Add sig vectors from envfit ontop of categ vars

```{r}
pca_mifish_sig_vectors <- as.data.frame(pca_envfit_mifish_exp$vectors$arrows) %>%
  rownames_to_column(var = "EnvVar") %>%
  filter(EnvVar %in% c("Avg_Salinity_psu", "Time_numeric"))  %>%  
  mutate(EnvVar = ifelse(EnvVar == "Avg_Salinity_psu", "Salinity", EnvVar)) %>%
  mutate(EnvVar = ifelse(EnvVar == "Time_numeric", "Time of Day", EnvVar))

# Plot vectors ontop of ellipse plot of bayside
pca_mifish_exp_bayside_date_salinity_plot <- pca_mifish_exp_bayside_plot +
  geom_segment(data = pca_mifish_sig_vectors,
               aes(x = 0, y = 0, xend = PC1, yend = PC2),
               arrow = arrow(type = "closed", length = unit(0.2, "inches")),
               color = "black") +  
  geom_text(data = pca_mifish_sig_vectors,
            aes(x = PC1, y = PC2, label = EnvVar),
            size = 4, color = "black", vjust = -0.5)

pca_mifish_exp_bayside_date_salinity_plot


```
save
```{r}
ggsave(plot = pca_mifish_exp_bayside_date_salinity_plot, filename = "figures-expedition/pca_mifish_exp_bayside_latlong_date_salinity_turbid_plot.jpg", width = 7, height = 5, units = "in")

ggsave(plot = pca_mifish_exp_nightday_plot, filename = "figures-expedition/pca_mifish_exp_nightday_plot.jpg", width = 7, height = 5, units = "in")

```

###### Plot Envfit + Numerical: Elas02
Add sig vectors from envfit ontop of categorical vars 
Date, salinity, night-day

```{r}
pca_elas_sig_vectors <- as.data.frame(pca_envfit_elas_exp$vectors$arrows) %>%
  rownames_to_column(var = "EnvVar") %>%
  filter(EnvVar %in% c("Avg_Salinity_psu","Datecode")) %>%
  mutate(EnvVar = ifelse(EnvVar == "Avg_Salinity_psu", "Salinity", EnvVar)) %>%
  mutate(EnvVar = ifelse(EnvVar == "Datecode", "Date", EnvVar))

    
# Plot vectors ontop of ellipse plot of Bayside
pca_elas_exp_nightday_salinity <- pca_elas_exp_nightday_plot +
  geom_segment(data = pca_elas_sig_vectors,
               aes(x = 0, y = 0, xend = PC1, yend = PC2),
               arrow = arrow(type = "closed", length = unit(0.2, "inches")),
               color = "black",
               inherit.aes = FALSE) +  
  geom_text(data = pca_elas_sig_vectors,
            aes(x = PC1, y = PC2, label = EnvVar),
            size = 4, color = "black", vjust = -0.5, inherit.aes = FALSE)
pca_elas_exp_nightday_salinity


```

save
```{r}
ggsave(plot = pca_elas_exp_nightday_salinity, filename = "figures-expedition/pca_elas_exp_nightday_salinity.jpg", width = 7, height = 5, units = "in")

ggsave(plot = pca_elas_exp_habitat_plot, filename = "figures-expedition/pca_elas_exp_habitat_plot.jpg", width = 7, height = 5, units = "in")

```




###### Plot Envfit + Numerical: CO1
Add sig vectors from envfit ontop of categ vars
Volume, lat, long, date, temp, salinity, bayside, habitat, night/day are all significant
```{r}
pca_co1_sig_vectors <- as.data.frame(pca_envfit_co1_exp$vectors$arrows) %>%
  rownames_to_column(var = "EnvVar") %>%
  filter(EnvVar %in% c("Volume_liter","lat","long","Datecode", "Avg_Temperature_C","Avg_Salinity_psu"))  %>%  
  mutate(EnvVar = ifelse(EnvVar == "Volume_liter", "Volume", EnvVar)) %>%
  mutate(EnvVar = ifelse(EnvVar == "Avg_Salinity_psu", "Salinity", EnvVar)) %>%
  mutate(EnvVar = ifelse(EnvVar == "Datecode", "Date", EnvVar)) %>%
  mutate(EnvVar = ifelse(EnvVar == "Avg_Temperature_C", "Temp", EnvVar)) 


# Plot vectors ontop of ellipse plot of bayside
pca_co1_exp_bayside_date_salinity_plot <- pca_co1_exp_bayside_plot +
  geom_segment(data = pca_co1_sig_vectors,
               aes(x = 0, y = 0, xend = PC1, yend = PC2),
               arrow = arrow(type = "closed", length = unit(0.2, "inches")),
               color = "black") +  
  geom_text(data = pca_co1_sig_vectors,
            aes(x = PC1, y = PC2, label = EnvVar),
            size = 4, color = "black", vjust = -0.5)

pca_co1_exp_bayside_date_salinity_plot


```
save
```{r}
ggsave(plot = pca_co1_exp_bayside_date_salinity_plot, filename = "figures-expedition/pca_co1_exp_bayside_latlong_date_salinity_turbid_plot.jpg", width = 7, height = 5, units = "in")

ggsave(plot = pca_co1_exp_nightday_plot, filename = "figures-expedition/pca_co1_exp_nightday_plot.jpg", width = 7, height = 5, units = "in")

```


#### Save

```{r}
save.image(file = "figures-expedition/exp_ecol_analysis_environment_upto_pca.RData")
```


```{r}
load(file = "figures-expedition/exp_ecol_analysis_environment_upto_pca.RData")
```


## Dissimilarity across geographic distance usiung and Mantel tests
Jaccard similarity (or its complement, Jaccard distance) can be used to examine spatial autocorrelation, especially when paired with [Mantel tests](https://uw.pressbooks.pub/appliedmultivariatestatistics/chapter/mantel-test/)

Bray Curtis can similarly be compared to geo distance and might be more appropriate for metabarcoding data. 

The clr/ Euclidean distance matrix is more apprpriate for compositional data

Try all...



[Example 1](https://fireecology.springeropen.com/articles/10.4996/fireecology.0502116): Mantel test compares two distance matrices (one based on the variable of interest and the other based on the geo distance between sampling units). From the paper:

- The normalized statistic behaves similar to the Pearson correlation coefficient, varying between 1 and +1, so that coefficients can be compared to other variables at the same site or to similar variables at other sites. We determined the overall significance of spatial relationships by permutation testing
- We subjected each of these measures within each experimental unit to a Mantel test using Euclidean distances, with 10 000 permutations used to establish significance ( = 0.05). Although the large number of tests we performed would argue for an adjustment of the critical value, we wanted these tests to be as liberal as possible to search for evidence of significant spatial autocorrelation (e.g., if we used a Bonferroni correction for our 144 tests, we would have a critical value of  = 0.05  144 = 0.00035, (a value not surpassed by any of our tests).

[Example 2](https://sciendo.com/article/10.2478/sg-2018-0013)

[Example 3, Wen et al.](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.1962) - further evidence (or non evidence) of spatial autocorrelation

[Example 4](https://www.jstor.org/stable/pdf/48703667.pdf)


### Elas02
#### Mantel tests
```{r}
# Jaccard uses  presence/absence
# use already-made presence/absence tables from SpOccupancy analysis
elas_exp_df_countmatrix

elas_jaccard_dist <- vegdist(t(elas_exp_df_countmatrix), method = "jaccard")


# for Bray, use relative abundance calculated from read abundance table
elas_exp_df_counttable
elas_exp_df_counttable_relabun <- sweep(elas_exp_df_counttable, 2, colSums(elas_exp_df_counttable), FUN = "/")

elas_bray_dist <- vegdist(t(elas_exp_df_counttable_relabun), method = "bray")


# for compositional approach, use clr transformed data and euclidean distance (aka Aitchison distance)
elas_exp_df_counttable_relabun_clr <- elas_exp_df_counttable
elas_exp_df_counttable_relabun_clr[elas_exp_df_counttable_relabun_clr == 0] <- 1e-10 # replace zeros using a small pseudocount
elas_exp_df_counttable_relabun_clr <- data.frame(compositions::clr(elas_exp_df_counttable_relabun_clr))

elas_aitchison_dist <- vegdist(t(elas_exp_df_counttable_relabun), method = "euclidean")

# extract and order coordinate rows to match matrix sample order
sample_ids <- colnames(elas_exp_df_countmatrix)

# Use coordinates form sampledata df. Note caveat that, bc samples were collected multiple times at same location on different days, there will be places with "zero" geographic distance that might be very different bc of time. Address that later
geo_dist_matrix <- elas_exp_df_sampledata[sample_ids, c("long", "lat")]


# calculate pairwise geographic distances
geo_dist_matrix <- distm(geo_dist_matrix, fun = distHaversine) # computes distances between points in meters using "Haversine" method, which assumes a spherical earth
geo_dist <- as.dist(geo_dist_matrix)

# compare Jaccard vs geographic distance
mantel(elas_jaccard_dist, as.dist(geo_dist), permutations = 10000)
mantel(elas_bray_dist, as.dist(geo_dist), permutations = 10000)
mantel(elas_aitchison_dist, as.dist(geo_dist), permutations = 10000)



```

* I manually verified the distances in geo_dist to make sure they made sense

#### Plot
```{r}
# Convert to vectors that should match in length
jaccard_vec <- as.vector(elas_jaccard_dist)
bray_vec <- as.vector(elas_bray_dist)
aitchison_vec <- as.vector(elas_aitchison_dist)
geo_vec <- as.vector(geo_dist)


# Combine into data frame. Note I converted to SIMILARITES so the plots are easier to understand
# Jaccard and Bray are bounded to 1
# Aitshison is unbounded, so use different calc
elas_similarities <- data.frame(Geo_Distance_km = geo_vec / 1000,
  Jaccard_Similarity = 1-jaccard_vec,
  BrayCurtis_Similarity = 1-bray_vec,
  Aitchison_Similarity = 1/(1+aitchison_vec))

elas_distvsjaccard <- ggplot(elas_similarities, aes(x = Geo_Distance_km, y = Jaccard_Similarity)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Distance-decay of community similarity, Jaccard, Elas02",
    x = "Geographic distance (km)",
    y = "1 - Jaccard dissimilarity") +
  theme_minimal()


elas_distvsbray <- ggplot(elas_similarities, aes(x = Geo_Distance_km, y = BrayCurtis_Similarity)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Distance-decay of community similarity, Bray-Curtis, Elas02",
    x = "Geographic distance (km)",
    y = "1 - Bray Curtis dissimilarity") +
  theme_minimal()


elas_distvsaitchison <- ggplot(elas_similarities, aes(x = Geo_Distance_km, y = Aitchison_Similarity)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Distance-decay of community similarity, Aitchison, Elas02",
    x = "Geographic distance (km)",
    y = "1/(1+Aitchison distance)") +
  theme_minimal()


elas_distvsjaccard
elas_distvsbray
elas_distvsaitchison
```
No relationship between Jaccard distance and geographic distance- suggests Elas02 presence/absence is spatially correlated 
HOWEVER both Bray Curtis and Aitchison suggests there is a relationship between dissimilarity and geo distance in which dissimilarity increases with geo distance (i.e. samples closer together are less dissimilar/ more similar)

CAVEAT- cannot include samples with all zeroes for Jaccard. Therefore this analysis only compares those stations at which at least one elasmobranch was detected. There were 33 stations (of 94) which had zero elasmobranchs. Also there is a very small number of ASVs (only 6) in this dataset compated to the others.

save
```{r}
ggsave(plot = elas_distvsjaccard, filename = "figures-expedition/elas_distvsjaccard.jpg", width = 7, height = 5, units = "in")

ggsave(plot = elas_distvsbray, filename = "figures-expedition/elas_distvsbray.jpg", width = 7, height = 5, units = "in")

ggsave(plot = elas_distvsaitchison, filename = "figures-expedition/elas_distvsaitchison.jpg", width = 7, height = 5, units = "in")

```


### MiFish
#### Mantel tests
```{r}
# Jaccard uses  presence/absence
# use already-made presence/absence tables from SpOccupancy analysis
mifish_exp_df_countmatrix

mifish_jaccard_dist <- vegdist(t(mifish_exp_df_countmatrix), method = "jaccard")


# for Bray, use relative abundance calculated from read abundance table
mifish_exp_df_counttable
mifish_exp_df_counttable_relabun <- sweep(mifish_exp_df_counttable, 2, colSums(mifish_exp_df_counttable), FUN = "/")

mifish_bray_dist <- vegdist(t(mifish_exp_df_counttable_relabun), method = "bray")


# for compositional approach, use clr transformed data and euclidean distance (aka Aitchison distance)
mifish_exp_df_counttable_relabun_clr <- mifish_exp_df_counttable
mifish_exp_df_counttable_relabun_clr[mifish_exp_df_counttable_relabun_clr == 0] <- 1e-10 # replace zeros using a small pseudocount
mifish_exp_df_counttable_relabun_clr <- data.frame(compositions::clr(mifish_exp_df_counttable_relabun_clr))

mifish_aitchison_dist <- vegdist(t(mifish_exp_df_counttable_relabun), method = "euclidean")

# extract and order coordinate rows to match matrix sample order
sample_ids <- colnames(mifish_exp_df_countmatrix)

# Use coordinates form sampledata df. Note caveat that, bc samples were collected multiple times at same location on different days, there will be places with "zero" geographic distance that might be very different bc of time. Address that later
geo_dist_matrix <- mifish_exp_df_sampledata[sample_ids, c("long", "lat")]


# calculate pairwise geographic distances
geo_dist_matrix <- distm(geo_dist_matrix, fun = distHaversine) # computes distances between points in meters using "Haversine" method, which assumes a spherical earth
geo_dist <- as.dist(geo_dist_matrix)

# compare Jaccard vs geographic distance
mantel(mifish_jaccard_dist, as.dist(geo_dist), permutations = 10000)
mantel(mifish_bray_dist, as.dist(geo_dist), permutations = 10000)
mantel(mifish_aitchison_dist, as.dist(geo_dist), permutations = 10000)



```

#### Plot
```{r}
# Convert to vectors that should match in length
jaccard_vec <- as.vector(mifish_jaccard_dist)
bray_vec <- as.vector(mifish_bray_dist)
aitchison_vec <- as.vector(mifish_aitchison_dist)
geo_vec <- as.vector(geo_dist)


# Combine into data frame. Note I converted to SIMILARITES so the plots are easier to understand
# Jaccard and Bray are bounded to 1
# Aitshison is unbounded, so use different calc
mifish_similarities <- data.frame(Geo_Distance_km = geo_vec / 1000,
  Jaccard_Similarity = 1-jaccard_vec,
  BrayCurtis_Similarity = 1-bray_vec,
  Aitchison_Similarity = 1/(1+aitchison_vec))

mifish_distvsjaccard <- ggplot(mifish_similarities, aes(x = Geo_Distance_km, y = Jaccard_Similarity)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Distance-decay of community similarity, Jaccard, MiFish",
    x = "Geographic distance (km)",
    y = "1 - Jaccard dissimilarity") +
  theme_minimal()


mifish_distvsbray <- ggplot(mifish_similarities, aes(x = Geo_Distance_km, y = BrayCurtis_Similarity)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Distance-decay of community similarity, Bray-Curtis, MiFish",
    x = "Geographic distance (km)",
    y = "1 - Bray Curtis dissimilarity") +
  theme_minimal()


mifish_distvsaitchison <- ggplot(mifish_similarities, aes(x = Geo_Distance_km, y = Aitchison_Similarity)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Distance-decay of community similarity, Aitchison, MiFish",
    x = "Geographic distance (km)",
    y = "1/(1+Aitchison distance)") +
  theme_minimal()


mifish_distvsjaccard
mifish_distvsbray
mifish_distvsaitchison
```

None are significant, i.e. there is no relationship between geo distance and compositional similarity for MiFish


save
```{r}
ggsave(plot = mifish_distvsjaccard, filename = "figures-expedition/mifish_distvsjaccard.jpg", width = 7, height = 5, units = "in")

ggsave(plot = mifish_distvsbray, filename = "figures-expedition/mifish_distvsbray.jpg", width = 7, height = 5, units = "in")

ggsave(plot = mifish_distvsaitchison, filename = "figures-expedition/mifish_distvsaitchison.jpg", width = 7, height = 5, units = "in")

```


### CO1
#### Mantel tests
```{r}
# Jaccard uses  presence/absence
# use already-made presence/absence tables from SpOccupancy analysis
co1_exp_df_countmatrix

co1_jaccard_dist <- vegdist(t(co1_exp_df_countmatrix), method = "jaccard")


# for Bray, use relative abundance calculated from read abundance table
co1_exp_df_counttable
co1_exp_df_counttable_relabun <- sweep(co1_exp_df_counttable, 2, colSums(co1_exp_df_counttable), FUN = "/")

co1_bray_dist <- vegdist(t(co1_exp_df_counttable_relabun), method = "bray")


# for compositional approach, use clr transformed data and euclidean distance (aka Aitchison distance)
co1_exp_df_counttable_relabun_clr <- co1_exp_df_counttable
co1_exp_df_counttable_relabun_clr[co1_exp_df_counttable_relabun_clr == 0] <- 1e-10 # replace zeros using a small pseudocount
co1_exp_df_counttable_relabun_clr <- data.frame(compositions::clr(co1_exp_df_counttable_relabun_clr))

co1_aitchison_dist <- vegdist(t(co1_exp_df_counttable_relabun), method = "euclidean")

# extract and order coordinate rows to match matrix sample order
sample_ids <- colnames(co1_exp_df_countmatrix)

# Use coordinates form sampledata df. Note caveat that, bc samples were collected multiple times at same location on different days, there will be places with "zero" geographic distance that might be very different bc of time. Address that later
geo_dist_matrix <- co1_exp_df_sampledata[sample_ids, c("long", "lat")]


# calculate pairwise geographic distances
geo_dist_matrix <- distm(geo_dist_matrix, fun = distHaversine) # computes distances between points in meters using "Haversine" method, which assumes a spherical earth
geo_dist <- as.dist(geo_dist_matrix)

# compare Jaccard vs geographic distance
mantel(co1_jaccard_dist, as.dist(geo_dist), permutations = 10000)
mantel(co1_bray_dist, as.dist(geo_dist), permutations = 10000)
mantel(co1_aitchison_dist, as.dist(geo_dist), permutations = 10000)



```


#### Plot
```{r}
# Convert to vectors that should match in length
jaccard_vec <- as.vector(co1_jaccard_dist)
bray_vec <- as.vector(co1_bray_dist)
aitchison_vec <- as.vector(co1_aitchison_dist)
geo_vec <- as.vector(geo_dist)


# Combine into data frame. Note I converted to SIMILARITES so the plots are easier to understand
# Jaccard and Bray are bounded to 1
# Aitshison is unbounded, so use different calc
co1_similarities <- data.frame(Geo_Distance_km = geo_vec / 1000,
  Jaccard_Similarity = 1-jaccard_vec,
  BrayCurtis_Similarity = 1-bray_vec,
  Aitchison_Similarity = 1/(1+aitchison_vec))

co1_distvsjaccard <- ggplot(co1_similarities, aes(x = Geo_Distance_km, y = Jaccard_Similarity)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Distance-decay of community similarity, Jaccard, CO1",
    x = "Geographic distance (km)",
    y = "1 - Jaccard dissimilarity") +
  theme_minimal()


co1_distvsbray <- ggplot(co1_similarities, aes(x = Geo_Distance_km, y = BrayCurtis_Similarity)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Distance-decay of community similarity, Bray-Curtis, CO1",
    x = "Geographic distance (km)",
    y = "1 - Bray Curtis dissimilarity") +
  theme_minimal()


co1_distvsaitchison <- ggplot(co1_similarities, aes(x = Geo_Distance_km, y = Aitchison_Similarity)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Distance-decay of community similarity, Aitchison, CO1",
    x = "Geographic distance (km)",
    y = "1/(1+Aitchison distance)") +
  theme_minimal()


co1_distvsjaccard
co1_distvsbray
co1_distvsaitchison
```

By all 3 distance metrics, there is a significant relationship between geo distance and compositional similarity. This makes sense bc this dataset is highly composed of single-celled phytoplankton and other planktonic things (larvae, zooplankton, protists, etc) which are dispersal limited and not mobile. Their position is thus controlled by mixing of currents, etc



save
```{r}
ggsave(plot = co1_distvsjaccard, filename = "figures-expedition/co1_distvsjaccard.jpg", width = 7, height = 5, units = "in")

ggsave(plot = co1_distvsbray, filename = "figures-expedition/co1_distvsbray.jpg", width = 7, height = 5, units = "in")

ggsave(plot = co1_distvsaitchison, filename = "figures-expedition/co1_distvsaitchison.jpg", width = 7, height = 5, units = "in")

```


### Save

```{r}
save.image(file = "figures-expedition/exp_ecol_analysis_environment_upto_dissimilarity.RData")
```


```{r}
load(file = "figures-expedition/exp_ecol_analysis_environment_upto_dissimilarity.RData")
```


## NMDS
Use compositional approach, an NMDS on Aitchison distance matrix (aka Euclidean distances on clr-trasnformed abundance. Already computed above)
To compare to PCA

### Run NMDS

```{r}
elas_aitchison_nmds <- metaMDS(elas_aitchison_dist, k=2, autotransform=FALSE) 

mifish_aitchison_nmds <- metaMDS(mifish_aitchison_dist, k=2, autotransform=FALSE) 

co1_aitchison_nmds <- metaMDS(co1_aitchison_dist, k=2, autotransform=FALSE) 

```


### Stress

```{r}
elas_aitchison_nmds$stress

mifish_aitchison_nmds$stress

co1_aitchison_nmds$stress
```

Stress less than 0.1 is good. Less than 0.05 is better. Elas02 is OK but the other two are a bit high. 

Can also try NMDS up to 3 dimensions. See if that's a better fit...

### 3D NMDS

```{r}
elas_aitchison_nmds_3d <- metaMDS(elas_aitchison_dist, k=3, autotransform=FALSE) 

mifish_aitchison_nmds_3d <- metaMDS(mifish_aitchison_dist, k=3, autotransform=FALSE) 
co1_aitchison_nmds_3d <- metaMDS(co1_aitchison_dist, k=3, autotransform=FALSE) 

```


### Stress

```{r}
elas_aitchison_nmds_3d$stress

mifish_aitchison_nmds_3d$stress

co1_aitchison_nmds_3d$stress
```

This improved, proceed with 3 dimensions


### Prepare data frames

Extract points and merge to metadata
Elas02
```{r}
# Extract points from nmds and merge into data frame with metadata 
elas_aitchison_nmds_3d_df <- data.frame(elas_aitchison_nmds_3d$points) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata 
elas_sample_data <- sample_data(ps2024_exp_elas_glommed) %>%
  data.frame() %>%
  rename("SampleID" = "Name.Deploy_Cartr")

elas_aitchison_nmds_3d_df <- full_join(elas_aitchison_nmds_3d_df, elas_sample_data)

elas_aitchison_nmds_3d_df
```


MiFish
```{r}
# Extract points from nmds and merge into data frame with metadata 
mifish_aitchison_nmds_3d_df <- data.frame(mifish_aitchison_nmds_3d$points) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata 
mifish_sample_data <- sample_data(ps2024_exp_mifish_glommed) %>%
  data.frame() %>%
  rename("SampleID" = "Name.Deploy_Cartr")

mifish_aitchison_nmds_3d_df <- full_join(mifish_aitchison_nmds_3d_df, mifish_sample_data)

mifish_aitchison_nmds_3d_df
```

CO1
```{r}
# Extract points from nmds and merge into data frame with metadata 
co1_aitchison_nmds_3d_df <- data.frame(co1_aitchison_nmds_3d$points) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata 
co1_sample_data <- sample_data(ps2024_exp_co1_glommed) %>%
  data.frame() %>%
  mutate(SampleID = gsub("_$", "", gsub("\\.", "_", Name_Deploy_Cartr)))

co1_aitchison_nmds_3d_df <- full_join(co1_aitchison_nmds_3d_df, co1_sample_data)

co1_aitchison_nmds_3d_df
```

## Plot

### Elas02

```{r}
elas_aitchison_nmds_3d_plot <- plot_ly(data = elas_aitchison_nmds_3d_df,
  x    = ~MDS1,
  y    = ~MDS2,
  z    = ~MDS3,
  color  = ~Habitat,
  symbol = ~Night__Day,
  symbols = c('circle','square'),   
  marker = list(size = 5)
) %>%
  layout(
    title = paste0("Elas02 3D NMDS (stress = ", round(elas_aitchison_nmds_3d$stress, 2), ")"),
    scene = list(
      xaxis = list(title = "NMDS1"),
      yaxis = list(title = "NMDS2"),
      zaxis = list(title = "NMDS3")
    ),
    legend = list(title = list(text = "<b>Habitat / Night__Day</b>"))
  )

# save 
withr::with_dir('figures-expedition', htmlwidgets::saveWidget(as_widget(elas_aitchison_nmds_3d_plot), file="elas_aitchison_nmds_3d_plot.html", selfcontained = F))
```


<iframe src="elas_aitchison_nmds_3d_plot.html" width="800" height="600"></iframe> 

--> NMDS1 is major axis of variation. What variable does it correlate to? (it's not habitat nor night/day)
--> These are majority open water sites so differentiation among habitats is difficult but there is clear separation between eelgrass and clam sanctuary, correpsonding to axis 2 and 3.
--> No clear diffferentiation between night and day.


### MiFish

```{r}
mifish_aitchison_nmds_3d_plot <- plot_ly(data = mifish_aitchison_nmds_3d_df,
  x    = ~MDS1,
  y    = ~MDS2,
  z    = ~MDS3,
  color  = ~Habitat,
  symbol = ~Night__Day,
  symbols = c('circle','square'),   
  marker = list(size = 5)
) %>%
  layout(
    title = paste0("MiFish 3D NMDS (stress = ", round(mifish_aitchison_nmds_3d$stress, 2), ")"),
    scene = list(
      xaxis = list(title = "NMDS1"),
      yaxis = list(title = "NMDS2"),
      zaxis = list(title = "NMDS3")
    ),
    legend = list(title = list(text = "<b>Habitat / Night__Day</b>"))
  )

# save 
withr::with_dir('figures-expedition', htmlwidgets::saveWidget(as_widget(mifish_aitchison_nmds_3d_plot), file="mifish_aitchison_nmds_3d_plot.html", selfcontained = F))
```


<iframe src="mifish_aitchison_nmds_3d_plot.html" width="800" height="600"></iframe> 

--> very hard to see any pattern here wrt env covariates

### CO1

```{r}
co1_aitchison_nmds_3d_plot <- plot_ly(data = co1_aitchison_nmds_3d_df,
  x    = ~MDS1,
  y    = ~MDS2,
  z    = ~MDS3,
  color  = ~Habitat,
  symbol = ~Night__Day,
  symbols = c('circle','square'),   
  marker = list(size = 5)
) %>%
  layout(
    title = paste0("CO1 3D NMDS (stress = ", round(co1_aitchison_nmds_3d$stress, 2), ")"),
    scene = list(
      xaxis = list(title = "NMDS1"),
      yaxis = list(title = "NMDS2"),
      zaxis = list(title = "NMDS3")
    ),
    legend = list(title = list(text = "<b>Habitat / Night__Day</b>"))
  )

# save 
withr::with_dir('figures-expedition', htmlwidgets::saveWidget(as_widget(co1_aitchison_nmds_3d_plot), file="co1_aitchison_nmds_3d_plot.html", selfcontained = F))
```


<iframe src="co1_aitchison_nmds_3d_plot.html" width="800" height="600"></iframe> 

--> Clear definition between night and day clusters 

## EnvFit
### Elas02
```{r}
# 3D NMDS scores
elas_3d_nmds_site_scores <- elas_aitchison_nmds_3d_df %>% select(MDS1, MDS2, MDS3)

# envfit on dims 1 & 2 (the default)
elas_nmds_ef12 <- envfit(elas_3d_nmds_site_scores, metadata_elas_exp, choices = c(1,2), permutations = 10000)

# envfit on dims 1 & 3
elas_nmds_ef13 <- envfit(elas_3d_nmds_site_scores, metadata_elas_exp, choices = c(1,3), permutations = 10000)

# envfit on dims 2 & 3
elas_nmds_ef23 <- envfit(elas_3d_nmds_site_scores, metadata_elas_exp, choices = c(2,3), permutations = 10000)

capture.output(elas_nmds_ef12, file = "figures-expedition/elas_nmds_ef12.txt")
capture.output(elas_nmds_ef13, file = "figures-expedition/elas_nmds_ef13.txt")
capture.output(elas_nmds_ef23, file = "figures-expedition/elas_nmds_ef23.txt")


```
ef12: Lat^, Long^, salinity, Bayside^, Habitat, Site_type
ef13: lat^, long^, salinity, chlorophyll, bayside^, habitat, site_type
ef23: long, chlorophyll, bayside, habitat

^ is very signficiant, p < 0.001

Compare to sig PCA envfit results: Date, salinity, site_type, night-day

OVERALL: Salinity is important, which is influenced in this case by position north/south (i.e. longitude, which is consistently important as well). Latitude also very important, corresponding to bayside (position east/west). 



### MiFish
```{r}
# 3D NMDS scores
mifish_3d_nmds_site_scores <- mifish_aitchison_nmds_3d_df %>% select(MDS1, MDS2, MDS3)

# envfit on dims 1 & 2 (the default)
mifish_nmds_ef12 <- envfit(mifish_3d_nmds_site_scores, metadata_mifish_exp, choices = c(1,2), permutations = 10000)

# envfit on dims 1 & 3
mifish_nmds_ef13 <- envfit(mifish_3d_nmds_site_scores, metadata_mifish_exp, choices = c(1,3), permutations = 10000)

# envfit on dims 2 & 3
mifish_nmds_ef23 <- envfit(mifish_3d_nmds_site_scores, metadata_mifish_exp, choices = c(2,3), permutations = 10000)

capture.output(mifish_nmds_ef12, file = "figures-expedition/mifish_nmds_ef12.txt")
capture.output(mifish_nmds_ef13, file = "figures-expedition/mifish_nmds_ef13.txt")
capture.output(mifish_nmds_ef23, file = "figures-expedition/mifish_nmds_ef23.txt")


```
ef12: Lat, depth, salinity, turbidity, habitat
ef13: Lat, salinity, bayside, habitat
ef23: Lat, Bayside

^ NOTE- none are very significant. p<0.1 in most cases

Compare to sig PCA envfit results: Salinity, Time, Site_type

OVERALL: Latitude and bayside consistently are important factors (note these are also related- i.e. position east/west). Salinity also consistently important (influence of estuarine mixing/ freshwater vs saltwater communities). Note- overall these are weaker associations than for Elas02



### CO1
```{r}
# 3D NMDS scores
co1_3d_nmds_site_scores <- co1_aitchison_nmds_3d_df %>% select(MDS1, MDS2, MDS3)

# envfit on dims 1 & 2 (the default)
co1_nmds_ef12 <- envfit(co1_3d_nmds_site_scores, metadata_co1_exp, choices = c(1,2), permutations = 10000)

# envfit on dims 1 & 3
co1_nmds_ef13 <- envfit(co1_3d_nmds_site_scores, metadata_co1_exp, choices = c(1,3), permutations = 10000)

# envfit on dims 2 & 3
co1_nmds_ef23 <- envfit(co1_3d_nmds_site_scores, metadata_co1_exp, choices = c(2,3), permutations = 10000)

capture.output(co1_nmds_ef12, file = "figures-expedition/co1_nmds_ef12.txt")
capture.output(co1_nmds_ef13, file = "figures-expedition/co1_nmds_ef13.txt")
capture.output(co1_nmds_ef23, file = "figures-expedition/co1_nmds_ef23.txt")


```
ef12: long, date^, temp, salinity, habitat^, site type^, night_day^
ef13: date^, temperature salinity, bayside, night_day
ef23: long, date^, temperature salinity, habitat^, site_type^, night_day^

^ is very signficiant, p < 0.001
Compare to sig PCA envfit results: Salinity, Time, Site_type

OVERALL: Date is consistently important for CO1. Within such a short window, interesting that there is a shift in CO1 community with time. 
Habitat important
Longitude important and secondarily salinity. North/south position may also reflect anthropogenic impact (proximity to shore vs proximity to ocean inlet).


### Save

```{r}
save.image(file = "figures-expedition/exp_ecol_analysis_environment_upto_nmds.RData")
```


```{r}
load(file = "figures-expedition/exp_ecol_analysis_environment_upto_nmds.RData")
```




## STOPPED HERE 8/25

## Things to do


- Follow most commonly sampled station (15? 20?)- diversity/ composition change through all 2 weeks, comparing day/night especially. follow composition (by bar?) and richness across all samples from single stations. annotate important events (day night, rain event, temp). Include CTD, chla, and pairwise aitchison distance between bars

- Present analysis of impact of RNAlater preservation (in 2024 trawl MiFish samples)


- What is average geo distance between stations? Min? Max?




